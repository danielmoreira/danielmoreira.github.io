<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Vision | Daniel Moreira</title>
    <link>https://danielmoreira.github.io/tag/computer-vision/</link>
      <atom:link href="https://danielmoreira.github.io/tag/computer-vision/index.xml" rel="self" type="application/rss+xml" />
    <description>Computer Vision</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 29 Aug 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://danielmoreira.github.io/media/sharing.jpg</url>
      <title>Computer Vision</title>
      <link>https://danielmoreira.github.io/tag/computer-vision/</link>
    </image>
    
    <item>
      <title>Computer Vision Applications, Fall 2022</title>
      <link>https://danielmoreira.github.io/teaching/cvapp-aut22/</link>
      <pubDate>Mon, 29 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/cvapp-aut22/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/cvapp-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/cvapp-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/cvapp-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 388-002 / COMP 488-002 Computer Science Topics&lt;br&gt;
Format: Seminar&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: MON, 4:15 to 6:45 PM, 117 Cuneo Hall&lt;br&gt;
Office Hours: TUE and THR, 5:00 to 7:00 PM, &lt;a href=&#34;https://bit.ly/3Tos8wx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt;&lt;br&gt;
Sakai: &lt;a href=&#34;https://sakai.luc.edu/x/4tCa9j&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://sakai.luc.edu/x/4tCa9j&lt;/a&gt;&lt;/p&gt;
&lt;!--- &gt; Announcements. --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Computer Vision then and now.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/cv-then-now.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;How might Google or TinEye reverse image search operate?
How can a computer program process the pixel values of images and video frames and classify the depicted scene,
or leverage the captured faces to perform person identification?
What about manipulated images with tools such as Photoshop?
Are there methods to help to debunk these manipulations?
These are some of the questions we will be addressing in this course,
focusing on state-of-the-art Computer Vision (CV) solutions to reduce the semantic gap
between the pixel values and the desired outcome of complex tasks such as content-based image retrieval,
content classification and recognition, biometric identification, and media forensics,
always with the &lt;a href=&#34;https://danielmoreira.github.io/post/bettersoc/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;greater good&lt;/a&gt; in mind.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Requirements to attend this course are basic programming skills (especially Python) and statistics and probability.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;schedule&#34;&gt;Schedule&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Leaders&lt;/th&gt;
&lt;th&gt;References&lt;/th&gt;
&lt;th&gt;Assignment&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;08/29&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_01.pdf&#34;&gt;Introduction to CV&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instructor&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09/05&lt;/td&gt;
&lt;td&gt;&lt;em&gt;Labor Day&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a01&#34;&gt;A01&lt;/a&gt;, due on 09/15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09/12&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_02.pdf&#34;&gt;Letter Soup: AI, ML, NN, DL, etc.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instructor&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref123&#34;&gt;[1, 2, 3]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a02&#34;&gt;A02&lt;/a&gt;, due on 09/20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09/19&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_03.pdf&#34;&gt;Image Description&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instructor&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref456&#34;&gt;[4, 5, 6]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a03&#34;&gt;A03&lt;/a&gt;, due on 09/27&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09/26&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_04.pdf&#34;&gt;Image Retrieval&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Nick and Jesus&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref78910&#34;&gt;[7, 8, 9, 10]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a04&#34;&gt;A04&lt;/a&gt;, due on 10/04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10/03&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_05.pdf&#34;&gt;Image Classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Nick and Kenneth&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref1112131415&#34;&gt;[11, 12, 13, 14, 15]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a05&#34;&gt;A05&lt;/a&gt;, due on 10/18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10/10&lt;/td&gt;
&lt;td&gt;&lt;em&gt;Fall Break&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10/17&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_06.pdf&#34;&gt;Object Detection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;John and Kenneth&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref1617181920&#34;&gt;[16, 17, 18, 19, 20]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a06&#34;&gt;A06&lt;/a&gt;, due on 10/25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10/24&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_07.pdf&#34;&gt;Image Segmentation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mujtaba and Matt&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref2122232425&#34;&gt;[21, 22, 23, 24, 25]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a07&#34;&gt;A07&lt;/a&gt;, due on 11/01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10/31&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_08.pdf&#34;&gt;Face Detection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;John and Amol&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref26272829&#34;&gt;[26, 27, 28, 29]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a08&#34;&gt;A08&lt;/a&gt;, due on 11/08&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11/07&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_09.pdf&#34;&gt;Face Recognition&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mujtaba and Amol&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref3031323334&#34;&gt;[30, 31, 32, 33, 34]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a09&#34;&gt;A09&lt;/a&gt;, due on 11/15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11/14&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_10.pdf&#34;&gt;Generative Adversarial Nets&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Jakob and Matt&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref3536373839&#34;&gt;[35, 36, 37, 38, 39]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a10&#34;&gt;A10&lt;/a&gt;, due on 11/29&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11/21&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_11.pdf&#34;&gt;Attacks &amp;amp; Deep Fake Detection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instructor&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref404142&#34;&gt;[40, 41, 42]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11/28&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_12.pdf&#34;&gt;Sensitive Video Analysis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instructor&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref4344&#34;&gt;[43, 44]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12/05&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_13.pdf&#34;&gt;Provenance Analysis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Jakob and Jesus&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref4546474849&#34;&gt;[45, 46, 47, 48, 49]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12/12&lt;/td&gt;
&lt;td&gt;&lt;em&gt;Final Exam&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;assignments&#34;&gt;Assignments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a name=&#34;a01&#34;&gt;&lt;/a&gt; &lt;del&gt;A01: Image Descriptors &lt;a href=&#34;#ref456&#34;&gt;[4, 5, 6]&lt;/a&gt;, due on 09/15 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a02&#34;&gt;&lt;/a&gt; &lt;del&gt;A02: Image Retrieval, &lt;a href=&#34;#ref78910&#34;&gt;[8, 9, 10]&lt;/a&gt;, due on 09/20 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a03&#34;&gt;&lt;/a&gt; &lt;del&gt;A03: Image Classification, &lt;a href=&#34;#ref1112131415&#34;&gt;[11, 12, 13, 14, 15]&lt;/a&gt;, due on 09/27 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a04&#34;&gt;&lt;/a&gt; &lt;del&gt;A04: Object Detection, &lt;a href=&#34;#ref1617181920&#34;&gt;[16, 17, 18, 19, 20]&lt;/a&gt;, due on 10/04 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a05&#34;&gt;&lt;/a&gt; &lt;del&gt;A05: Image Segmentation, &lt;a href=&#34;#ref2122232425&#34;&gt;[21, 22, 23, 24, 25]&lt;/a&gt;, due on 10/18 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a06&#34;&gt;&lt;/a&gt; &lt;del&gt;A06: Face Detection, &lt;a href=&#34;#ref26272829&#34;&gt;[26, 27, 28, 29]&lt;/a&gt;, due on 10/25 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a07&#34;&gt;&lt;/a&gt; &lt;del&gt;A07: Face Recognition, &lt;a href=&#34;#ref3031323334&#34;&gt;[30, 31, 32, 33, 34]&lt;/a&gt;, due on 11/01 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a08&#34;&gt;&lt;/a&gt; &lt;del&gt;A08: Generative Adversarial Nets, &lt;a href=&#34;#ref3536373839&#34;&gt;[35, 36, 37, 38, 39]&lt;/a&gt;, due on 11/08 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a09&#34;&gt;&lt;/a&gt; &lt;del&gt;A09: Attacks and Sensitive Video Analysis, &lt;a href=&#34;#ref404142&#34;&gt;[40, 41, 42, 43, 44]&lt;/a&gt;, due on 11/16 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a10&#34;&gt;&lt;/a&gt; &lt;del&gt;A10: Provenance Analysis, &lt;a href=&#34;#ref4546474849&#34;&gt;[46, 47, 48, 49]&lt;/a&gt;, due on 11/29 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Students will have to do at most eight assignments.
Each assignment will comprise a particular set of scientific articles.
Students will have to choose one of the articles for each assignment and provide a summary on the due date.
There is no limit of pages for the summaries.
Each summary should contain:&lt;br&gt;
(1) &lt;strong&gt;What&lt;/strong&gt; is the problem addressed in the article?&lt;br&gt;
(2) &lt;strong&gt;Why&lt;/strong&gt; is it important to address this problem?&lt;br&gt;
(3) &lt;strong&gt;How&lt;/strong&gt; do the authors address the problem?&lt;br&gt;
(4) What are the authors&amp;rsquo; &lt;strong&gt;claims&lt;/strong&gt;?&lt;br&gt;
(5) What &lt;strong&gt;methodology&lt;/strong&gt; did they adopt (e.g., datasets, problem metrics, experiments) to prove their claims?&lt;br&gt;
(6) Do you agree with the authors&amp;rsquo; claims?&lt;br&gt;
(7) For the graduate students, how do you think you may use this work in your research?&lt;br&gt;
(8) What open questions do you have about the article?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;discussion-leaders&#34;&gt;Discussion Leaders&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;Image Retrieval, Nick and Jesus, on 09/26.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Image Classification, Nick and Kenneth, on 10/03.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Object Detection, John and Kenneth, on 10/17.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Image Segmentation, Mujtaba and Matt, on 10/24.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Face Detection, John and Amol, on 10/31.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Face Recognition, Mujtaba and Amol, on 11/07.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Generative Adversarial Networks, Jakob and Matt, on 11/14.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Provenance Analysis, Jakob and Jesus, on 12/05.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Each student will play the role of &lt;em&gt;discussion leader&lt;/em&gt; twice along the course.
Students will lead discussion in groups, preferably in pairs of one graduate and one undergraduate student.
The graduate students are expected to help their undergraduate peers.&lt;/p&gt;
&lt;p&gt;Discussion leaders will be responsible for organizing a 1.5-hour presentation of the topic of the day,
resorting to slides, videos, and demonstrations.
The instructor advises the discussion leaders to share their material with him
a couple of days before the presentation day.&lt;br&gt;
Discussion leaders will also receive the summaries of the articles and open questions related to their topics
from the other students at least 5 days before their presentation.&lt;/p&gt;
&lt;p&gt;The discussion and assignment topics coincide; as a consequence, discussion leaders are not required to
provide summaries for the topics they will present.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;final-exam&#34;&gt;Final Exam&lt;/h2&gt;
&lt;p&gt;Date and Local: 12/12, 4:15 PM, 117 Cuneo Hall&lt;br&gt;
Format: Oral Quiz&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;grading&#34;&gt;Grading&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point Interval&lt;/th&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point Interval&lt;/th&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point Interval&lt;/th&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point Interval&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;[94, 100)&lt;/td&gt;
&lt;td&gt;B+&lt;/td&gt;
&lt;td&gt;[88, 89]&lt;/td&gt;
&lt;td&gt;C+&lt;/td&gt;
&lt;td&gt;[78, 79]&lt;/td&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;[60, 69]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A-&lt;/td&gt;
&lt;td&gt;[90, 93]&lt;/td&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;[84, 87]&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;[74, 77]&lt;/td&gt;
&lt;td&gt;F&lt;/td&gt;
&lt;td&gt;[0, 59]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;B-&lt;/td&gt;
&lt;td&gt;[80, 83]&lt;/td&gt;
&lt;td&gt;C-&lt;/td&gt;
&lt;td&gt;[70, 73]&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;distribution&#34;&gt;Distribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Total&lt;/strong&gt;: 100 points&lt;/li&gt;
&lt;li&gt;Class Presence and Participation: 6 points (x13)&lt;/li&gt;
&lt;li&gt;Assignments: 1 point (x8)&lt;/li&gt;
&lt;li&gt;Discussion Leadership: 3 points (x2)&lt;/li&gt;
&lt;li&gt;Final Exam: 8 points&lt;/li&gt;
&lt;li&gt;&lt;em&gt;CV-on-the-news&lt;/em&gt; Post: 1 point (extra)&lt;/li&gt;
&lt;li&gt;Demonstration on Discussion Day: 5 points (extra)&lt;/li&gt;
&lt;li&gt;Late Assignments: -0.1 point per day&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Grading.&#34; srcset=&#34;
               /teaching/cvapp-aut22/grading_hu3a9cdd06fb4f6267548ce78325163976_526278_92026d99672eb47ccd334acf0a51fc6a.webp 400w,
               /teaching/cvapp-aut22/grading_hu3a9cdd06fb4f6267548ce78325163976_526278_b3811655f7faf03136557ce3593313b3.webp 760w,
               /teaching/cvapp-aut22/grading_hu3a9cdd06fb4f6267548ce78325163976_526278_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/grading_hu3a9cdd06fb4f6267548ce78325163976_526278_92026d99672eb47ccd334acf0a51fc6a.webp&#34;
               width=&#34;760&#34;
               height=&#34;236&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Each student has two &lt;em&gt;&amp;ldquo;Oopsie&amp;rdquo;&lt;/em&gt; cards (OC), which will allow them to either avoid losing points because of absence
or extend due dates until 12/11.
They may use an OC at their discretion for any task, except for their assigned days of discussion leadership
and final exam.
Please let the instructor know you want to use your OC.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Oopsie card.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/card.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;cv-on-the-news&#34;&gt;CV On the News&lt;/h2&gt;
&lt;p&gt;Posted by the students on Sakai.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://bit.ly/3HebdsS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3HebdsS&lt;/a&gt; (Matt&amp;rsquo;s submission).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://intel.ly/3B2o5hS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://intel.ly/3B2o5hS&lt;/a&gt; (Jakob&amp;rsquo;s).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://yhoo.it/3Fl3sjx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://yhoo.it/3Fl3sjx&lt;/a&gt; (Nick&amp;rsquo;s).&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;google-colab&#34;&gt;Google Colab&lt;/h2&gt;
&lt;p&gt;Practical material used in class.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Harris&amp;rsquo; corner detector (&lt;a href=&#34;https://bit.ly/3gRv0E2%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3gRv0E2)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;SIFT detector (&lt;a href=&#34;https://bit.ly/3gXsZWL%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3gXsZWL)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;SURF detector (&lt;a href=&#34;https://bit.ly/3B7dNxg%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3B7dNxg)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Face recognition (&lt;a href=&#34;https://bit.ly/3F4D5NM%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3F4D5NM)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;FGSM (&lt;a href=&#34;https://bit.ly/3Fl4Oe7%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3Fl4Oe7)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Lippe&amp;rsquo;s FGSM (&lt;a href=&#34;https://bit.ly/3FmvbAD%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3FmvbAD)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref123&#34;&gt;&lt;/a&gt; LeCun, Y., Bengio, Y., Hinton, G. &lt;em&gt;Deep learning&lt;/em&gt;.
Nature 521 (1), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hearst, M., Dumais, S., Osuna, E., Platt, J., Scholkopf, B. &lt;em&gt;Support vector machines&lt;/em&gt;.
IEEE Intelligent Systems and their Applications 13 (4), 1998.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ho, T. &lt;em&gt;The Random Subspace Method for Constructing Decision Forests&lt;/em&gt;.
IEEE Transactions on Pattern Analysis and Machine Intelligence 20 (8), 1998.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref456&#34;&gt;&lt;/a&gt; Lowe, D. &lt;em&gt;Distinctive Image Features from Scale-Invariant Keypoints&lt;/em&gt;.
Springer International Journal of Computer Vision 60 (2), 2004.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bay, H., Tuytelaars, T., Van Gool, L. &lt;em&gt;SURF: Speeded Up Robust Features&lt;/em&gt;.
Springer European Conference on Computer Vision (ECCV), 2006&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Noh, H., Araujo, A., Sim, J., Weyand, T., Han, B. &lt;em&gt;Large-Scale Image Retrieval with Attentive Deep Local Features&lt;/em&gt;.
IEEE International Conference on Computer Vision (ICCV), 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref78910&#34;&gt;&lt;/a&gt; Jegou, H., Douze, M., Johnson, J. &lt;em&gt;Faiss: A library for efficient similarity search&lt;/em&gt;.
Available at &lt;a href=&#34;https://bit.ly/3BiGYg9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3BiGYg9&lt;/a&gt;. Meta Platforms, Inc., 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Brogan, J., Bharati, A., Moreira, D., Rocha, A., Bowyer, K., Flynn, P., Scheirer, W.
&lt;em&gt;Fast Local Spatial Verification for Feature-Agnostic Large-Scale Image Retrieval&lt;/em&gt;.
IEEE Transactions on Image Processing 30 (1), 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Kalantidis, Y., Avrithis, Y. &lt;em&gt;Locally Optimized Product Quantization for Approximate Nearest Neighbor Search&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jegou, H., Douze, M., Schmid, C. &lt;em&gt;Product quantization for nearest neighbor search&lt;/em&gt;.
IEEE Transactions on Pattern Analysis and Machine Intelligence 33 (1), 2010.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref1112131415&#34;&gt;&lt;/a&gt; Howard, A., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H.
&lt;em&gt;Mobilenets: Efficient convolutional neural networks for mobile vision applications&lt;/em&gt;.
ArXiv Preprint, 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Krizhevsky, A., Sutskever, I., Hinton, G. &lt;em&gt;Imagenet classification with deep convolutional neural networks&lt;/em&gt;.
ACM Communications 60 (6), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;He, K., Zhang, X., Ren, S., Sun, J. &lt;em&gt;Deep residual learning for image recognition&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.
&lt;em&gt;Going deeper with convolutions&lt;/em&gt;. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simonyan, K., Zisserman, A.
&lt;em&gt;Very deep convolutional networks for large-scale image recognition&lt;/em&gt;.
International Conference on Learning Representations (ICLR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref1617181920&#34;&gt;&lt;/a&gt; Lin, T-Y., Goyal, P., Girshick, R., He, K., Dollar, P. &lt;em&gt;Focal loss for dense object detection&lt;/em&gt;.
IEEE International Conference on Computer Vision (ICCV), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Redmon, J., Divvala, S., Girshick, R., and Farhadi, A. &lt;em&gt;You only look once: Unified, real-time object detection&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ren, S., He, K., Girshick, R., Sun, J.
&lt;em&gt;Faster R-CNN: Towards real-time object detection with region proposal networks&lt;/em&gt;
Advances in Neural Information Processing Systems 28 (1), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Girshick, R. &lt;em&gt;Fast R-CNN&lt;/em&gt;. IEEE International Conference on Computer Vision (ICCV), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Girshick, R., Donahue, J., Darrell, T., Malik, J.
&lt;em&gt;Rich feature hierarchies for accurate object detection and semantic segmentation&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref2122232425&#34;&gt;&lt;/a&gt; Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., Fu, Y., Feng, J., Xiang, T., Torr, P., Zhang, L.
&lt;em&gt;Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;He, K., Gkioxari, G., Dollar, P., Girshick, R. &lt;em&gt;Mask R-CNN&lt;/em&gt;.
IEEE International Conference on Computer Vision (ICCV), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Badrinarayanan, V., Kendall, A., Cipolla, R.
&lt;em&gt;SegNet: A deep convolutional encoder-decoder architecture for image segmentation&lt;/em&gt;.
IEEE Transactions on Pattern Analysis and Machine Intelligence 39 (12), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Long, J., Shelhamer, E., Darrell, T.
&lt;em&gt;Fully convolutional networks for semantic segmentation&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ronneberger, O., Fischer, P., Brox, T.
&lt;em&gt;U-net: Convolutional networks for biomedical image segmentation&lt;/em&gt;.
Springer International Conference on Medical Image Computing and Computer-assisted Intervention (MICCAI), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref26272829&#34;&gt;&lt;/a&gt; Viola, P., Jones, M. &lt;em&gt;Robust real-time face detection&lt;/em&gt;.
Springer International Journal of Computer Vision 57 (2), 2004.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Li, H., Lin, Z., Shen, X., Brandt, J., Hua, G. &lt;em&gt;A convolutional neural network cascade for face detection&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Xu, X., Kakadiaris, I.
&lt;em&gt;Joint head pose estimation and face alignment framework using global and local CNN features&lt;/em&gt;.
IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Albiero, V., Chen, X., Yin, X., Pang, G., Hassner, T.
&lt;em&gt;img2pose: Face alignment and detection via 6dof, face pose estimation&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref3031323334&#34;&gt;&lt;/a&gt; Parkhi, O., Vedaldi, A., Zisserman, A. &lt;em&gt;Deep face recognition&lt;/em&gt;.
British Machine Vision Conference (BMVC), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Schroff, F., Kalenichenko, D., Philbin, J.
&lt;em&gt;Facenet: A unified embedding for face recognition and clustering&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wen, Y., Zhang, K., Li, Z., Qiao, Y.
&lt;em&gt;A discriminative feature learning approach for deep face recognition&lt;/em&gt;.
Springer European Conference on Computer Vision (ECCV), 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Liu, W., Wen, Y., Yu, Z., Li, M., Raj, B., Song, L.
&lt;em&gt;Sphereface: Deep hypersphere embedding for face recognition&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deng, J., Guo, J., Xue, N., Zafeiriou, S.
&lt;em&gt;Arcface: Additive angular margin loss for deep face recognition&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref3536373839&#34;&gt;&lt;/a&gt; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.
&lt;em&gt;Generative adversarial nets&lt;/em&gt;. ArXiv preprint (&lt;a href=&#34;https://bit.ly/3OXpCvn%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3OXpCvn)&lt;/a&gt;, 2014.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mirza, M., Osindero, S. &lt;em&gt;Conditional generative adversarial nets&lt;/em&gt;.
ArXiv preprint (&lt;a href=&#34;https://bit.ly/3OZwM2j%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3OZwM2j)&lt;/a&gt;, 2014.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Isola, P., Zhu, J., Zhou, T., Efros, A. &lt;em&gt;Image-to-image translation with conditional adversarial networks&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Zhu, J., Park, T., Isola, P., Efros, A.
&lt;em&gt;Unpaired image-to-image translation using cycle-consistent adversarial networks&lt;/em&gt;.
IEEE International Conference on Computer Vision (ICCV), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Karras, T., Laine, S., Aila, T. &lt;em&gt;A style-based generator architecture for generative adversarial networks&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref404142&#34;&gt;&lt;/a&gt; Goodfellow, I., Shlens, J., Szegedy, C. &lt;em&gt;Explaining and harnessing adversarial examples&lt;/em&gt;.
International Conference on Learning Representations (ICLR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bai, T., Zhao, J., Zhu, J., Han, S., Chen, J., Li, B., Kot, A.
&lt;em&gt;AI-gan: Attack-inspired generation of adversarial examples&lt;/em&gt;.
IEEE International Conference on Image Processing (ICIP), 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wang, S., Wang, O., Zhang, R., Owens, A., Efros, A.
&lt;em&gt;CNN-generated images are surprisingly easy to spot&amp;hellip; for now&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref4344&#34;&gt;&lt;/a&gt; Perez, M., Avila, S., Moreira, D., Moraes, D., Testoni, V., Valle, E., Goldenstein, S., Rocha, A.
&lt;em&gt;Video pornography detection through deep learning techniques and motion information&lt;/em&gt;.
Elsevier Neurocomputing 230 (1), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Moreira, D., Avila, S., Perez, M., Moraes, D., Testoni, V., Valle, E., Goldenstein, S., Rocha, A.
&lt;em&gt;Temporal robust features for violence detection&lt;/em&gt;.
IEEE Winter Conference on Applications of Computer Vision (WACV), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref4546474849&#34;&gt;&lt;/a&gt; Moreira, D., Theisen, W., Scheirer, W., Bharati, A., Brogan, J., Rocha, A. &lt;em&gt;Image Provenance Analysis&lt;/em&gt;.
Springer Multimedia Forensics (Book), 2022.
Available at &lt;a href=&#34;https://bit.ly/3ESzK5q&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3ESzK5q&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pinto, A., Moreira, D., Bharati, A., Brogan, J., Bowyer, K., Flynn, P., Scheirer, W., Rocha, A.
&lt;em&gt;Provenance filtering for multimedia phylogeny&lt;/em&gt;. IEEE International Conference on Image Processing (ICIP), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Moreira, D., Bharati, A., Brogan, J., Pinto, A., Parowski, M., Bowyer, K., Flynn, P., Rocha, A., Scheirer, W.
&lt;em&gt;Image provenance analysis at scale&lt;/em&gt;. IEEE Transactions on Image Processing 27 (12), 2018.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bharati, A., Moreira, D., Brogan, J., Hale, P., Bowyer, K., Flynn, P., Rocha, A., Scheirer, W.
&lt;em&gt;Beyond pixels: Image provenance analysis leveraging metadata&lt;/em&gt;.
IEEE Winter Conference on Applications of Computer Vision (WACV), 2019.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bharati, A., Moreira, D., Flynn, P., Rocha, A., Bowyer, K., Scheirer, W.
&lt;em&gt;Transformation-aware embeddings for image provenance&lt;/em&gt;.
IEEE Transactions on Information Forensics and Security 16 (1), 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;academic-integrity&#34;&gt;Academic Integrity&lt;/h2&gt;
&lt;p&gt;Students are expected to adhere to the LUC statements on academic integrity available at &lt;a href=&#34;https://bit.ly/3TmiQkQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3TmiQkQ&lt;/a&gt;.
These policies fully apply to this course.
The penalty for task-wise academic misconduct is zero points.
Multiple events of misconduct will incur in failing the entire course (with an F grade).
All cases of academic misconduct will be reported to the proper department offices.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;accommodations&#34;&gt;Accommodations&lt;/h2&gt;
&lt;p&gt;Students who have disabilities and wish to request academic accommodations are advised to contact the
&lt;em&gt;Services for Students With Disabilities&lt;/em&gt; (SSWD) office at 773-508-3700 or &lt;a href=&#34;mailto:SSWD@luc.edu&#34;&gt;SSWD@luc.edu&lt;/a&gt; as soon as possible.
The SSWD office will provide accommodation letters that, once shared with the instructor, will be fully accommodated
as per the terms of their content with no further questions.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
