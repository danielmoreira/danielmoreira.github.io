[{"authors":["daniel"],"categories":null,"content":"My name is Daniel and I am a computer scientist. I am currently an assistant research professor at the University of Notre Dame, USA, and I received my PhD degree from the University of Campinas, Brazil, in 2016.\nAs a member of the Computer Vision Research Lab, I investigate the application of techniques from the fields of Computer Vision, Machine Learning, Visual Media Forensics, and Biometrics to make our society better.\nIf you need my CV, please find it here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1631331247,"objectID":"13fb944df2e35b4baa2c6664c8ff164a","permalink":"https://danielmoreira.github.io/authors/daniel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/daniel/","section":"authors","summary":"My name is Daniel and I am a computer scientist. I am currently an assistant research professor at the University of Notre Dame, USA, and I received my PhD degree from the University of Campinas, Brazil, in 2016.\nAs a member of the Computer Vision Research Lab, I investigate the application of techniques from the fields of Computer Vision, Machine Learning, Visual Media Forensics, and Biometrics to make our society better.","tags":null,"title":"Daniel H. Moreira","type":"authors"},{"authors":null,"categories":null,"content":"    Details Course: CSE 40537 / 60537 Biometrics\nInstructor: Daniel Moreira (dhenriq1@nd.edu)\nTeaching Assistant: Jason You (syou@nd.edu)\nLectures: TUE and THR, 3:30 to 4:45 PM, 356A Fitzpatrick Hall\nOffice Hours: Daniel - MON and WED, 5:00 to 6:00 PM, 313 Cushing Hall, Jason - WED, 1:00 to 2:00 PM, 150M Fitzpatrick Hall\nSlack: https://nd-biometrics-spr22.slack.com\nPanopto: https://bit.ly/3A4QEKc\n Progress  01/11/2022 - Syllabus, Course details. 01/13/2022 - Basics I, Biometrics, traits, and systems. 01/18/2022 - Basics II, Errors, metrics, and attacks. 01/20/2022 - Basics II (cont.), 1st Coding Class, Metrics. 01/25/2022 - Fingerprint Recog. I, History and features. 01/27/2022 - Fingerprint Recog. II, Acquisition and enhancement. 02/01/2022 - Fingerprint Recog. III, Minutiae detection.   Assignments  01/20/2022 - 1st assignment, data, due date: 01/28/2022.   Important Dates  01/28/2022 - 1st assignment due date 02/03/2022 - Fingerprint data collection 02/16/2022 - 2nd assignment due date 02/24/2022 - Iris data collection 03/03/2022 - Midterm exam 03/18/2022 - 3rd assignment due date 03/24/2022 - Face data collection 04/05/2022 - Fingerprint presentation attack day 04/07/2022 - Iris presentation attack day 04/08/2022 - 4th assignment due date 04/12/2022 - Face presentation attack day 04/19/2022 - Presentation attack report due date 05/05/2022 - Final exam   Grading    Concept Point interval     A [94, 100)   A- [90, 93]   B+ [88, 89]   B [84, 87]   B- [80, 83]   C+ [78, 79]   C [74, 77]   C- [70, 73]   D [60, 69]   F [0, 59]    Distribution  Total: 100 points Assignments: 10 points (x4) Presentation attack detection report: 20 points Midterm exam: 20 points Final exam: 20 points Late assignments: -1 point per day   Links  Classroom recording notification.   ","date":1641600000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643744131,"objectID":"24aadea06c79d658adaf71213f4263b5","permalink":"https://danielmoreira.github.io/teaching/biometrics-spr22/","publishdate":"2022-01-08T00:00:00Z","relpermalink":"/teaching/biometrics-spr22/","section":"teaching","summary":"CSE 40537 / 60537 Biometrics","tags":["Teaching","Biometrics","Fingerprint Recognition","Face Recognition","Iris Recognition"],"title":"Biometrics, Spring 2022","type":"teaching"},{"authors":["Joel Brogan","Aparna Bharati","Daniel Moreira","Anderson Rocha","Kevin Bowyer","Patrick Flynn","Walter Scheirer"],"categories":null,"content":"","date":1626825600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628821022,"objectID":"1642d311553b4e54a6fcfd9c43414f13","permalink":"https://danielmoreira.github.io/publication/2021_tip/","publishdate":"2021-07-21T00:00:00Z","relpermalink":"/publication/2021_tip/","section":"publication","summary":"2021 IEEE Transactions on Image Processing","tags":["CBIR","Media Forensics","Provenance Analysis","Provenance Filtering"],"title":"Fast Local Spatial Verification for Feature-Agnostic Large-Scale Image Retrieval","type":"publication"},{"authors":null,"categories":null,"content":"Status: Ongoing, Funded by: DARPA\nThe Semantic Forensics research project (SemaFor) is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA), whose goal is to leverage forensic tools to perform the detection of the existence, atribution of the authorship, and characterization of the intention of manipulated digital media.\nWorking together with the Universities of Purdue, Siena, Campinas (Unicamp), Naples Federico II, and the Politécnico di Milano, our team leads the development of solutions to the problem of digital document analysis (such as scientific papers, news articles, patents, grants, etc.). By combining ideas from the topics of image retrieval, digital image forensics, natural language processing, and deep learning, we aim at proposing multimodal methods to spot semantic inconsistencies within the content of documents.\nResearch Team  Prof. Walter Scheirer (PI) Prof. Anderson Rocha (PI) Prof. Kevin Bowyer (PI) Prof. Tim Weninger (PI) Prof. Daniel Moreira (PI) William Theisen (PhD Student) Trenton Ford (PhD Student) Rosaura VidalMata (PhD Student) Priscila Saboia Moreira (PhD Student) João P. Cardenuto (PhD Student)  ","date":1622678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628821022,"objectID":"0637272bead5fc08c94ecba1be402dcf","permalink":"https://danielmoreira.github.io/project/semafor/","publishdate":"2021-06-03T00:00:00Z","relpermalink":"/project/semafor/","section":"project","summary":"Semantic analysis of digital documents to support forensics.","tags":["Semantic Forensics","Document Analysis"],"title":"SemaFor","type":"project"},{"authors":null,"categories":null,"content":"Status: Ongoing, Funded by: DARPA\nThe Scientific Integrity (Sci-Int) project is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA), whose goal is to develop solutions to identify misconduct in scientific research through the detection of image tampering in scientific papers.\nWorking together with the Universities of Purdue, South California (USC), Campinas (Unicamp), Naples Federico II, and the Politécnico di Milano, our team leads the development of techniques to (1) rule out false positive cases of misidentified misconduct, and to (2) better report and document misconduct practices in retraction notices.\nTo accomplish item (1), we plan to perform semantic analyses of the suspect paper cases, in order to identify situations in which duplications or manipulations of content were made with fair scientific purpose (e.g., to visually highlight or to better explain previous results). To do that, we plan to use natural language processing to perform basic automated paper text and image caption interpretation.\nTo accomplish item (2), we plan to rely on techniques of Provenance Graph Construction to present better explanations of how problematic images relate to each other, and how they share content across different papers.\nResearch Team  Prof. Walter Scheirer (PI) Prof. Anderson Rocha (PI) Prof. Kevin Bowyer (PI) Prof. Daniel Moreira (PI) João P. Cardenuto (PhD Student)  ","date":1622592000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628821022,"objectID":"a9d89a042b5261f9823062ae35a22cef","permalink":"https://danielmoreira.github.io/project/sciint/","publishdate":"2021-06-02T00:00:00Z","relpermalink":"/project/sciint/","section":"project","summary":"Assessment of scientific research integrity through the detection of image tampering in scientific papers.","tags":["Media Forensics","Image Manipulation Detection","Provenance Analysis","Natural Language Processing"],"title":"Sci-Int","type":"project"},{"authors":["William Theisen","Joel Brogan","Pamela Bilo Thomas","Daniel Moreira","Pascal Phoa","Tim Weninger","Walter Scheirer"],"categories":null,"content":"","date":1621641600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628821022,"objectID":"fe3c7fb8d0ddb8e792d99fcbf0529350","permalink":"https://danielmoreira.github.io/publication/2021_icwsm/","publishdate":"2021-05-22T00:00:00Z","relpermalink":"/publication/2021_icwsm/","section":"publication","summary":"2021 AAAI International Conference on Web and Social Media","tags":["Meme Genres","Politics","Image Fitlering"],"title":"Automatic Discovery of Political Meme Genres with Diverse Appearances","type":"publication"},{"authors":["Aparna Bharati","Daniel Moreira","Patrick Flynn","Anderson Rocha","Kevin Bowyer","Walter Scheirer"],"categories":null,"content":"","date":1610064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628821022,"objectID":"f69605846e42c0b40155436fcc83a1ab","permalink":"https://danielmoreira.github.io/publication/2021_tifs/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/publication/2021_tifs/","section":"publication","summary":"2021 IEEE Transactions on Information Forensics and Security","tags":["Deep Learning","Media Forensics","Provenance Analysis","Provenance Graph Construction"],"title":"Transformation-Aware Embeddings for Image Provenance","type":"publication"},{"authors":null,"categories":null,"content":"    Details Course: CSE 40537 / 60537 Biometrics\nInstructor: Daniel Moreira (dhenriq1@nd.edu)\nLectures: TUE and THR, 5:05 to 6:20 PM, 125 DeBartolo Hall1Office Hours: MON and WED, 2:00 to 4:00 PM, 150N Fitzpatrick Hall1Lectures: TUE and THR, 2:00 to 3:15 PM, at Zoom1Office Hours: TUE and THR, 5:05 to 6:20 PM, at Zoom1Students are not obligated to attend classes at 2:00 pm, but are certainly welcome. All classes are being recorded with Panopto.\nSlack: https://cse-biometrics-spr20.slack.com (now deactivated) Panopto: https://bit.ly/33ZkU97\nZoom: https://notredame.zoom.us/my/dmoreira\nCourse grades are now available.  Progress  01/14/2020 - Syllabus, Course details. 01/16/2020 - Basics I, Biometrics, traits, and systems. 01/21/2020 - Basics II, Errors, metrics, and attacks. 01/23/2020 - 1st Coding Class, Implementation of metrics. 01/28/2020 - Fingerprint Recog. I, History and features. 01/30/2020 - Fingerprint Recog. II, Acquisition and enhancement. 02/04/2020 - Fingerprint Recog. III, Minutiae detection. 02/06/2020 - Fingerprint Data Collection, password with instructor. 02/11/2020 - 2nd Coding Class, Minutiae-based recognition. 02/13/2020 - 2nd Coding Class, continuation. 02/18/2020 - Face Recog. I, Why faces and faces vs. fingerprints. 02/20/2020 - Face Recog. II, Acquisition and enhancement. 02/25/2020 - Face Recog. III, Description and matching. 02/27/2020 - 3rd Coding Class, Face recognition. 03/03/2020 - Fingerprints assignment, Developers\u0026rsquo; day. 03/05/2020 - Fingerprints assignment, Attackers\u0026rsquo; day. 03/10/2020 - Spring Break. 03/12/2020 - Spring Break. 03/17/2020 - Extended Spring Break1. 03/18/2020 - Extended Spring Break1. 03/24/2020 - New Course Directions1. 03/26/2020 - Iris Recog. I, Why irises and irises vs. other traits. 03/31/2020 - Iris Recog. II, Acquisition and enhancement. 04/02/2020 - Iris Recog. III, Description and matching. 04/07/2020 - 4th Coding Class, Iris recognition. 04/09/2020 - Multibiometrics, Other traits, data fusion. 04/14/2020 - 1st Invited Talk, Dr. Andrey Kuehlkamp. 04/16/2020 - 2nd Invited Talk, Dr. Adam Czajka. 04/21/2020 - Faces assignment, Developers\u0026rsquo; day. 04/23/2020 - Irises assignment, Developers\u0026rsquo; day. 04/28/2020 - Assignment Report due date. 05/04/2020 - Final exam, see grades.   Important Dates  03/03/2020 - Fingerprints assignment, Developers\u0026rsquo; day. 03/05/2020 - Fingerprints assignment, Attackers\u0026rsquo; day. ~~03/31/2020 - Faces assignment, Developers\u0026rsquo; day.~~1 ~~04/02/2020 - Faces assignment, Attackers\u0026rsquo; day.~~1 ~~04/14/2020 - Irises assignment, Developers\u0026rsquo; day.~~1 ~~04/16/2020 - Irises assignment, Attackers\u0026rsquo; day.~~1 ~~04/28/2020 - Last assignment, Collaboration day.~~1 04/14/2020 (5:05 PM at Zoom) - Dr. Andrey Kuehlkamp\u0026rsquo;s talk. 04/16/2020 (5:05 PM at Zoom) - Dr. Adam Czajka\u0026rsquo;s talk. 04/21/2020 - Faces assignment, Developers\u0026rsquo; day1. 04/23/2020 - Irises assignment, Developers\u0026rsquo; day1. 04/28/2020 - Final Report due date1. 05/04/2020 - Final exam.   Invited Talks           Dr. Andrey KuehkampPostdoctoral Research Associate at the Center for Research Computing, University of Notre Dame            Diverse Aspects in Advancing Iris Recognition SystemsAre we ready for widespread, mass-scale adoption of iris recognition systems? Following the miniaturization of fingerprint scanners, these have dominated recognition systems and have even become almost commonplace for unlocking cell phones, but what if in the not-so-far-off future they were replaced with iris scanners, would you be comfortable with it? Since its initial introduction in 1993, automated iris recognition has dramatically grown in popularity and soon could become the dominant method for automated recognition. Take for example the largest recognition system in the world \u0026mdash; India’s Aadhaar program \u0026mdash; which has collected more than 1.1 billion irises from their citizens to be used as the primary identification for banking, pensions, and welfare programs. Even more recently \u0026mdash; November 2017 \u0026mdash; Somaliland became the first country in the world to use iris recognition as the means for identification in a public election, which had more than 800,000 registered voters. Although a mature technology in many regards, the drastic increase in iris recognition adoption has revealed many opportunities for improvement. In this talk I present an overview of my research, which focuses on improving iris recognition in three ways: speed, accuracy, and robustness.               Dr. Adam CzajkaAssistant Professor at the Department of Computer Science and Engineering, University of Notre Dame            **Is this eye alive or artificial?***Oh wait, maybe it’s dead? Detection of unknown presentation attacks in biometrics.*Presentation attacks are those physical presentations to a biometric system that aim at driving it into an incorrect decision. Rediscovered recently in general computer vision community (and raising a significant interest; look \u0026mdash; for instance \u0026mdash; for famous stop sign attacks on deep learning-based object detection models), these attacks are known in biometrics for several decades. In this talk, I will use iris recognition as an example and will present the huge creativity of attackers in using various artifacts (printouts, patterned contact lenses, plastic eyes, GAN-generated fakes and\u0026hellip; dead eyes) to spoof a system. Although training a model to recognize each of these presentation attack instruments is relatively easy and works well, a big challenge now is how to build models that generalize onto unknown attack types, going beyond our understanding of attackers’ creativity when training our models. I will present a few methods we are exploring in our research to provide presentation attack detection methods that perform promisingly in open-set classification scenario.     Links  Classroom recording notification. Yale face dataset,  used to replace face acquisition1. CASIA-IrisV1,  used to replace iris acquisition1.   Biometrics on the News Posted by the students and the instructor on Slack:\n  https://vancouversun.com/news/local-news/biometric-opioid-vending-machine-unveiled-in-vancouver\n  https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html\n  https://www.landmobile.co.uk/news/metropolitan-police-service-nec-live-facial-recognition/\n  https://www.nytimes.com/2020/01/20/opinion/facial-recognition-ban-privacy.html\n  https://www.biometricupdate.com/202001/securiport-partners-with-university-of-notre-dame-in-biometrics-and-data-analytics-research-for-border-security\n  https://www.nytimes.com/2020/02/06/business/facial-recognition-schools.html\n  https://www.abacusnews.com/tech/why-your-palm-could-be-safer-fingerprints-or-facial-recognition/article/3046162\n  https://www.cnn.com/2020/02/26/tech/clearview-ai-hack/index.html\n  https://nakedsecurity.sophos.com/2020/04/08/as-if-the-world-couldnt-get-any-weirder-this-ai-toilet-scans-your-anus-to-identify-you/\n  https://arstechnica.com/information-technology/2020/04/attackers-can-bypass-fingerprint-authentication-with-an-80-success-rate/    COVID-19 1: Modified/canceled due to COVID-19.\n Acknowledgments This course is heavily based on Dr. Adam Czajka\u0026rsquo;s and Dr. Walter Scheirer\u0026rsquo;s previous Biometrics courses. I sincerely thank them for kindly allowing me to rely upon their materials.\n ","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589593635,"objectID":"121fb4f8057a9a39884ee21fcdbea52e","permalink":"https://danielmoreira.github.io/teaching/biometrics-spr20/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/teaching/biometrics-spr20/","section":"teaching","summary":"CSE 40537 / 60537 Biometrics","tags":["Teaching","Biometrics","Fingerprint Recognition","Face Recognition","Iris Recognition"],"title":"Biometrics, Spring 2020","type":"teaching"},{"authors":null,"categories":null,"content":"One of the things I worry about while doing my research is how to drive it towards building a better society. Although the concept of a better society may differ from one culture to the other, I believe any society gets better whenever all of its members experience more freedom to enjoy their rights.\nAmong the untold manners technology can be used to breach people\u0026rsquo;s rights, five flaws in the way we are doing informatics get my attention. Devices and programs usually suffer from (1) lack of safety, (2) lack of trustworthiness, (3) lack of privacy, (4) ignorance of diversity, and (5) lack of accountability. Not unintentionally, the projects I\u0026rsquo;ve been contributing to in the past few years tackle one or more of these issues.\nSafety    From the many ways safety can be harmed by technology, the improper dissemination of sensitive content (such as pornography or violence), to inadequate audiences (such as kids or unwary spectators), gained my attention while I was developing my PhD, under the supervision of prof. Anderson Rocha (who generously proposed the topic).\nWith the popularity and pervasiveness of online video streams, sensitive scenes depicting suicide, murder, and even rape have been broadcasted on the Internet, raising questions about the safety of these services. Aware of this situation, Samsung has funded us to focus on the development of solutions to detect sensitive video. Rather than aiming at denouncing or morally condemning the lawful consumers of certain types of sensitive content, our intent has always been to support the implementation of filtering and warning features that would make player systems safer (especially in the case of child spectators).\nI\u0026rsquo;ve had the chance to tackle the lack of safety in video streaming systems through the SMA project.\nTrustworthiness   In the era of misinformation and fake news, there is a symptomatic undermining of trust not only in textual but also in visual information. People are conscious of the existence of image editing software (e.g., Photoshop), with which even unskilled users can easily fabricate and manipulate pictures. Although many of these manipulations have benign purposes (no, there is nothing wrong with your memes), some contents are generated with malicious intents, such as general public deception and propaganda.\nThe lack of available solutions to assess the integrity of images and videos allows adversarial manipulated data to have a negative impact on the way people relate to each other on the Internet. They don\u0026rsquo;t know what to believe or whom to trust anymore. In addition, fraudulent images represent a challenge even for the scientific community. Aware of this scenario, DARPA has been funding us, at CVRL, to conduct research on the development of tools to verify the integrity of digital images.\nI\u0026rsquo;m having the chance to tackle the lack of trustworthiness in visual media systems through the MediFor and Sci-Int projects.\nPrivacy and Diversity   With the advent of deep learning and the necessity for large datasets, visual data collection has become an important step of Computer Vision and Machine Learning research. Due to the popularity of image and video capture devices (such as digital cameras, smartphones, dash cams, etc.), large datasets can now be quickly generated. Nevertheless, a major question that stands out in such a process is how to protect the privacy of people who are eventually being recorded. Imagine, for example, a dash cam that is collecting road data for a self-driving car project. In a major city, plenty of people will certainly be captured in the footages, and it is very unlikely that one will be able to obtain image rights for each individual.\nInterested in such issue, we, at CVRL, investigate the generation of realistic synthetic faces, whose identities do not belong to a real existing person, hence avoiding privacy breaches. The idea is to de-identify the recorded individuals, by replacing their faces with synthetic assets.\n   In addition, collected data may be biased, due to a lack of diversity in the captured individuals. Consider, for instance, training video footages collected in China. It is very unlikely that black people will be represented in such a dataset.\nLimitations of this nature comprise what I call ignorance of diversity and are the potential cause of many technological failures in the presence of underrepresented groups. Unfortunately, glitches like these may go beyond the technological aspects and prejudice the rights of equality in face of diversity. To cope with this problem, similar to the privacy protection strategy, synthetic identities can be used to diversify the recorded individuals by performing face replacement, providing controlled variation of not only ethnicity but also of age and of gender.\nI\u0026rsquo;m having the chance to tackle the lack of privacy and ignorance of diversity in image and video datasets through the SREFV project.\nAccountability   People have the right to understand in details the decisions made about them by algorithms belonging to either government or industry. This is fundamental to give them the possibility of questioning determinations and defending against resolutions that might be the outcome of incorrect, rigged, or even bogus computations. In this context, accountability becomes a relevant concept, since it comprises the property of an automated decision system to be fair, transparent, and explainable to human beings. As a consequence, the more accountable a system is, the more audit power it gives to people.\nWithin the field of Biometrics, traditional iris recognition solutions are well known for constituting very reliable methods of identity verification. Nevertheless, since they are not human-friendly enough to convince people who do not possess image processing expertise, their usage before a jury in courts of law is usually avoided. Aware of this limitation, Prof. Adam Czajka has started at CVRL the investigation of human-intelligible iris matching strategies.\nI\u0026rsquo;m having the chance to tackle the lack of accountability in iris recognition algorithms through the TSHEPII project.\nKeep pushing    Although the aforementioned efforts may seem minuscule in face of the size of the challenge of building a better society, I try to calm myself down by making a parallel to the explanation of Prof. Matt Might on how the human knowledge increases with the progress of scientific research. As he advises, I keep pushing.\n","date":1560384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564694632,"objectID":"07602f928b69d804bda2d657c4b532e7","permalink":"https://danielmoreira.github.io/post/bettersoc/","publishdate":"2019-06-13T00:00:00Z","relpermalink":"/post/bettersoc/","section":"post","summary":"What does a better society mean?","tags":["Random Thoughts"],"title":"A Better Society","type":"post"},{"authors":null,"categories":null,"content":"Status: Concluded, Funded by: DARPA\nAdvisor: Prof. Walter Scheirer\nThe Media Forensics research project (MediFor) is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA) and the Air Force Research Laboratory (AFRL), whose goal is to develop solutions for the automated assessment of the integrity of digital images.\nWorking together with the Universities of Purdue, South California (USC), New York (NYU), Siena, Campinas (Unicamp), and the Politécnico di Milano, our team leads the development of solutions to the problem of Provenance Analysis. Given a questioned image, namely a probe, and a large corpus of images (such as the Internet), Provenance Analysis aims at two major tasks:\n  Finding the images that directly and transitively share content with the probe (a task we call Provenance Filtering).\n  Building the directed acyclic graph whose nodes individually represent the probe and related images, and whose edges express the edition and content-donation history (e.g., cropping, blurring, removal, splicing, etc.) between pairs of images, linking seminal to generated elements (a task we call Provenance Graph Construction).\n     By combining ideas from the areas of image retrieval, digital image forensics, and graph theory, Provenance Analysis constitutes an interesting interdisciplinary topic that spans the fields of image processing and computer vision.\nResearch Team  Prof. Walter Scheirer (PI) Prof. Anderson Rocha (PI) Prof. Kevin Bowyer (PI) Prof. Patrick Flynn (PI) Daniel Moreira (Postdoc) Aparna Bharati (PhD Student) Joel Brogan (PhD Student) Allan Pinto (PhD Student) Michael Parowski (Undergrad Student) Patricia Hale (Undergrad Student) William Badart (Undergrad Student)  ","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596902014,"objectID":"2ce2b93ee954a04842b88663b1a80847","permalink":"https://danielmoreira.github.io/project/medifor/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/project/medifor/","section":"project","summary":"Integrity assessment of digital images through content provenance analysis.","tags":["Media Forensics","Provenance Analysis","Provenance Filtering","Provenance Graph Construction"],"title":"MediFor","type":"project"},{"authors":null,"categories":null,"content":"Status: Concluded\nAdvisor: Prof. Patrick Flynn\nThe SREFV project aims at extending prior research on synthesis of realistic faces, to support the generation of videos containing animated faces with synthetic identities, depicted either frontally or in varying poses.\nBesides the obvious artistic and entertainment purposes, the outcome of this project will constitute an interesting tool to de-identify and diversify the faces depicted in video training datasets, helping to protect the identity of volunteers, and to mitigate eventual age, gender, and ethnic dataset collection biases.\nResearch Team  Prof. Patrick Flynn (PI) Prof. Kevin Bowyer (PI) Prof. Adam Czajka (PI) Prof. Walter Scheirer (PI) Daniel Moreira (Postdoc) Sandipan Banerjee (PhD Student)  ","date":1559260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596902014,"objectID":"537f8411954a4c4c6b9bc998a07a6d40","permalink":"https://danielmoreira.github.io/project/srefv/","publishdate":"2019-05-31T00:00:00Z","relpermalink":"/project/srefv/","section":"project","summary":"Synthesis of Realistic Example Face Videos.","tags":["Face Synthesis","Identity Synthesis","Video Synthesis","Biometrics"],"title":"SREFV","type":"project"},{"authors":null,"categories":null,"content":"Status: Concluded\nAdvisor: Prof. Adam Czajka\nThe TSHEPII project aims at developing a software tool to support the human examination of post-mortem iris images. The tool puts together diverse computer vision techniques to automatically process, extract, annotate, and match iris regions from two different eye captures. The idea is to give to the user enough iris texture matching and non-matching information, so they can decided if the two given images depict the same eye or not.\n   The video above depicts a demo of the TSHEPII tool, with all the computer vision techniques added to the software. As the project name suggests (Tool Supporting the Human Examination of Post-Mortem Iris Images), the tool is particularly tuned to the case of comparing post-mortem irises, which, contrary to the common sense, might still be useful for performing iris recognition.\nResearch Team  Prof. Adam Czajka (PI) Prof. Patrick Flynn (PI) Prof. Kevin Bowyer (PI) Daniel Moreira (Postdoc) Mateusz Trokielewicz (PhD Student) M.D. Piotr Maciejewicz (Collaborator)  ","date":1559088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596902014,"objectID":"6e56f34183b51fc8d0f9e6ff96491f5d","permalink":"https://danielmoreira.github.io/project/tshepii/","publishdate":"2019-05-29T00:00:00Z","relpermalink":"/project/tshepii/","section":"project","summary":"Tool Supporting the Human Examination of Post-Mortem Iris Images.","tags":["Iris Recognition","Post-Mortem Iris Recognition","Biometrics"],"title":"TSHEPII","type":"project"},{"authors":null,"categories":null,"content":"","date":1559001600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560488561,"objectID":"1de616391e830170d5282040d55a25f9","permalink":"https://danielmoreira.github.io/project/trof/","publishdate":"2019-05-28T00:00:00Z","relpermalink":"/project/trof/","section":"project","summary":"Temporal Robust Features, a fast spatiotemporal video content detector and descriptor.","tags":["Video Description","TRoF"],"title":"TRoF","type":"project"},{"authors":null,"categories":null,"content":"Status: Concluded, Funded by: Samsung Eletrônica da Amazônia Ltda.\nAdvisor: Prof. Anderson Rocha\nThe Sensitive Media Analysis (SMA) project aims at researching solutions to combine different and complementary data representations and pattern classifiers for detecting sensitive content in digital images and videos.\nSensitive media can be defined as the digital content whose depiction to particular audiences (e.g., children or unwary spectators), at particular places (e.g., at work, at school, in the church) may inflict harm (e.g., trauma, shock, or fear) due to its inappropriateness. Typical representatives include – but are not limited to – scenes depicting pornography and violence, animal cruelty and child abuse, hate speech, etc.\nThe innovation aspects of the project reside on the development of solutions that are amenable to deployment on mobile devices (e.g., smartphones and tablets), observing their constraints of memory footprint, processing power, and runtime responsiveness.\nResearch Team  Prof. Anderson Rocha (PI) Prof. Siome Goldenstein (PI) Prof. Eduardo Valle (PI) Dr. Vanessa Testoni (Samsung Collaborator) Dr. Sandra Avila (Postdoc) Daniel Moreira (PhD Student) Mauricio Perez (MSc Student) Daniel Moraes (Programmer)  ","date":1558915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560488561,"objectID":"8c202c01c9c0cb8865f1f79d879ccdda","permalink":"https://danielmoreira.github.io/project/sma/","publishdate":"2019-05-27T00:00:00Z","relpermalink":"/project/sma/","section":"project","summary":"Sensitive Media Analysis through the detection and localization of sensitive video content.","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection"],"title":"SMA","type":"project"},{"authors":["Sandra Avila","Daniel Moreira","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1548720000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560488561,"objectID":"d5edbd8365c7dddf14bb76b8cdcce3f6","permalink":"https://danielmoreira.github.io/publication/2019_patent/","publishdate":"2019-01-29T00:00:00Z","relpermalink":"/publication/2019_patent/","section":"publication","summary":"2019 US Patent Office","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection","Multimodal Data Fusion"],"title":"Multimodal and real-time method for filtering sensitive media","type":"publication"},{"authors":["Aparna Bharati","Daniel Moreira","Joel Brogan","Patricia Hale","Kevin Bowyer","Patrick Flynn","Anderson Rocha","Walter Scheirer"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"cec704dbc02dcdd4772cdada6dabda4f","permalink":"https://danielmoreira.github.io/publication/2019_wacv_metada/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/2019_wacv_metada/","section":"publication","summary":"2019 IEEE Winter Conference on Applications of Computer Vision","tags":["Media Forensics","Provenance Analysis","Provenance Graph Construction"],"title":"Beyond Pixels: Image Provenance Analysis Leveraging Metadata","type":"publication"},{"authors":["Adam Czajka","Daniel Moreira","Kevin Bowyer","Patrick Flynn"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"8dbd380984ae361a7a51034f1a7fe26c","permalink":"https://danielmoreira.github.io/publication/2019_wacv_bsif/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/2019_wacv_bsif/","section":"publication","summary":"2019 IEEE Winter Conference on Applications of Computer Vision","tags":["Iris Recognition","BSIF","Biometrics"],"title":"Domain-Specific Human-Inspired Binarized Statistical Image Features for Iris Recognition","type":"publication"},{"authors":["Daniel Moreira","Mateusz Trokielewicz","Adam Czajka","Kevin Bowyer","Patrick Flynn"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"fba13bfc64b4a1351fe20af6d9bb8a78","permalink":"https://danielmoreira.github.io/publication/2019_wacv_human/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/2019_wacv_human/","section":"publication","summary":"2019 IEEE Winter Conference on Applications of Computer Vision","tags":["Iris Recognition","Human Performance","Biometrics"],"title":"Performance of Humans in Iris Recognition: The Impact of Iris Condition and Annotation-Driven Verification","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"841df25d6df2414cfad507adb08dbab6","permalink":"https://danielmoreira.github.io/publication/2019_if/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/2019_if/","section":"publication","summary":"2019 Elsevier Information Fusion","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection","Multimodal Data Fusion"],"title":"Multimodal data fusion for sensitive scene localization","type":"publication"},{"authors":["Daniel Moreira","Aparna Bharati","Joel Brogan","Allan Pinto","Michael Parowski","Kevin Bowyer","Patrick Flynn","Anderson Rocha","Walter Scheirer"],"categories":null,"content":"","date":1534377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"4b2f08ef5a215cbc816e2d78b1acc987","permalink":"https://danielmoreira.github.io/publication/2018_tip/","publishdate":"2018-08-16T00:00:00Z","relpermalink":"/publication/2018_tip/","section":"publication","summary":"2018 IEEE Transactions on Image Processing","tags":["CBIR","Media Forensics","Provenance Analysis","Provenance Filtering","Provenance Graph Construction"],"title":"Image Provenance Analysis at Scale","type":"publication"},{"authors":["Nathaniel Blanchard","Daniel Moreira","Aparna Bharati","Walter Scheirer"],"categories":null,"content":"","date":1532044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"02bff565c8b8a0844a62c8358bf0b176","permalink":"https://danielmoreira.github.io/publication/2018_acl/","publishdate":"2018-07-20T00:00:00Z","relpermalink":"/publication/2018_acl/","section":"publication","summary":"2018 ACL Grand Challenge and Workshop on Human Multimodal Language","tags":["Sentiment Classification","Multimodal Data Fusion"],"title":"Getting the subtext without the text: Scalable multimodal sentiment classification from visual and acoustic modalities","type":"publication"},{"authors":["Sandra Avila","Daniel Moreira","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1507593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560488561,"objectID":"d081d8e219b281b95d7d562e0344c762","permalink":"https://danielmoreira.github.io/publication/2017_patent/","publishdate":"2017-10-10T00:00:00Z","relpermalink":"/publication/2017_patent/","section":"publication","summary":"2017 BR Instituto Nacional de Propriedade Industrial","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection","Multimodal Data Fusion"],"title":"Método multimodal e em tempo real para filtragem de conteúdo sensível","type":"publication"},{"authors":["Allan Pinto","Daniel Moreira","Aparna Bharati","Joel Brogan","Kevin Bowyer","Patrick Flynn","Walter Scheirer","Anderson Rocha"],"categories":null,"content":"","date":1505865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"01756fc5abf88d5fa03edf5125183c98","permalink":"https://danielmoreira.github.io/publication/2017_icip_filtering/","publishdate":"2017-09-20T00:00:00Z","relpermalink":"/publication/2017_icip_filtering/","section":"publication","summary":"2017 IEEE International Conference on Image Processing","tags":["Media Forensics","Provenance Analysis","Provenance Filtering"],"title":"Provenance filtering for multimedia phylogeny","type":"publication"},{"authors":["Joel Brogan","Paolo Bestagini","Aparna Bharati","Allan Pinto","Daniel Moreira","Kevin Bowyer","Patrick Flynn","Anderson Rocha","Walter Scheirer"],"categories":null,"content":"","date":1505865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"02147cfb5fb75dce768201eadfb88ecb","permalink":"https://danielmoreira.github.io/publication/2017_icip_spotting/","publishdate":"2017-09-20T00:00:00Z","relpermalink":"/publication/2017_icip_spotting/","section":"publication","summary":"2017 IEEE International Conference on Image Processing","tags":["Media Forensics","Provenance Analysis","Provenance Filtering","Forgery Detection","Forgery Localization"],"title":"Spotting the difference: Context retrieval and analysis for improved forgery detection and localization","type":"publication"},{"authors":["Aparna Bharati","Daniel Moreira","Allan Pinto","Joel Brogan","Kevin Bowyer","Patrick Flynn","Walter Scheirer","Anderson Rocha"],"categories":null,"content":"","date":1505865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"e0e55df34f95abd748c49a3c73976a22","permalink":"https://danielmoreira.github.io/publication/2017_icip_uphylogeny/","publishdate":"2017-09-20T00:00:00Z","relpermalink":"/publication/2017_icip_uphylogeny/","section":"publication","summary":"2017 IEEE International Conference on Image Processing","tags":["Media Forensics","Provenance Analysis","Provenance Graph Construction"],"title":"U-Phylogeny: Undirected provenance graph construction in the wild","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"   ","date":1490313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"d6e6309c8877cb2a9c81810845939da6","permalink":"https://danielmoreira.github.io/publication/2017_wacv/","publishdate":"2017-03-24T00:00:00Z","relpermalink":"/publication/2017_wacv/","section":"publication","summary":"2017 IEEE Winter Conference on Applications of Computer Vision","tags":["Sensitive Media Analysis","Violence Detection","TRoF"],"title":"Temporal Robust Features for Violence Detection","type":"publication"},{"authors":["Mauricio Perez","Sandra Avila","Daniel Moreira","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1490140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"15191369fe40e5bb02e6086be58c4f73","permalink":"https://danielmoreira.github.io/publication/2017_neurocomputing/","publishdate":"2017-03-22T00:00:00Z","relpermalink":"/publication/2017_neurocomputing/","section":"publication","summary":"2017 Elsevier Neurocomputing","tags":["Sensitive Media Analysis","Pornography Detection","Deep Learning"],"title":"Video pornography detection through deep learning techniques and motion information","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"   ","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"7494b3fed906e23b0a676deb4fd9433b","permalink":"https://danielmoreira.github.io/publication/2016_fsi/","publishdate":"2016-11-01T00:00:00Z","relpermalink":"/publication/2016_fsi/","section":"publication","summary":"2016 Elsevier Forensic Science International","tags":["Sensitive Media Analysis","Pornography Detection","TRoF"],"title":"Pornography classification: The hidden clues in video space–time","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1444953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"7fa554d52ea776bd773cd0077ad60f5a","permalink":"https://danielmoreira.github.io/publication/2015_mediaeval/","publishdate":"2015-10-16T00:00:00Z","relpermalink":"/publication/2015_mediaeval/","section":"publication","summary":"2015 Mediaeval Workshop","tags":["Sensitive Media Analysis","Violence Detection","MediaEval"],"title":"RECOD at MediaEval 2015: Affective Impact of Movies Task","type":"publication"},{"authors":["Sandra Avila","Daniel Moreira","Mauricio Perez","Daniel Moraes","Isabela Cota","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1413417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"70ffa72781253d07b83dc47ed4e8837b","permalink":"https://danielmoreira.github.io/publication/2014_mediaeval/","publishdate":"2014-10-16T00:00:00Z","relpermalink":"/publication/2014_mediaeval/","section":"publication","summary":"2014 Mediaeval Workshop","tags":["Sensitive Media Analysis","Violence Detection","MediaEval"],"title":"RECOD at MediaEval 2014: Violent Scenes Detection Task","type":"publication"}]