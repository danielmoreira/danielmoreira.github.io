[{"authors":["daniel"],"categories":null,"content":"My name is Daniel and I am a computer scientist who works as an assistant professor at Loyola University Chicago, USA.\nI investigate the application of techniques from the fields of Computer Vision, Machine Learning, Media Forensics, and Biometrics to make our society better.\n I\u0026rsquo;m proud to have just recently joined Loyola University Chicago. Further news will be posted here soon.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1660615832,"objectID":"13fb944df2e35b4baa2c6664c8ff164a","permalink":"https://danielmoreira.github.io/authors/daniel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/daniel/","section":"authors","summary":"My name is Daniel and I am a computer scientist who works as an assistant professor at Loyola University Chicago, USA.\nI investigate the application of techniques from the fields of Computer Vision, Machine Learning, Media Forensics, and Biometrics to make our society better.\n I\u0026rsquo;m proud to have just recently joined Loyola University Chicago. Further news will be posted here soon.\n ","tags":null,"title":"Daniel H. Moreira","type":"authors"},{"authors":null,"categories":null,"content":"    Details Course: COMP 388-002 / COMP 488-002 Computer Science Topics\nFormat: Seminar\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dmoreira1@luc.edu)\nLectures: MON, 4:15 to 6:45 PM, 117 Cuneo Hall\nOffice Hours: TUE and THR, 5:00 to 7:00 PM, by appointment\nSakai: https://sakai.luc.edu/x/4tCa9j\nAnnouncements. --  Overview How might Google or TinEye reverse image search operate? How can a computer program process the pixel values of images and video frames and classify the depicted scene, or leverage the captured faces to perform person identification? What about manipulated images with tools such as Photoshop? Are there methods to help to debunk these manipulations? These are some of the questions we will be addressing in this course, focusing on state-of-the-art Computer Vision (CV) solutions to reduce the semantic gap between the pixel values and the desired outcome of complex tasks such as content-based image retrieval, content classification and recognition, biometric identification, and media forensics, always with the greater good in mind.\n Requirements to attend this course are basic programming skills (especially Python) and statistics and probability.\n  Schedule (tentative)    Date Topic Leaders References Assignment     08/29 Introduction to CV Instructor N.A. N.A.   09/05 Labor Day N.A. N.A. A01, due on 09/15   09/12 Letter Soup: AI, ML, NN, DL, etc. Instructor [1, 2, 3] A02, due on 09/20   09/19 Local and Global Descriptors Instructor [4, 5, 6] A03, due on 09/27   09/26 CBIR and Indexing Nick and Jesus [7, 8, 9, 10, 11] A04, due on 10/04   10/03 Image Classification Nick and Kenneth TBD A05, due on 10/18   10/10 Fall Break N.A. N.A. N.A.   10/17 Object Detection John and Kenneth TBD A06, due on 10/25   10/24 Image Segmentation Mujtaba and Matt TBD A07, due on 11/01   10/31 Face Detection John and Amol TBD A08, due on 11/08   11/07 Face Verification Mujtaba and Amol TBD A09, due on 11/15   11/14 GANs and Generative DL Jakob and Matt TBD A10, due on 11/29   11/21 Deep and Cheap Fakes Instructor TBD N.A.   11/28 Sensitive Media Analysis Instructor TBD N.A.   12/05 Provenance Analysis Jakob and Jesus TBD N.A.   12/12 Final Exam N.A. N.A. N.A.            \nAssignments  A01: Image Descriptors [4, 5, 6], due on 09/15 at noon. A02: Image Retrieval, [8, 9, 10, 11], due on 09/20 at noon. A03: TBD, released no later than 09/19, due on 09/27 at noon. A04: TBD, released no later than 09/26, due on 10/04 at noon. A05: TBD, released no later than 10/03, due on 10/18 at noon. A06: TBD, released no later than 10/17, due on 10/25 at noon. A07: TBD, released no later than 10/24, due on 11/01 at noon. A08: TBD, released no later than 10/31, due on 11/08 at noon. A09: TBD, released no later than 11/07, due on 11/15 at noon. A10: TBD, released no later than 11/14, due on 11/29 at noon.   Students will have to do at most eight assignments. Each assignment will comprise a particular set of scientific articles. Students will have to choose one of the articles for each assignment and provide a summary on the due date. There is no limit of pages for the summaries. Each summary should contain:\n(1) What is the problem addressed in the article?\n(2) Why is it important to address this problem?\n(3) How do the authors address the problem?\n(4) What are the authors\u0026rsquo; claims?\n(5) What methodology did they adopt (e.g., datasets, problem metrics, experiments) to prove their claims?\n(6) Do you agree with the authors\u0026rsquo; claims?\n(7) For the graduate students, how do you think you may use this work in your research?\n(8) What open questions do you have about the article?\n  Discussion Leaders  CBIR and Indexing, Nick and Jesus, on 09/26. Image Classification, Nick and Kenneth, on 10/03. Object Detection, John and Kenneth, on 10/17. Image Segmentation, Mujtaba and Matt, on 10/24. Face Detection, John and Amol, on 10/31. Face Verification, Mujtaba and Amol, on 11/07. GANs and Generative DL, Jakob and Matt, on 11/14. Provenance Analysis, Jakob and Jesus, on 12/05.   Each student will play the role of discussion leader twice along the course. Students will lead discussion in groups, preferably in pairs of one graduate and one undergraduate student. The graduate students are expected to help their undergraduate peers.\nDiscussion leaders will be responsible for organizing a 1.5-hour presentation of the topic of the day, resorting to slides, videos, and demonstrations. The instructor advises the discussion leaders to share their material with him a couple of days before the presentation day.\nDiscussion leaders will also receive the summaries of the articles and open questions related to their topics from the other students at least 5 days before their presentation.\nThe discussion and assignment topics coincide; as a consequence, discussion leaders are not required to provide summaries for the topics they will present.\n  Final Exam Date and Local: 12/12, 4:15 PM, 117 Cuneo Hall\nFormat: Oral Quiz\n Grading    Concept Point Interval Concept Point Interval Concept Point Interval Concept Point Interval     A [94, 100) B+ [88, 89] C+ [78, 79] D [60, 69]   A- [90, 93] B [84, 87] C [74, 77] F [0, 59]     B- [80, 83] C- [70, 73]      Distribution  Total: 100 points Class Presence and Participation: 6 points (x13) Assignments: 1 point (x8) Discussion Leadership: 3 points (x2) Final Exam: 8 points CV-on-the-news Post: 1 point (extra) Demonstration on Discussion Day: 5 points (extra) Late Assignments: -1 point per day   Each student has two \u0026ldquo;Oopsie\u0026rdquo; cards (OC), which will allow them to either avoid losing points because of absence or extend due dates until 12/11. They may use an OC at their discretion for any task, except for their assigned days of discussion leadership and final exam. Please let the instructor know you want to use your OC.\n  Useful Links Links useful to the course will be posted here.\n CV On the News News involving CV issues shared and discussed by the students and instructor will be posted here. \n References   LeCun, Y., Bengio, Y., Hinton, G. Deep learning. Nature 521 (1), 2015.\n  Hearst, M., Dumais, S., Osuna, E., Platt, J., Scholkopf, B. Support vector machines. IEEE Intelligent Systems and their Applications 13 (4), 1998.\n   Ho, T. The Random Subspace Method for Constructing Decision Forests. IEEE Transactions on Pattern Analysis and Machine Intelligence 20 (8), 1998.\n  Lowe, D. Distinctive Image Features from Scale-Invariant Keypoints. Springer International Journal of Computer Vision 60 (2), 2004.\n  Bay, H., Tuytelaars, T., Van Gool, L. SURF: Speeded Up Robust Features. Springer European Conference on Computer Vision (ECCV), 2006\n   Noh, H., Araujo, A., Sim, J., Weyand, T., Han, B. Large-Scale Image Retrieval with Attentive Deep Local Features. IEEE International Conference on Computer Vision (ICCV), 2016.\n  Jegou, H., Douze, M., Johnson, J. Faiss: A library for efficient similarity search. Available at https://bit.ly/3BiGYg9. Meta Platforms, Inc., 2017.\n  Brogan, J., Bharati, A., Moreira, D., Rocha, A., Bowyer, K., Flynn, P., Scheirer, W. Fast Local Spatial Verification for Feature-Agnostic Large-Scale Image Retrieval. IEEE Transactions on Image Processing 30 (1), 2021.\n  Wieschollek, P., Wang, O., Sorkine-Hornung, A., Lensch, H. Efficient large-scale approximate nearest neighbor search on the GPU. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.\n  Kalantidis, Y., Avrithis, Y. Locally Optimized Product Quantization for Approximate Nearest Neighbor Search. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014.\n  Jegou, H., Douze, M., Schmid, C. Product quantization for nearest neighbor search. IEEE Transactions on Pattern Analysis and Machine Intelligence 33 (1), 2010.\n  More soon\u0026hellip;\n   Academic Integrity Students are expected to adhere to the LUC statements on academic integrity available at https://bit.ly/3TmiQkQ. These policies fully apply to this course. The penalty for task-wise academic misconduct is zero points. Multiple events of misconduct will incur in failing the entire course (with an F grade). All cases of academic misconduct will be reported to the proper department offices.\n Accommodations Students who have disabilities and wish to request academic accommodations are advised to contact the Services for Students With Disabilities (SSWD) office at 773-508-3700 or SSWD@luc.edu as soon as possible. The SSWD office will provide accommodation letters that, once shared with the instructor, will be fully accommodated as per the terms of their content with no further questions.\n","date":1661472000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663124371,"objectID":"d7586ab04df07d71e034dcc85e28cf74","permalink":"https://danielmoreira.github.io/teaching/cvapp-aut22/","publishdate":"2022-08-26T00:00:00Z","relpermalink":"/teaching/cvapp-aut22/","section":"teaching","summary":"COMP 388-002 / COMP 488-002 Computer Science Topics","tags":["Teaching","Computer Vision"],"title":"Computer Vision Applications, Fall 2022","type":"teaching"},{"authors":["Sara Mandelli","Davide Cozzolino","Edoardo Cannas","Joao Cardenuto","Daniel Moreira","Paolo Bestagini","Walter Scheirer","Anderson Rocha","Luisa Verdoliva","Stefano Tubaro","Edward Delp"],"categories":null,"content":"","date":1653868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655000278,"objectID":"24dc52a6df753e3d2cc038090d9ca8f0","permalink":"https://danielmoreira.github.io/publication/2022_ieeeaccess/","publishdate":"2022-05-30T00:00:00Z","relpermalink":"/publication/2022_ieeeaccess/","section":"publication","summary":"2022 IEEE Access","tags":["Media Forensics","Scientific Integrity","GANs"],"title":"Forensic Analysis of Synthetically Generated Western Blot Images","type":"publication"},{"authors":["Daniel Moreira","William Theisen","Walter Scheirer","Aparna Bharati","Joel Brogan","Anderson Rocha"],"categories":null,"content":"","date":1648857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649109793,"objectID":"784c890c282381057c41d4e51f21e217","permalink":"https://danielmoreira.github.io/publication/2022_chapter/","publishdate":"2022-04-02T00:00:00Z","relpermalink":"/publication/2022_chapter/","section":"publication","summary":"2022 Springer Book Chapter","tags":["Media Forensics","Provenance Analysis","Provenance Filtering","Provenance Graph Construction","Image Clustering"],"title":"Image Provenance Analysis","type":"publication"},{"authors":null,"categories":null,"content":"    Details Course: CSE 40537 / 60537 Biometrics\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dhenriq1@nd.edu)\nTeaching Assistant: Jason You (syou@nd.edu)\nLectures: TUE and THR, 3:30 to 4:45 PM, 356A Fitzpatrick Hall\nOffice Hours: Daniel - MON to FRI, 5:00 to 6:00 PM, 182 Fitzpatrick Hall, Jason - WED, 1:00 to 2:00 PM, 150M Fitzpatrick Hall\nSlack: https://nd-biometrics-spr22.slack.com (now deactivated)\nPanopto: https://bit.ly/3A4QEKc\n Course grades are now available.\n  Progress  01/11/2022 - Syllabus, Course details. 01/13/2022 - Basics I, Biometrics, traits, and systems. 01/18/2022 - Basics II, Errors, metrics, and attacks. 01/20/2022 - Basics II (cont.), 1st Coding Class, Metrics. 01/25/2022 - Fingerprint Recog. I, History and features. 01/27/2022 - Fingerprint Recog. II, Acquisition and enhancement. 02/01/2022 - Fingerprint Recog. III, Minutiae detection. 02/03/2022 - Fingerprint Data Collection, password with instructor. 02/08/2022 - Iris Recog. I, Why irises and irises vs. other traits. 02/10/2022 - Iris Recog. II, Acquisition and enhancement. 02/15/2022 - Iris Recog. III, Description and matching. 02/17/2022 - 2nd Coding Class, Fingerprint recognition. 02/22/2022 - Iris Data Collection, password with instructor. 02/24/2022 - 3rd Coding Class, Iris recognition. 03/01/2022 - 1st Invited Talk, Dr. Andrey Kuehlkamp. 03/03/2022 - Midterm exam, grades. 03/08/2022 - Spring Break. 03/10/2022 - Spring Break. 03/15/2022 - Face Recog. I, Why faces and faces vs. other traits. 03/17/2022 - Face Recog. II, Acquisition and enhancement. 03/22/2022 - Face Recog. III, Description and matching. 03/24/2022 - Face Recog. IV, Deep learning face recognition. 03/29/2022 - 4th Coding Class, Face recognition. 03/31/2022 - Feature Indexing, Index building and feature querying. 04/05/2022 - Other Traits, Alternative traits and Soft Biometrics. 04/07/2022 - Multibiometrics, Data fusion. 04/12/2022 - 2nd Invited Talk, Mr. Aidan Boyd. 04/14/2022 - Fingerprint presentation attack day. 04/19/2022 - Iris and face presentation attack day. 04/21/2022 - Grad students\u0026rsquo; signature recog. and gender from iris. 05/05/2022 - Final exam, grades.   Assignments  01/20/2022 - 1st assignment, good answers, grades. 02/22/2022 - 2nd assignment, good answers, grades. 03/15/2022 - 3rd assignment, good answers, grades. 04/04/2022 - 4th assignment, good answers, grades.   Important Dates  01/28/2022 - 1st assignment due date. 02/03/2022 - Fingerprint data collection. 02/22/2022 - Iris data collection. 03/01/2022 - Dr. Andrey Kuehlkamp’s talk. 03/03/2022 - Midterm exam. 03/04/2022 - 2nd assignment due date. 03/25/2022 - 3rd assignment due date. 04/12/2022 - Mr. Aidan Boyd\u0026rsquo;s talk. 04/14/2022 - Fingerprint presentation attack day. 04/18/2022 - 4th assignment due date. 04/19/2022 - Iris and face presentation attack day. 04/21/2022 - Grad students\u0026rsquo; final report presentation. 05/05/2022 - Final exam, 10:30 to 12:30 PM, 356A Fitzpatrick Hall.   \nInvited Talks           Dr. Andrey Kuehlkamp Postdoctoral Research Associate at the Center for Research Computing, University of Notre Dame            Diverse Aspects in Advancing Iris Recognition Systems Are we ready for widespread, mass-scale adoption of iris recognition systems? Following the miniaturization of fingerprint scanners, these have dominated recognition systems and have even become almost commonplace for unlocking cell phones, but what if in the not-so-far-off future they were replaced with iris scanners, would you be comfortable with it? Since its initial introduction in 1993, automated iris recognition has dramatically grown in popularity and soon could become the dominant method for automated recognition. Take for example the largest recognition system in the world \u0026mdash; India’s Aadhaar program \u0026mdash; which has collected more than 1.1 billion irises from their citizens to be used as the primary identification for banking, pensions, and welfare programs. Even more recently \u0026mdash; in 2017 \u0026mdash; Somaliland became the first country in the world to use iris recognition as the means for identification in a public election, which had more than 800,000 registered voters. Although a mature technology in many regards, the drastic increase in iris recognition adoption has revealed many opportunities for improvement. In this talk I present an overview of my research, which focuses on improving iris recognition in three ways: speed, accuracy, and robustness.               Mr. Aidan Boyd Ph.D. Candidate at the Department of Computer Science and Engineering, University of Notre Dame            Using human perception to train better CNNs Traditional deep learning is a data-driven process. Images are shown to a CNN and it is expected to learn rules that enable it to perform a task efficiently on new unseen images after training. The problem with this approach is that the model can only learn from the supplied training data. Potentially, this training data is not representative of the entire domain. Although the model classifies training images near perfectly, this learned rule may actually just be coincidental to this data, rather than applying to all images in that task. Additionally, the decision making of these models can be ambiguous and not explainable, meaning it can be difficult to trust the classifications. Humans, however, possess great ability to generalize what they have seen in the past and apply it to the current task. Humans don’t focus on incidental features in data, instead we tend to look at more obvious occurrences that can be easily explained.  This talk will cover two of my recent works where we investigated whether the incorporation of human perception into the training of deep learning models results in better performance on unseen data. Each of these works approach this in different ways, both showing promising results. In the second work, we also investigate whether the models we have trained in this way are more “human-like” in their decision making. These approaches are applied to the domains of iris presentation attack detection and synthetically generated face detection (see www.thispersondoesnotexist.com for examples of synthetically generated faces).     Grading    Concept Point interval Concept Point interval Concept Point interval Concept Point interval     A [94, 100) B+ [88, 89] C+ [78, 79] D [60, 69]   A- [90, 93] B [84, 87] C [74, 77] F [0, 59]     B- [80, 83] C- [70, 73]      Distribution  Total: 100 points Assignments: 10 points (x4) Presentation attack detection report: 20 points Midterm exam: 20 points Final exam: 20 points Late assignments: -1 point per day   Final project grades.\n  Links  Classroom recording notification. Yale face dataset, used in the 4th assignment.   Biometrics on the News Posted by the students and instructor on Slack:\n  https://fortune.com/2021/10/22/crypto-worldcoin-cryptocurrency-eye-scan-biometrics-orb/\n  https://www.biometricupdate.com/202201/attacks-countermeasures-and-pulses-of-blood-in-remote-identity-proofing\n  https://www.yahoo.com/news/irs-wants-scan-face-171738919.html?.tsrc=fp_deeplink\n  https://www.irs.gov/newsroom/irs-announces-transition-away-from-use-of-third-party-verification-involving-facial-recognition\n  https://www.nytimes.com/2022/02/14/technology/texas-facebook-facial-recognition-lawsuit.html\n  https://abcnews.go.com/GMA/Living/video/hyper-realistic-face-masks-optical-illusions-needed-71835222\n  https://www.newscientist.com/article/2114900-concerns-as-face-recognition-tech-used-to-identify-criminals/\n  https://www.yahoo.com/news/ukraine-using-facial-recognition-tech-153640828.html\n  https://www.nytimes.com/2022/04/07/technology/facial-recognition-ukraine-clearview.html\n  https://www.washingtonpost.com/technology/2022/04/15/ukraine-facial-recognition-warfare/\n  https://www.biometricupdate.com/202204/biometrics-secure-unhcr-direct-cash-payments-to-ukrainian-refugees\n  https://www.theverge.com/22672123/ai-voice-clone-synthesis-deepfake-applications-vergecast\n  https://www.biometricupdate.com/202204/ny-state-audit-finds-bidding-for-school-facial-recognition-system-was-improper\n  https://www.biometricupdate.com/202204/suprema-face-biometrics-enable-uk-school-to-cut-back-plastic-waste-from-access-cards\n  https://techcrunch.com/2022/04/18/web-scraping-legal-court/\n   ","date":1641600000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661661604,"objectID":"24aadea06c79d658adaf71213f4263b5","permalink":"https://danielmoreira.github.io/teaching/biometrics-spr22/","publishdate":"2022-01-08T00:00:00Z","relpermalink":"/teaching/biometrics-spr22/","section":"teaching","summary":"CSE 40537 / 60537 Biometrics","tags":["Teaching","Biometrics","Fingerprint Recognition","Iris Recognition","Face Recognition"],"title":"Biometrics, Spring 2022","type":"teaching"},{"authors":["Joel Brogan","Aparna Bharati","Daniel Moreira","Anderson Rocha","Kevin Bowyer","Patrick Flynn","Walter Scheirer"],"categories":null,"content":"","date":1626825600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628821022,"objectID":"1642d311553b4e54a6fcfd9c43414f13","permalink":"https://danielmoreira.github.io/publication/2021_tip/","publishdate":"2021-07-21T00:00:00Z","relpermalink":"/publication/2021_tip/","section":"publication","summary":"2021 IEEE Transactions on Image Processing","tags":["CBIR","Media Forensics","Provenance Analysis","Provenance Filtering"],"title":"Fast Local Spatial Verification for Feature-Agnostic Large-Scale Image Retrieval","type":"publication"},{"authors":null,"categories":null,"content":"Status: Ongoing, Funded by: DARPA\nThe Semantic Forensics research project (SemaFor) is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA), whose goal is to leverage forensic tools to perform the detection of the existence, atribution of the authorship, and characterization of the intention of manipulated digital media.\nWorking together with the Universities of Purdue, Siena, Campinas (Unicamp), Naples Federico II, and the Politécnico di Milano, our team leads the development of solutions to the problem of digital document analysis (such as scientific papers, news articles, patents, grants, etc.). By combining ideas from the topics of image retrieval, digital image forensics, natural language processing, and deep learning, we aim at proposing multimodal methods to spot semantic inconsistencies within the content of documents.\nResearch Team  Prof. Walter Scheirer (PI) Prof. Anderson Rocha (PI) Prof. Kevin Bowyer (PI) Prof. Tim Weninger (PI) Prof. Daniel Moreira (PI) William Theisen (PhD Student) Trenton Ford (PhD Student) Rosaura VidalMata (PhD Student) Priscila Saboia Moreira (PhD Student) João P. Cardenuto (PhD Student)  ","date":1622678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628821022,"objectID":"0637272bead5fc08c94ecba1be402dcf","permalink":"https://danielmoreira.github.io/project/semafor/","publishdate":"2021-06-03T00:00:00Z","relpermalink":"/project/semafor/","section":"project","summary":"Semantic analysis of digital documents to support forensics.","tags":["Semantic Forensics","Document Analysis"],"title":"SemaFor","type":"project"},{"authors":null,"categories":null,"content":"Status: Ongoing, Funded by: DARPA\nThe Scientific Integrity (Sci-Int) project is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA), whose goal is to develop solutions to identify misconduct in scientific research through the detection of image tampering in scientific papers.\nWorking together with the Universities of Purdue, South California (USC), Campinas (Unicamp), Naples Federico II, and the Politécnico di Milano, our team leads the development of techniques to (1) rule out false positive cases of misidentified misconduct, and to (2) better report and document misconduct practices in retraction notices.\nTo accomplish item (1), we plan to perform semantic analyses of the suspect paper cases, in order to identify situations in which duplications or manipulations of content were made with fair scientific purpose (e.g., to visually highlight or to better explain previous results). To do that, we plan to use natural language processing to perform basic automated paper text and image caption interpretation.\nTo accomplish item (2), we plan to rely on techniques of Provenance Graph Construction to present better explanations of how problematic images relate to each other, and how they share content across different papers.\nResearch Team  Prof. Walter Scheirer (PI) Prof. Anderson Rocha (PI) Prof. Kevin Bowyer (PI) Prof. Daniel Moreira (PI) João P. Cardenuto (PhD Student)  ","date":1622592000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628821022,"objectID":"a9d89a042b5261f9823062ae35a22cef","permalink":"https://danielmoreira.github.io/project/sciint/","publishdate":"2021-06-02T00:00:00Z","relpermalink":"/project/sciint/","section":"project","summary":"Assessment of scientific research integrity through the detection of image tampering in scientific papers.","tags":["Media Forensics","Image Manipulation Detection","Provenance Analysis","Natural Language Processing"],"title":"Sci-Int","type":"project"},{"authors":["William Theisen","Joel Brogan","Pamela Bilo Thomas","Daniel Moreira","Pascal Phoa","Tim Weninger","Walter Scheirer"],"categories":null,"content":"","date":1621641600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649109793,"objectID":"fe3c7fb8d0ddb8e792d99fcbf0529350","permalink":"https://danielmoreira.github.io/publication/2021_icwsm/","publishdate":"2021-05-22T00:00:00Z","relpermalink":"/publication/2021_icwsm/","section":"publication","summary":"2021 AAAI International Conference on Web and Social Media","tags":["Meme Genres","Politics","Image Clustering"],"title":"Automatic Discovery of Political Meme Genres with Diverse Appearances","type":"publication"},{"authors":["Aparna Bharati","Daniel Moreira","Patrick Flynn","Anderson Rocha","Kevin Bowyer","Walter Scheirer"],"categories":null,"content":"","date":1610064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628821022,"objectID":"f69605846e42c0b40155436fcc83a1ab","permalink":"https://danielmoreira.github.io/publication/2021_tifs/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/publication/2021_tifs/","section":"publication","summary":"2021 IEEE Transactions on Information Forensics and Security","tags":["Deep Learning","Media Forensics","Provenance Analysis","Provenance Graph Construction"],"title":"Transformation-Aware Embeddings for Image Provenance","type":"publication"},{"authors":null,"categories":null,"content":"    Details Course: CSE 40537 / 60537 Biometrics\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dhenriq1@nd.edu)\nLectures: TUE and THR, 5:05 to 6:20 PM, 125 DeBartolo Hall1\nOffice Hours: MON and WED, 2:00 to 4:00 PM, 150N Fitzpatrick Hall1 Lectures: TUE and THR, 2:00 to 3:15 PM, at Zoom1\nOffice Hours: TUE and THR, 5:05 to 6:20 PM, at Zoom1\nStudents are not obligated to attend classes at 2:00 pm, but are certainly welcome. All classes are being recorded with Panopto.\nSlack: https://cse-biometrics-spr20.slack.com (now deactivated) Panopto: https://bit.ly/33ZkU97\nZoom: https://notredame.zoom.us/my/dmoreira\nCourse grades are now available.  Progress  01/14/2020 - Syllabus, Course details. 01/16/2020 - Basics I, Biometrics, traits, and systems. 01/21/2020 - Basics II, Errors, metrics, and attacks. 01/23/2020 - 1st Coding Class, Implementation of metrics. 01/28/2020 - Fingerprint Recog. I, History and features. 01/30/2020 - Fingerprint Recog. II, Acquisition and enhancement. 02/04/2020 - Fingerprint Recog. III, Minutiae detection. 02/06/2020 - Fingerprint Data Collection, password with instructor. 02/11/2020 - 2nd Coding Class, Minutiae-based recognition. 02/13/2020 - 2nd Coding Class, continuation. 02/18/2020 - Face Recog. I, Why faces and faces vs. fingerprints. 02/20/2020 - Face Recog. II, Acquisition and enhancement. 02/25/2020 - Face Recog. III, Description and matching. 02/27/2020 - 3rd Coding Class, Face recognition. 03/03/2020 - Fingerprints assignment, Developers\u0026rsquo; day. 03/05/2020 - Fingerprints assignment, Attackers\u0026rsquo; day. 03/10/2020 - Spring Break. 03/12/2020 - Spring Break. 03/17/2020 - Extended Spring Break1. 03/18/2020 - Extended Spring Break1. 03/24/2020 - New Course Directions1. 03/26/2020 - Iris Recog. I, Why irises and irises vs. other traits. 03/31/2020 - Iris Recog. II, Acquisition and enhancement. 04/02/2020 - Iris Recog. III, Description and matching. 04/07/2020 - 4th Coding Class, Iris recognition. 04/09/2020 - Multibiometrics, Other traits, data fusion. 04/14/2020 - 1st Invited Talk, Dr. Andrey Kuehlkamp. 04/16/2020 - 2nd Invited Talk, Dr. Adam Czajka. 04/21/2020 - Faces assignment, Developers\u0026rsquo; day. 04/23/2020 - Irises assignment, Developers\u0026rsquo; day. 04/28/2020 - Assignment Report due date. 05/04/2020 - Final exam, see grades.   Important Dates  03/03/2020 - Fingerprints assignment, Developers\u0026rsquo; day. 03/05/2020 - Fingerprints assignment, Attackers\u0026rsquo; day. 03/31/2020 - Faces assignment, Developers\u0026rsquo; day.1 04/02/2020 - Faces assignment, Attackers\u0026rsquo; day.1 04/14/2020 - Irises assignment, Developers\u0026rsquo; day.1 04/16/2020 - Irises assignment, Attackers\u0026rsquo; day.1 04/28/2020 - Last assignment, Collaboration day.1 04/14/2020 (5:05 PM at Zoom) - Dr. Andrey Kuehlkamp\u0026rsquo;s talk. 04/16/2020 (5:05 PM at Zoom) - Dr. Adam Czajka\u0026rsquo;s talk. 04/21/2020 - Faces assignment, Developers\u0026rsquo; day1. 04/23/2020 - Irises assignment, Developers\u0026rsquo; day1. 04/28/2020 - Final Report due date1. 05/04/2020 - Final exam.   \nInvited Talks           Dr. Andrey Kuehlkamp Postdoctoral Research Associate at the Center for Research Computing, University of Notre Dame            Diverse Aspects in Advancing Iris Recognition Systems Are we ready for widespread, mass-scale adoption of iris recognition systems? Following the miniaturization of fingerprint scanners, these have dominated recognition systems and have even become almost commonplace for unlocking cell phones, but what if in the not-so-far-off future they were replaced with iris scanners, would you be comfortable with it? Since its initial introduction in 1993, automated iris recognition has dramatically grown in popularity and soon could become the dominant method for automated recognition. Take for example the largest recognition system in the world \u0026mdash; India’s Aadhaar program \u0026mdash; which has collected more than 1.1 billion irises from their citizens to be used as the primary identification for banking, pensions, and welfare programs. Even more recently \u0026mdash; November 2017 \u0026mdash; Somaliland became the first country in the world to use iris recognition as the means for identification in a public election, which had more than 800,000 registered voters. Although a mature technology in many regards, the drastic increase in iris recognition adoption has revealed many opportunities for improvement. In this talk I present an overview of my research, which focuses on improving iris recognition in three ways: speed, accuracy, and robustness.               Dr. Adam Czajka Assistant Professor at the Department of Computer Science and Engineering, University of Notre Dame            Is this eye alive or artificial? Oh wait, maybe it’s dead? Detection of unknown presentation attacks in biometrics. Presentation attacks are those physical presentations to a biometric system that aim at driving it into an incorrect decision. Rediscovered recently in general computer vision community (and raising a significant interest; look \u0026mdash; for instance \u0026mdash; for famous stop sign attacks on deep learning-based object detection models), these attacks are known in biometrics for several decades. In this talk, I will use iris recognition as an example and will present the huge creativity of attackers in using various artifacts (printouts, patterned contact lenses, plastic eyes, GAN-generated fakes and\u0026hellip; dead eyes) to spoof a system. Although training a model to recognize each of these presentation attack instruments is relatively easy and works well, a big challenge now is how to build models that generalize onto unknown attack types, going beyond our understanding of attackers’ creativity when training our models. I will present a few methods we are exploring in our research to provide presentation attack detection methods that perform promisingly in open-set classification scenario.     Links  Classroom recording notification. Yale face dataset,  used to replace face acquisition1. CASIA-IrisV1,  used to replace iris acquisition1.   Biometrics on the News Posted by the students the instructor on Slack:\n  https://vancouversun.com/news/local-news/biometric-opioid-vending-machine-unveiled-in-vancouver\n  https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html\n  https://www.landmobile.co.uk/news/metropolitan-police-service-nec-live-facial-recognition/\n  https://www.nytimes.com/2020/01/20/opinion/facial-recognition-ban-privacy.html\n  https://www.biometricupdate.com/202001/securiport-partners-with-university-of-notre-dame-in-biometrics-and-data-analytics-research-for-border-security\n  https://www.nytimes.com/2020/02/06/business/facial-recognition-schools.html\n  https://www.abacusnews.com/tech/why-your-palm-could-be-safer-fingerprints-or-facial-recognition/article/3046162\n  https://www.cnn.com/2020/02/26/tech/clearview-ai-hack/index.html\n  https://nakedsecurity.sophos.com/2020/04/08/as-if-the-world-couldnt-get-any-weirder-this-ai-toilet-scans-your-anus-to-identify-you/\n  https://arstechnica.com/information-technology/2020/04/attackers-can-bypass-fingerprint-authentication-with-an-80-success-rate/ \n   COVID-19 1: Modified/canceled due to COVID-19.\n Acknowledgments This course is heavily based on Dr. Adam Czajka\u0026rsquo;s and Dr. Walter Scheirer\u0026rsquo;s previous Biometrics courses. I sincerely thank them for kindly allowing me to rely upon their materials.\n ","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661661954,"objectID":"121fb4f8057a9a39884ee21fcdbea52e","permalink":"https://danielmoreira.github.io/teaching/biometrics-spr20/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/teaching/biometrics-spr20/","section":"teaching","summary":"CSE 40537 / 60537 Biometrics","tags":["Teaching","Biometrics","Fingerprint Recognition","Face Recognition","Iris Recognition"],"title":"Biometrics, Spring 2020","type":"teaching"},{"authors":null,"categories":null,"content":"One of the things I worry about while doing my research is how to drive it towards building a better society. Although the concept of a better society may differ from one culture to the other, I believe any society gets better whenever all of its members experience more freedom to enjoy their rights.\nAmong the untold manners technology can be used to breach people\u0026rsquo;s rights, five flaws in the way we are doing informatics get my attention. Devices and programs usually suffer from (1) lack of safety, (2) lack of trustworthiness, (3) lack of privacy, (4) ignorance of diversity, and (5) lack of accountability. Not unintentionally, the projects I\u0026rsquo;ve been contributing to in the past few years tackle one or more of these issues.\nSafety    From the many ways safety can be harmed by technology, the improper dissemination of sensitive content (such as pornography or violence), to inadequate audiences (such as kids or unwary spectators), gained my attention while I was developing my PhD, under the supervision of prof. Anderson Rocha (who generously proposed the topic).\nWith the popularity and pervasiveness of online video streams, sensitive scenes depicting suicide, murder, and even rape have been broadcasted on the Internet, raising questions about the safety of these services. Aware of this situation, Samsung has funded us to focus on the development of solutions to detect sensitive video. Rather than aiming at denouncing or morally condemning the lawful consumers of certain types of sensitive content, our intent has always been to support the implementation of filtering and warning features that would make player systems safer (especially in the case of child spectators).\nI\u0026rsquo;ve had the chance to tackle the lack of safety in video streaming systems through the SMA project.\nTrustworthiness   In the era of misinformation and fake news, there is a symptomatic undermining of trust not only in textual but also in visual information. People are conscious of the existence of image editing software (e.g., Photoshop), with which even unskilled users can easily fabricate and manipulate pictures. Although many of these manipulations have benign purposes (no, there is nothing wrong with your memes), some contents are generated with malicious intents, such as general public deception and propaganda.\nThe lack of available solutions to assess the integrity of images and videos allows adversarial manipulated data to have a negative impact on the way people relate to each other on the Internet. They don\u0026rsquo;t know what to believe or whom to trust anymore. In addition, fraudulent images represent a challenge even for the scientific community. Aware of this scenario, DARPA has been funding us, at CVRL, to conduct research on the development of tools to verify the integrity of digital images.\nI\u0026rsquo;m having the chance to tackle the lack of trustworthiness in visual media systems through the MediFor and Sci-Int projects.\nPrivacy and Diversity   With the advent of deep learning and the necessity for large datasets, visual data collection has become an important step of Computer Vision and Machine Learning research. Due to the popularity of image and video capture devices (such as digital cameras, smartphones, dash cams, etc.), large datasets can now be quickly generated. Nevertheless, a major question that stands out in such a process is how to protect the privacy of people who are eventually being recorded. Imagine, for example, a dash cam that is collecting road data for a self-driving car project. In a major city, plenty of people will certainly be captured in the footages, and it is very unlikely that one will be able to obtain image rights for each individual.\nInterested in such issue, we, at CVRL, investigate the generation of realistic synthetic faces, whose identities do not belong to a real existing person, hence avoiding privacy breaches. The idea is to de-identify the recorded individuals, by replacing their faces with synthetic assets.\n   In addition, collected data may be biased, due to a lack of diversity in the captured individuals. Consider, for instance, training video footages collected in China. It is very unlikely that black people will be represented in such a dataset.\nLimitations of this nature comprise what I call ignorance of diversity and are the potential cause of many technological failures in the presence of underrepresented groups. Unfortunately, glitches like these may go beyond the technological aspects and prejudice the rights of equality in face of diversity. To cope with this problem, similar to the privacy protection strategy, synthetic identities can be used to diversify the recorded individuals by performing face replacement, providing controlled variation of not only ethnicity but also of age and of gender.\nI\u0026rsquo;m having the chance to tackle the lack of privacy and ignorance of diversity in image and video datasets through the SREFV project.\nAccountability   People have the right to understand in details the decisions made about them by algorithms belonging to either government or industry. This is fundamental to give them the possibility of questioning determinations and defending against resolutions that might be the outcome of incorrect, rigged, or even bogus computations. In this context, accountability becomes a relevant concept, since it comprises the property of an automated decision system to be fair, transparent, and explainable to human beings. As a consequence, the more accountable a system is, the more audit power it gives to people.\nWithin the field of Biometrics, traditional iris recognition solutions are well known for constituting very reliable methods of identity verification. Nevertheless, since they are not human-friendly enough to convince people who do not possess image processing expertise, their usage before a jury in courts of law is usually avoided. Aware of this limitation, Prof. Adam Czajka has started at CVRL the investigation of human-intelligible iris matching strategies.\nI\u0026rsquo;m having the chance to tackle the lack of accountability in iris recognition algorithms through the TSHEPII project.\nKeep pushing    Although the aforementioned efforts may seem minuscule in face of the size of the challenge of building a better society, I try to calm myself down by making a parallel to the explanation of Prof. Matt Might on how the human knowledge increases with the progress of scientific research. As he advises, I keep pushing.\n","date":1560384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564694632,"objectID":"07602f928b69d804bda2d657c4b532e7","permalink":"https://danielmoreira.github.io/post/bettersoc/","publishdate":"2019-06-13T00:00:00Z","relpermalink":"/post/bettersoc/","section":"post","summary":"What does a better society mean?","tags":["Random Thoughts"],"title":"A Better Society","type":"post"},{"authors":null,"categories":null,"content":"Status: Concluded, Funded by: DARPA\nAdvisor: Prof. Walter Scheirer\nThe Media Forensics research project (MediFor) is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA) and the Air Force Research Laboratory (AFRL), whose goal is to develop solutions for the automated assessment of the integrity of digital images.\nWorking together with the Universities of Purdue, South California (USC), New York (NYU), Siena, Campinas (Unicamp), and the Politécnico di Milano, our team leads the development of solutions to the problem of Provenance Analysis. Given a questioned image, namely a probe, and a large corpus of images (such as the Internet), Provenance Analysis aims at two major tasks:\n  Finding the images that directly and transitively share content with the probe (a task we call Provenance Filtering).\n  Building the directed acyclic graph whose nodes individually represent the probe and related images, and whose edges express the edition and content-donation history (e.g., cropping, blurring, removal, splicing, etc.) between pairs of images, linking seminal to generated elements (a task we call Provenance Graph Construction).\n     By combining ideas from the areas of image retrieval, digital image forensics, and graph theory, Provenance Analysis constitutes an interesting interdisciplinary topic that spans the fields of image processing and computer vision.\nResearch Team  Prof. Walter Scheirer (PI) Prof. Anderson Rocha (PI) Prof. Kevin Bowyer (PI) Prof. Patrick Flynn (PI) Daniel Moreira (Postdoc) Aparna Bharati (PhD Student) Joel Brogan (PhD Student) Allan Pinto (PhD Student) Michael Parowski (Undergrad Student) Patricia Hale (Undergrad Student) William Badart (Undergrad Student)  ","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596902014,"objectID":"2ce2b93ee954a04842b88663b1a80847","permalink":"https://danielmoreira.github.io/project/medifor/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/project/medifor/","section":"project","summary":"Integrity assessment of digital images through content provenance analysis.","tags":["Media Forensics","Provenance Analysis","Provenance Filtering","Provenance Graph Construction"],"title":"MediFor","type":"project"},{"authors":null,"categories":null,"content":"Status: Concluded\nAdvisor: Prof. Patrick Flynn\nThe SREFV project aims at extending prior research on synthesis of realistic faces, to support the generation of videos containing animated faces with synthetic identities, depicted either frontally or in varying poses.\nBesides the obvious artistic and entertainment purposes, the outcome of this project will constitute an interesting tool to de-identify and diversify the faces depicted in video training datasets, helping to protect the identity of volunteers, and to mitigate eventual age, gender, and ethnic dataset collection biases.\nResearch Team  Prof. Patrick Flynn (PI) Prof. Kevin Bowyer (PI) Prof. Adam Czajka (PI) Prof. Walter Scheirer (PI) Daniel Moreira (Postdoc) Sandipan Banerjee (PhD Student)  ","date":1559260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596902014,"objectID":"537f8411954a4c4c6b9bc998a07a6d40","permalink":"https://danielmoreira.github.io/project/srefv/","publishdate":"2019-05-31T00:00:00Z","relpermalink":"/project/srefv/","section":"project","summary":"Synthesis of Realistic Example Face Videos.","tags":["Face Synthesis","Identity Synthesis","Video Synthesis","Biometrics"],"title":"SREFV","type":"project"},{"authors":null,"categories":null,"content":"Status: Concluded\nAdvisor: Prof. Adam Czajka\nThe TSHEPII project aims at developing a software tool to support the human examination of post-mortem iris images. The tool puts together diverse computer vision techniques to automatically process, extract, annotate, and match iris regions from two different eye captures. The idea is to give to the user enough iris texture matching and non-matching information, so they can decided if the two given images depict the same eye or not.\n   The video above depicts a demo of the TSHEPII tool, with all the computer vision techniques added to the software. As the project name suggests (Tool Supporting the Human Examination of Post-Mortem Iris Images), the tool is particularly tuned to the case of comparing post-mortem irises, which, contrary to the common sense, might still be useful for performing iris recognition.\nResearch Team  Prof. Adam Czajka (PI) Prof. Patrick Flynn (PI) Prof. Kevin Bowyer (PI) Daniel Moreira (Postdoc) Mateusz Trokielewicz (PhD Student) M.D. Piotr Maciejewicz (Collaborator)  ","date":1559088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596902014,"objectID":"6e56f34183b51fc8d0f9e6ff96491f5d","permalink":"https://danielmoreira.github.io/project/tshepii/","publishdate":"2019-05-29T00:00:00Z","relpermalink":"/project/tshepii/","section":"project","summary":"Tool Supporting the Human Examination of Post-Mortem Iris Images.","tags":["Iris Recognition","Post-Mortem Iris Recognition","Biometrics"],"title":"TSHEPII","type":"project"},{"authors":null,"categories":null,"content":"   About Temporal Robust Features (TRoF) comprise a spatiotemporal video content detector and a descriptor developed to present low-memory footprint and small runtime. It was shown to be effective for the tasks of pornography and violence detection. Please refer to both articles for further technical details.\n Usage TRoF executable is available through a docker image, available here. Prior to running it, you have to install docker (available for various OS platforms). Once docker is running, you have to execute the following scripts, in command line:\nyour-computer$ docker run -ti dmoreira/trof bash docker-instance# cd TRoF docker-instance# ./fast_trof_descriptor Follow the printed usage instructions for running TRoF. The software reads a video input file and outputs float feature vectors, one per line, in the following format:\nx y t v1 v2 v3 ... vn Pleaser refer to either here or here, if you want to add videos to a running TRoF docker instance.\n Citation If you are using TRoF, please cite:\n@article{moreira2016fsi, title = {Pornography classification: the hidden clues in video space-time}, author={Daniel Moreira and Sandra Avila and Mauricio Perez and Daniel Moraes and Vanessa Testoni and Eduardo Valle and Siome Goldenstein and Anderson Rocha}, journal = {Elsevier Forensic Science International}, year = {2016}, volume = {268}, number = {1}, pages = {46--61} }  Disclaimer This software is provided by the authors as is, with no warranties and no support, for academic purposes only. The authors assume no responsibility or liability for the use of the software. They do not convey any license or title under any patent or copyright, and they reserve the right to make changes in the software without notification.\n Acknowledgments This software was developed through the project \u0026ldquo;Sensitive Media Analysis\u0026rdquo;, sponsored by Samsung Eletronica da Amazonia Ltda., in the framework of Brazilian law N. 815 8,248/91. We thank the financial support of the Brazilian Council for Scientific and Technological Development - CNPq (Grants #477662/2013-7, #304472/2015-8), the Sao Paulo Research Foundation - Fapesp (DejaVu Grant #2015/19222-9), and the Coordination for the Improvement of Higher Level Education Personnel - CAPES (DeepEyes project).\n","date":1559001600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660343955,"objectID":"1de616391e830170d5282040d55a25f9","permalink":"https://danielmoreira.github.io/project/trof/","publishdate":"2019-05-28T00:00:00Z","relpermalink":"/project/trof/","section":"project","summary":"Temporal Robust Features, a fast spatiotemporal video content detector and descriptor.","tags":["Video Description","TRoF"],"title":"TRoF","type":"project"},{"authors":null,"categories":null,"content":"Status: Concluded, Funded by: Samsung Eletrônica da Amazônia Ltda.\nAdvisor: Prof. Anderson Rocha\nThe Sensitive Media Analysis (SMA) project aims at researching solutions to combine different and complementary data representations and pattern classifiers for detecting sensitive content in digital images and videos.\nSensitive media can be defined as the digital content whose depiction to particular audiences (e.g., children or unwary spectators), at particular places (e.g., at work, at school, in the church) may inflict harm (e.g., trauma, shock, or fear) due to its inappropriateness. Typical representatives include – but are not limited to – scenes depicting pornography and violence, animal cruelty and child abuse, hate speech, etc.\nThe innovation aspects of the project reside on the development of solutions that are amenable to deployment on mobile devices (e.g., smartphones and tablets), observing their constraints of memory footprint, processing power, and runtime responsiveness.\nResearch Team  Prof. Anderson Rocha (PI) Prof. Siome Goldenstein (PI) Prof. Eduardo Valle (PI) Dr. Vanessa Testoni (Samsung Collaborator) Dr. Sandra Avila (Postdoc) Daniel Moreira (PhD Student) Mauricio Perez (MSc Student) Daniel Moraes (Programmer)  ","date":1558915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560488561,"objectID":"8c202c01c9c0cb8865f1f79d879ccdda","permalink":"https://danielmoreira.github.io/project/sma/","publishdate":"2019-05-27T00:00:00Z","relpermalink":"/project/sma/","section":"project","summary":"Sensitive Media Analysis through the detection and localization of sensitive video content.","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection"],"title":"SMA","type":"project"},{"authors":["Sandra Avila","Daniel Moreira","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1548720000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560488561,"objectID":"d5edbd8365c7dddf14bb76b8cdcce3f6","permalink":"https://danielmoreira.github.io/publication/2019_patent/","publishdate":"2019-01-29T00:00:00Z","relpermalink":"/publication/2019_patent/","section":"publication","summary":"2019 US Patent Office","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection","Multimodal Data Fusion"],"title":"Multimodal and real-time method for filtering sensitive media","type":"publication"},{"authors":["Aparna Bharati","Daniel Moreira","Joel Brogan","Patricia Hale","Kevin Bowyer","Patrick Flynn","Anderson Rocha","Walter Scheirer"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"cec704dbc02dcdd4772cdada6dabda4f","permalink":"https://danielmoreira.github.io/publication/2019_wacv_metada/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/2019_wacv_metada/","section":"publication","summary":"2019 IEEE Winter Conference on Applications of Computer Vision","tags":["Media Forensics","Provenance Analysis","Provenance Graph Construction"],"title":"Beyond Pixels: Image Provenance Analysis Leveraging Metadata","type":"publication"},{"authors":["Adam Czajka","Daniel Moreira","Kevin Bowyer","Patrick Flynn"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"8dbd380984ae361a7a51034f1a7fe26c","permalink":"https://danielmoreira.github.io/publication/2019_wacv_bsif/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/2019_wacv_bsif/","section":"publication","summary":"2019 IEEE Winter Conference on Applications of Computer Vision","tags":["Iris Recognition","BSIF","Biometrics"],"title":"Domain-Specific Human-Inspired Binarized Statistical Image Features for Iris Recognition","type":"publication"},{"authors":["Daniel Moreira","Mateusz Trokielewicz","Adam Czajka","Kevin Bowyer","Patrick Flynn"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"fba13bfc64b4a1351fe20af6d9bb8a78","permalink":"https://danielmoreira.github.io/publication/2019_wacv_human/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/2019_wacv_human/","section":"publication","summary":"2019 IEEE Winter Conference on Applications of Computer Vision","tags":["Iris Recognition","Human Performance","Biometrics"],"title":"Performance of Humans in Iris Recognition: The Impact of Iris Condition and Annotation-Driven Verification","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"841df25d6df2414cfad507adb08dbab6","permalink":"https://danielmoreira.github.io/publication/2019_if/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/2019_if/","section":"publication","summary":"2019 Elsevier Information Fusion","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection","Multimodal Data Fusion"],"title":"Multimodal data fusion for sensitive scene localization","type":"publication"},{"authors":["Daniel Moreira","Aparna Bharati","Joel Brogan","Allan Pinto","Michael Parowski","Kevin Bowyer","Patrick Flynn","Anderson Rocha","Walter Scheirer"],"categories":null,"content":"","date":1534377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"4b2f08ef5a215cbc816e2d78b1acc987","permalink":"https://danielmoreira.github.io/publication/2018_tip/","publishdate":"2018-08-16T00:00:00Z","relpermalink":"/publication/2018_tip/","section":"publication","summary":"2018 IEEE Transactions on Image Processing","tags":["CBIR","Media Forensics","Provenance Analysis","Provenance Filtering","Provenance Graph Construction"],"title":"Image Provenance Analysis at Scale","type":"publication"},{"authors":["Nathaniel Blanchard","Daniel Moreira","Aparna Bharati","Walter Scheirer"],"categories":null,"content":"","date":1532044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"02bff565c8b8a0844a62c8358bf0b176","permalink":"https://danielmoreira.github.io/publication/2018_acl/","publishdate":"2018-07-20T00:00:00Z","relpermalink":"/publication/2018_acl/","section":"publication","summary":"2018 ACL Grand Challenge and Workshop on Human Multimodal Language","tags":["Sentiment Classification","Multimodal Data Fusion"],"title":"Getting the subtext without the text: Scalable multimodal sentiment classification from visual and acoustic modalities","type":"publication"},{"authors":["Sandra Avila","Daniel Moreira","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1507593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560488561,"objectID":"d081d8e219b281b95d7d562e0344c762","permalink":"https://danielmoreira.github.io/publication/2017_patent/","publishdate":"2017-10-10T00:00:00Z","relpermalink":"/publication/2017_patent/","section":"publication","summary":"2017 BR Instituto Nacional de Propriedade Industrial","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection","Multimodal Data Fusion"],"title":"Método multimodal e em tempo real para filtragem de conteúdo sensível","type":"publication"},{"authors":["Allan Pinto","Daniel Moreira","Aparna Bharati","Joel Brogan","Kevin Bowyer","Patrick Flynn","Walter Scheirer","Anderson Rocha"],"categories":null,"content":"","date":1505865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"01756fc5abf88d5fa03edf5125183c98","permalink":"https://danielmoreira.github.io/publication/2017_icip_filtering/","publishdate":"2017-09-20T00:00:00Z","relpermalink":"/publication/2017_icip_filtering/","section":"publication","summary":"2017 IEEE International Conference on Image Processing","tags":["Media Forensics","Provenance Analysis","Provenance Filtering"],"title":"Provenance filtering for multimedia phylogeny","type":"publication"},{"authors":["Joel Brogan","Paolo Bestagini","Aparna Bharati","Allan Pinto","Daniel Moreira","Kevin Bowyer","Patrick Flynn","Anderson Rocha","Walter Scheirer"],"categories":null,"content":"","date":1505865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"02147cfb5fb75dce768201eadfb88ecb","permalink":"https://danielmoreira.github.io/publication/2017_icip_spotting/","publishdate":"2017-09-20T00:00:00Z","relpermalink":"/publication/2017_icip_spotting/","section":"publication","summary":"2017 IEEE International Conference on Image Processing","tags":["Media Forensics","Provenance Analysis","Provenance Filtering","Forgery Detection","Forgery Localization"],"title":"Spotting the difference: Context retrieval and analysis for improved forgery detection and localization","type":"publication"},{"authors":["Aparna Bharati","Daniel Moreira","Allan Pinto","Joel Brogan","Kevin Bowyer","Patrick Flynn","Walter Scheirer","Anderson Rocha"],"categories":null,"content":"","date":1505865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"e0e55df34f95abd748c49a3c73976a22","permalink":"https://danielmoreira.github.io/publication/2017_icip_uphylogeny/","publishdate":"2017-09-20T00:00:00Z","relpermalink":"/publication/2017_icip_uphylogeny/","section":"publication","summary":"2017 IEEE International Conference on Image Processing","tags":["Media Forensics","Provenance Analysis","Provenance Graph Construction"],"title":"U-Phylogeny: Undirected provenance graph construction in the wild","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"   ","date":1490313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"d6e6309c8877cb2a9c81810845939da6","permalink":"https://danielmoreira.github.io/publication/2017_wacv/","publishdate":"2017-03-24T00:00:00Z","relpermalink":"/publication/2017_wacv/","section":"publication","summary":"2017 IEEE Winter Conference on Applications of Computer Vision","tags":["Sensitive Media Analysis","Violence Detection","TRoF"],"title":"Temporal Robust Features for Violence Detection","type":"publication"},{"authors":["Mauricio Perez","Sandra Avila","Daniel Moreira","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1490140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"15191369fe40e5bb02e6086be58c4f73","permalink":"https://danielmoreira.github.io/publication/2017_neurocomputing/","publishdate":"2017-03-22T00:00:00Z","relpermalink":"/publication/2017_neurocomputing/","section":"publication","summary":"2017 Elsevier Neurocomputing","tags":["Sensitive Media Analysis","Pornography Detection","Deep Learning"],"title":"Video pornography detection through deep learning techniques and motion information","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"   ","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"7494b3fed906e23b0a676deb4fd9433b","permalink":"https://danielmoreira.github.io/publication/2016_fsi/","publishdate":"2016-11-01T00:00:00Z","relpermalink":"/publication/2016_fsi/","section":"publication","summary":"2016 Elsevier Forensic Science International","tags":["Sensitive Media Analysis","Pornography Detection","TRoF"],"title":"Pornography classification: The hidden clues in video space–time","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1444953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"7fa554d52ea776bd773cd0077ad60f5a","permalink":"https://danielmoreira.github.io/publication/2015_mediaeval/","publishdate":"2015-10-16T00:00:00Z","relpermalink":"/publication/2015_mediaeval/","section":"publication","summary":"2015 Mediaeval Workshop","tags":["Sensitive Media Analysis","Violence Detection","MediaEval"],"title":"RECOD at MediaEval 2015: Affective Impact of Movies Task","type":"publication"},{"authors":["Sandra Avila","Daniel Moreira","Mauricio Perez","Daniel Moraes","Isabela Cota","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1413417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564609317,"objectID":"70ffa72781253d07b83dc47ed4e8837b","permalink":"https://danielmoreira.github.io/publication/2014_mediaeval/","publishdate":"2014-10-16T00:00:00Z","relpermalink":"/publication/2014_mediaeval/","section":"publication","summary":"2014 Mediaeval Workshop","tags":["Sensitive Media Analysis","Violence Detection","MediaEval"],"title":"RECOD at MediaEval 2014: Violent Scenes Detection Task","type":"publication"}]