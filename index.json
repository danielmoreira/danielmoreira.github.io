
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"My name is Daniel and I am a computer scientist who works as an assistant professor at Loyola University Chicago, USA.\nI investigate the application of techniques from the fields of Computer Vision, Machine Learning, Media Forensics, and Biometrics to make our society better.\nHere is my CV.\nI am glad to have joined Drs. Anderson Rocha and Sébastien Marcel as the guest editors of the IEEE Security \u0026amp; Privacy “Special Issue on Synthetic Realities and AI-Generated Contents”. The issue is now published at IEEE Xplore. Many thanks to the authors for their wonderful contributions!\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"13fb944df2e35b4baa2c6664c8ff164a","permalink":"https://danielmoreira.github.io/authors/daniel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/daniel/","section":"authors","summary":"My name is Daniel and I am a computer scientist who works as an assistant professor at Loyola University Chicago, USA.\nI investigate the application of techniques from the fields of Computer Vision, Machine Learning, Media Forensics, and Biometrics to make our society better.","tags":null,"title":"Daniel Moreira","type":"authors"},{"authors":["Daniel Moreira","Sébastien Marcel","Anderson Rocha"],"categories":null,"content":"","date":1715904000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715904000,"objectID":"457e7775514daa44b0c66ebf250aac42","permalink":"https://danielmoreira.github.io/publication/2024_sp/","publishdate":"2024-05-17T00:00:00Z","relpermalink":"/publication/2024_sp/","section":"publication","summary":"2024 IEEE Security \u0026 Privacy Special Issue","tags":["Synthetic Realities","Artificial Intelligence","Generated Contents"],"title":"Synthetic Realities and Artificial Intelligence-Generated Contents","type":"publication"},{"authors":null,"categories":null,"content":" Details Course: COMP 379-001 / COMP 479-001 Machine Learning\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dmoreira1@luc.edu)\nLectures: THR, 4:15 to 6:45 PM, 123 Institute of Environmental Sustainability\nOffice Hours: FRI, 8 AM to 5 PM, 310 Doyle Center or Zoom, by appointment\nSakai: https://sakai.luc.edu/x/Od0gze\nOverview “Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed.”\n– Arthur Samuel, 1959\nEven though Samuel’s definition is now more than six decades old, it still holds true. With the recent advances in computer processing power, memory, and storage, machine learning has stressed its learn-by-example data-driven aspect, and is available — commonly as a black box — to everyone.\nAnnotated high-quality datasets can be easily harnessed to train a multitude of models to solve very specific problems under the different paradigms of supervised, unsupervised, hybrid (e.g., semi-supervised and self-supervised), and reinforcement learning. This course will cover these paradigms, trying to establish a balance between theory and practice. While students will be exposed to the theories that fight the black-box and irresponsible usage of machine learning, hands-on activities leveraging real-world data will prepare them for industrial, academic, and societal needs.\nLet’s learn how the machines learn!\nRequirements to attend this course are basic programming skills (especially Python), data structures, math fundamentals (such as linear algebra and calculus), and probability and statistics. This course and its materials are also available in Sakai.\nSchedule (Tentative) 01/18 - Syllabus and Intro 01/25 - Data-driven Aspects 02/01 - Supervised Learning I 02/08 - Supervised Learning II 02/15 - Supervised Learning III 02/22 - Supervised Learning IV 02/29 - Supervised Learning V 03/07 - Spring Break, no classes. 03/14 - Ensemble Learning. 03/21 - Unsupervised Learning. 03/28 - Easter Break, no classes. 04/04 - Neural Networks I. 04/11 - Neural Networks II. 04/18 - Hybrid and Reinforcement Learning. 04/25 - Project Presentations. 05/02 - Final Exam. Important Dates 02/15 - Definition of project groups. 02/29 - Definition of project topics. 03/07 - Spring Break. 03/14 - Midterm Exam. 03/21 - Definition of project plan. 03/28 - Easter Break. 04/11 - Report of project status. 04/18 - Graduate students’ lectures. 04/25 - Project presentations. 05/02 - Final Exam. Grading Concept Interval (%) Concept Interval (%) Concept Interval (%) Concept Interval (%) A [96, 100) B+ [88, 92) C+ [76, 80) D+ [64, 68) A- [92, 96) B [84, 88) C [72, 76) D [60, 64) B- [80, 84) C- [68, 72) F (0, 60) Distribution Undergraduate Graduate Assignments (4) 30% 25% Exams (2) 30% 25% Project 30% 25% Participation 10% 10% Topic Lecture N.A. 15% On the News +1% (extra) +1% (extra) Assignments Soon. Late Policy\nDeduction of 10% of the maximum possible grade for each day of delay.\nExams Midterm Exam, 03/14. Final Exam, 05/02. Project Written report and presentation, work alone or in groups. More soon. Participation Class Attendance: every presence counts. Today-I-missed Statements: every submission counts. Today-I-missed Statements\nAfter every attended class, each student will have to submit (through Sakai) a short paragraph answering one of the following:\nWhat is your biggest question after class? OR What was the most interesting point you learned today? Inspired by Dr. Sandra Avila.\nOopsie Cards\nEach student has two “Oopsie” Cards, which will allow them to avoid losing points because of late delivered work. The cards are not valid to dismiss or postpone exams, topic lectures (graduate students), or final project dates. Students may use their cards at their own discretion, as long as they clearly communicate the instructor.\nLife happens, be wise.\nML on the News Soon. Links Python Machine Learning book, code repository. Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow book, code repository, An Introduction to Statistical Learning with Applications in Python book, online version. Academic Integrity Students are expected to adhere to the LUC statements on academic integrity available at https://bit.ly/3TmiQkQ. These policies fully apply to this course. The penalty for task-wise academic misconduct is losing all the task’s points. Multiple events of misconduct will incur in failing the entire course (with an F grade). All cases of academic misconduct will be reported to the proper department offices. Lastly, students are not allowed to use AI assisted technology (such as ChatGPT) along the entirety of the course, unless explicitly authorized by the instructor.\nAccommodations Students who have disabilities and wish to request academic accommodations are advised to contact the Services for Students With Disabilities (SSWD) office at 773-508-3700 or SSWD@luc.edu as soon as possible. The SSWD office will provide accommodation letters that, once shared with the …","date":1705449600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705449600,"objectID":"6b017525220c5120110b64e1f05c8987","permalink":"https://danielmoreira.github.io/teaching/ml-spr24/","publishdate":"2024-01-17T00:00:00Z","relpermalink":"/teaching/ml-spr24/","section":"teaching","summary":"COMP 379-001 / COMP 479-001 Machine Learning","tags":["Teaching","Machine Learning","Artificial Intelligence"],"title":"Machine Learning, Spring 2024","type":"teaching"},{"authors":null,"categories":null,"content":" Details Course: COMP 141-001 / COMP 400D-001 Intro to Computing Tool\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dmoreira1@luc.edu)\nTeaching Assistant: Bright Duffour (bduffour@luc.edu)\nLectures: MON, 4:15 to 5:30 PM, online\nOffice Hours: FRI, 8:00 AM to 5:00 PM, 310 Doyle Center or Zoom, by appointment\nSakai: https://sakai.luc.edu/x/xaQGV2\nOverview Despite the current era of rich graphical user interfaces (desktop, web, and mobile), the “command line” experience remains important, especially for software developers and computer-aided scientific researchers. Many development scenarios still require command line and fluency in Unix tools, including the modern embedded, cloud, cybersecurity, and supercomputing environments. With mobile computing and Internet of Things, Unix (via Linux) has risen to the level of a ubiquitous platform, owing to its lightweight and open-source nature. While this course does not aim at being a comprehensive programming class, students will master basic programming skills using shell scripting. They will also learn about problem-solving using Unix commands supported by shell scripts.\nPlease refer to Sakai for having access to the materials, assignments, quizzes, announcements, grading, and progress of the course. This page is static and will not be updated.\nTeam This course is offered in multiple sessions with the following leading and contributing LUC instructors (Spring 2024):\nJohn O’Sullivan Konstantin Läufer References Shots, W. The Linux Command Line, 2nd Edition. No Starch Press Book, 2019. Available at https://linuxcommand.org/. ","date":1705363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705363200,"objectID":"60d38b71d30a75556f512d59e88fa10f","permalink":"https://danielmoreira.github.io/teaching/comptool-spr24/","publishdate":"2024-01-16T00:00:00Z","relpermalink":"/teaching/comptool-spr24/","section":"teaching","summary":"COMP 141-001 / COMP 400D-001 Introduction to Computing Tool","tags":["Teaching","Shell","Unix"],"title":"Learning the Shell, Spring 2024","type":"teaching"},{"authors":["João Phillipe Cardenuto","Jing Yang","Rafael Padilha","Renjie Wan","Daniel Moreira","Haoliang Li","Shiqi Wang","Fernanda Andaló","Sébastien Marcel","Anderson Rocha"],"categories":null,"content":"","date":1699228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699228800,"objectID":"140c5c5f8b2af210e74735c63c198db2","permalink":"https://danielmoreira.github.io/publication/2023_apsipa/","publishdate":"2023-11-06T00:00:00Z","relpermalink":"/publication/2023_apsipa/","section":"publication","summary":"2023 APSIPA Transactions on Signal and Information Processing","tags":["Synthetic Realities","Media Forensics"],"title":"The Age of Synthetic Realities: Challenges and Opportunities","type":"publication"},{"authors":null,"categories":null,"content":" Details Course: COMP 388-002 / COMP 488-002 Computer Science Topics\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dmoreira1@luc.edu)\nLectures: MON and WED, 4:15 to 5:30 PM, 218 Cuneo Hall\nOffice Hours: MON and TUE evenings, 6 to 8 PM, and WED mornings, 8 AM to noon, 310 Doyle Center or Zoom, by appointment\nSakai: https://sakai.luc.edu/x/gUHhNw\nFinal grades were released on Sakai. Thank you, everyone!\nOverview How do computers match a person’s fingerprints? Do they still use the same techniques proposed in the XIX century? How do computers identify people captured in a video? Do they leverage the depicted faces only, or can they use other traits such as gait or voice? How about iris recognition as portrayed in the movies? Is it really possible? What happens in the case of people who look very similar, such as identical twins? Which traits are more reliable and robust to impersonation or prone to falsification? These are some of the questions we will address in this course, whose main topic is Biometrics. In a nutshell, Biometrics is the study of techniques to identify individuals through their physical, chemical, and behavioral traits, such as fingerprints, face, iris, DNA, voice, gait, etc. Our focus will be on the technical and ethical aspects of computer-aided Biometrics, discussing the issues of going from simple and benign authentication to the more problematic case of surveillance. The course will have an intense hands-on approach, with the collection of samples and implementation of fingerprint, face, and iris recognition.\nRequirements to attend this course are basic programming skills (especially Python). This course and its materials are also available in Sakai.\nProgress 08/28 - Syllabus, Course details. 08/30 - Basics I, Biometrics, traits, and systems. 09/04 - Labor Day, no classes. 09/06 - Basics II, Biometric systems, errors, and metrics. 09/11 - 1st Coding Class, Metrics’ implementation. 09/13 - Fingerprint Recog. I, History and features. 09/18 - Fingerprint Recog. II, Acquisition and enhancement. 09/20 - Fingerprint Recog. III, Minutiae detection. 09/25 - Fingerprint Recog. IV, Data collection. 09/27 - 2nd Coding Class, Fingerprint recognition. 10/02 - Midterm Preparation, Project discussion and recap. 10/04 - Midterm Exam, Grades on Sakai. 10/09 - Fall Break, no classes. 10/11 - Face Recog. I, Why faces and faces vs. other traits. 10/16 - Face Recog. II, Acquisition and enhancement. 10/18 - Face Recog. III, Description and matching. 10/23 - Face Recog. IV, Deep learning face recognition. 10/25 - 3rd Coding Class, Face recognition. 10/30 - Iris Recog. I, Why irises and irises vs. other traits. 11/01 - Iris Recog. II, Acquisition and enhancement. 11/06 - Iris Recog. III, Description and matching. 11/08 - 4th Coding Class, Iris recognition. 11/13 - Other Traits, Alternative traits and Soft Biometrics. 11/15 - Multibiometrics, Data fusion. 11/20 - Feature Indexing, Index building and feature querying. 11/22 - Thanksgiving, no classes. 11/27 - 1st Invited Talk, Dr. Aparna Bharati. 11/29 - Office Hours to Conclude Projects, no classes. 12/04 - Project presentations, 5 groups present. 12/06 - 2nd Invited Talk, Dr. Adam Czajka. 12/11 - Final Exam, Grades on Sakai. Important Dates 08/28 - First Class. 09/04 - Labor Day, no classes. 09/11 - 1st Coding Class. 09/25 - 2nd Coding Class and Fingerprint Collection. 10/02 - 1st Assignment deadline. 10/04 - Midterm Exam. 10/09 - Fall Break, no classes. 10/16 - 2nd Assignment deadline. 10/25 - 3rd Coding Class. 11/08 - 4th Coding Class. 11/13 - 3rd Assignment deadline. 11/22 - Thanksgiving, no classes. 11/27 - Dr. Aparna Bharati’s talk. 12/04 - Project presentations. 12/06 - Dr. Adam Czajka’s talk. 12/11 - Final Exam. Notebooks (for coding classes) Notebook 01, Metrics’ implementation. Notebook 02, Fingerprint recognition. Notebook 03, Face recognition. Notebook 04, Iris recognition. Invited Talks Dr. Aparna Bharati Assistant Professor Department of Computer Science and Engineering Lehigh University Synthetic Data in Face Biometrics How do image manipulations affect face recognition? How can computer-aided solutions detect and profile these manipulations? In this talk, I will present my recent work and the findings obtained while trying to answer these questions. We will discuss solutions to detect retouched faces by a variety of methods, including smartphone apps, as well as evaluate when face retouching is a problem for face recognition and our society. Moreover, we will talk about the recent trend of generating synthetic faces and how one can measure identity leakage from the training set to the generated samples, a major privacy issue that indeed deserves attention. Lastly, I introduce our recent work on SynthProv, which allies provenance analysis to synthetic face detection and identity leakage evaluation. Dr. Adam Czajka Associate Professor Department of Computer Science and Engineering University of Notre Dame Do you want a better …","date":1692748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692748800,"objectID":"3644758ce533600b75922d8fd05dc748","permalink":"https://danielmoreira.github.io/teaching/biometrics-aut23/","publishdate":"2023-08-23T00:00:00Z","relpermalink":"/teaching/biometrics-aut23/","section":"teaching","summary":"COMP 388-002 / COMP 488-002 Computer Science Topics","tags":["Teaching","Biometrics","Fingerprint Recognition","Iris Recognition","Face Recognition"],"title":"Biometrics, Fall 2023","type":"teaching"},{"authors":null,"categories":null,"content":" Details Course: COMP 141-001 / COMP 400D-001 Intro to Computing Tool\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dmoreira1@luc.edu)\nTeaching Assistants: Alvaro Delandaluce (adelandaluce@luc.edu) and Bright Duffour (bduffour@luc.edu)\nLectures: TUE, 4:15 to 5:30 PM, online\nOffice Hours: MON and TUE evenings, 6 to 8 PM, and WED mornings, 8 AM to noon, 310 Doyle Center or Zoom, by appointment Sakai: https://sakai.luc.edu/x/Qzs2kZ\nOverview Despite the current era of rich graphical user interfaces (desktop, web, and mobile), the “command line” experience remains important, especially for software developers and computer-aided scientific researchers. Many development scenarios still require command line and fluency in Unix tools, including the modern embedded, cloud, cybersecurity, and supercomputing environments. With mobile computing and Internet of Things, Unix (via Linux) has risen to the level of a ubiquitous platform, owing to its lightweight and open-source nature. While this course does not aim at being a comprehensive programming class, students will master basic programming skills using shell scripting. They will also learn about problem-solving using Unix commands supported by shell scripts.\nPlease refer to Sakai for having access to the materials, assignments, quizzes, announcements, grading, and progress of the course. This page is static and will not be updated.\nTeam This course is offered in multiple sessions with the following leading and contributing LUC instructors (Spring 2023):\nJohn O’Sullivan Nathan Hishon Leo Irakliotis Konstantin Läufer References Shots, W. The Linux Command Line, 2nd Edition. No Starch Press Book, 2019. Available at https://linuxcommand.org/. ","date":1692489600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692489600,"objectID":"d8f10a7413dd9ecacb8dc661acb9fbce","permalink":"https://danielmoreira.github.io/teaching/comptool-aut23/","publishdate":"2023-08-20T00:00:00Z","relpermalink":"/teaching/comptool-aut23/","section":"teaching","summary":"COMP 141-001 / COMP 400D-001 Introduction to Computing Tool","tags":["Teaching","Shell","Unix"],"title":"Learning the Shell, Fall 2023","type":"teaching"},{"authors":["Daniel Moreira","Aparna Bharati","Cecilia Pasquini","Yassine Yousfi"],"categories":null,"content":"","date":1687910400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687910400,"objectID":"ca4900869dc5cf1bc16d470e01ddb6f3","permalink":"https://danielmoreira.github.io/publication/2023_ihmmsec/","publishdate":"2023-06-28T00:00:00Z","relpermalink":"/publication/2023_ihmmsec/","section":"publication","summary":"2023 ACM Workshop on Information Hiding and Multimedia Security","tags":["Information Hiding","Multimedia Security"],"title":"IH\u0026MMSec '23: Proceedings of the 2023 ACM Workshop on Information Hiding and Multimedia Security","type":"publication"},{"authors":null,"categories":null,"content":" Details Course: COMP 180-001 Computing and Data Analysis for the Sciences\nLevel: Undergraduate\nInstructor: Daniel Moreira (dmoreira1@luc.edu)\nTeaching Assistant: Jerome Santos (msantos@luc.edu)\nLectures: TUE, 4:15 to 6:45 PM, 103 Cuneo Hall\nOffice Hours: THR, 6:00 to 8:00 PM, and FRI, 10:00 AM to 12:00 PM, by appointment\nSakai: https://sakai.luc.edu/x/ouBYMu\nGrades are now available.\nOverview Map with inspected Chicago food establishments generated during the course.\nRegardless of their field, scientists’ work generates and consumes large troves of research data, whose effective, efficient, and reliable storage, management, processing, interpretation, presentation, and sharing are mostly possible due to the current computer systems. Besides mastering one’s own scientific area of research, mastering the usage of the available computing power to analyze data has become essential to foster steady and solid scientific progress. This course aims at training attendees to use modern computing tools and techniques to perform rapid data analysis and rich data presentation, both within collaborative environments and in scientific contexts. At the end of the course, students shall be well-versed in writing their own programs and leveraging up-to-date scientific libraries to collaboratively analyze their research data and richly present their findings.\nAttending students are required to have taken MATH 117 (College Algebra) or have been placed in MATH 118 (Precalculus) or higher. Please refer to Sakai for having access to the materials, assignments, quizzes, announcements, grading, and progress of the course. This page is static and will not be updated.\nAcknowledgements This course is heavily based on Dr. Mohammed Abuhamad’s previous course. I sincerely thank Mohammed for kindly allowing me to rely upon his materials.\nReferences Harrington, A. Hands-on Python Tutorial. Available at https://anh.cs.luc.edu/python/hands-on/3.1/index.html. The City of Chicago. Chicago Food Inspections Dataset. Available at: https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5. ","date":1674864000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674864000,"objectID":"ff08040450af295a14248adb6dd4f50d","permalink":"https://danielmoreira.github.io/teaching/compsci-spr23/","publishdate":"2023-01-28T00:00:00Z","relpermalink":"/teaching/compsci-spr23/","section":"teaching","summary":"COMP 180-001 Computing and Data Analysis for the Sciences","tags":["Teaching","Computing for the Sciences","Data Analysis"],"title":"Computing for the Sciences, Spring 2023","type":"teaching"},{"authors":null,"categories":null,"content":" Details Course: COMP 141-001 / COMP 400D-001 Intro to Computing Tool\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dmoreira1@luc.edu)\nTeaching Assistants: Brianna Chou (bchou@luc.edu) and Jerome Santos (msantos@luc.edu)\nLectures: MON, 4:15 to 5:30 PM, online\nOffice Hours: WED, 6:00 to 8:00 PM, and FRI, 8:00 to 10:00 AM, by appointment\nSakai: https://sakai.luc.edu/x/HxHiwy\nGrades are now available.\nOverview Despite the current era of rich graphical user interfaces (desktop, web, and mobile), the “command line” experience remains important, especially for software developers and computer-aided scientific researchers. Many development scenarios still require command line and fluency in Unix tools, including the modern embedded, cloud, cybersecurity, and supercomputing environments. With mobile computing and Internet of Things, Unix (via Linux) has risen to the level of a ubiquitous platform, owing to its lightweight and open-source nature. While this course does not aim at being a comprehensive programming class, students will master basic programming skills using shell scripting. They will also learn about problem-solving using Unix commands supported by shell scripts.\nPlease refer to Sakai for having access to the materials, assignments, quizzes, announcements, grading, and progress of the course. This page is static and will not be updated.\nTeam This course is offered in multiple sessions with the following leading and contributing LUC instructors (Spring 2023):\nNathan Hishon John O’Sullivan References Shots, W. The Linux Command Line, 2nd Edition. No Starch Press Book, 2019. Available at https://linuxcommand.org/. ","date":1674777600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674777600,"objectID":"89ae27dc0f3fd73efdf47fdb02978b83","permalink":"https://danielmoreira.github.io/teaching/comptool-spr23/","publishdate":"2023-01-27T00:00:00Z","relpermalink":"/teaching/comptool-spr23/","section":"teaching","summary":"COMP 141-001 / COMP 400D-001 Introduction to Computing Tool","tags":["Teaching","Shell","Unix"],"title":"Learning the Shell, Spring 2023","type":"teaching"},{"authors":["William Theisen","Daniel Gonzales Cedre","Zachariah Carmichael","Daniel Moreira","Tim Weninger","Walter Scheirer"],"categories":null,"content":"","date":1672876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672876800,"objectID":"35702f20f90855556abb03ec1c623bcf","permalink":"https://danielmoreira.github.io/publication/2023_wacv_motif/","publishdate":"2023-01-05T00:00:00Z","relpermalink":"/publication/2023_wacv_motif/","section":"publication","summary":"2023 IEEE Winter Conference on Applications of Computer Vision","tags":["Motif Mining","CBIR","Media Forensics"],"title":"Motif Mining: Finding and Summarizing Remixed Image Content","type":"publication"},{"authors":["Aidan Boyd","Daniel Moreira","Andrey Kuehlkamp","Kevin Bowyer","Adam Czajka"],"categories":null,"content":"","date":1672790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672790400,"objectID":"0d9a9fcbd68c2a1d381a64521590b134","permalink":"https://danielmoreira.github.io/publication/2023_wacv_human/","publishdate":"2023-01-04T00:00:00Z","relpermalink":"/publication/2023_wacv_human/","section":"publication","summary":"2023 IEEE Winter Conference on Applications of Computer Vision (Workshop)","tags":["Post-mortem Iris Recognition","Interpretable Iris Recognition","Iris Recognition","Biometrics"],"title":"Human Saliency-driven Patch-based Matching for Interpretable Post-mortem Iris Recognition","type":"publication"},{"authors":null,"categories":null,"content":" Dear COMP 141 Students,\nPlease find below some tips to answer Homework #7. I acknowledge this is a more challenging assignment, in particular given the course’s asynchronous and fully remote nature. Because of this, I’d like to give you some hints that might be useful to answer it.\nMay you have any questions, please let me know.\n– Daniel (dmoreira1@luc.edu)\nQuestion 1 The steps below will give you some structure to answer this question.\n1.1. Create a username on GitHub. You can do this at https://github.com, using the “Sign Up” button in the top right corner of the page. Follow the steps and provide a screenshot with your new GitHub profile. This will be your screenshot number one.\nMine is below, for your reference. 1.2. Create a project on GitHub. This can be done through the GitHub web interface, from your GitHub profile page that you’ve just used to generate a screenshot. In the top right corner of your profile page, there is button with a plus sign. Click there and select the “New repository” option.\nIn the following page, provide a “Repository name”, and mark it as “Public” (so that everybody, including the TA and me, can access it). Don’t forget to select the “Add a README file” option, so your project is not empty. You may also provide a project “Description”, if you want. This will be useful once you get to the point where you have lots of projects. A possible description is “My first GitHub project for Comp 141.”.\nAfter doing this, go to the bottom of the page, and click on the “Create repository” button. Voilà, you now have your new project on GitHub, on the web. Provide a screenshot of the current project page; this will be you screenshot number two.\n1.3. Clone the project from GitHub (on the web) to your local computer. On your computer, open the terminal screen. Make sure you have git installed:\nuser@host: git --version If you don’t, install it with either apt-get or homebrew, depending on your OS. For Linux users (your COMP 141 Virtual Machine is Linux):\nuser@host: sudo apt install git For macOS users:\nuser@host% brew install git Clone the project from GitHub to your local machine. Go to your project GitHub page (the one you’ve just used to generate the last screenshot), and click on the “\u0026lt;\u0026gt; Code” button on the top mid-right portion of the screen. Select the “HTTPS” option on the “Clone” function and copy the “https://gtihub.com/\u0026lt;your_name\u0026gt;/\u0026lt;your_project\u0026gt;” link.\nGo back to the terminal and type:\nuser@host: git clone https://gtihub.com/\u0026lt;your_name\u0026gt;/\u0026lt;your_project\u0026gt; Don’t forget to paste and replace “https://gtihub.com/\u0026lt;your_name\u0026gt;/\u0026lt;your_project\u0026gt;” with the content you’ve just copied from your GitHub project page.\nVoilà, your project was copied to your local computer. Execute the “ls” command on your terminal and localize your project folder; the folder’s name will be the same as your project’s. Generate a screenshot of your terminal with this content and add to your answers; this will be your screenshot number three.\n1.4. Setup an authentication token, so you can upload things to your GitHub project. This is a step with security purposes, to avoid people inadvertently messing up with your project. Go to your GitHub profile page (the one you’ve used to generate the first screenshot). Click on your profile picture in the top right corner of the page. Select the “Settings” option on the drop-down menu.\nOn the following page, on the left-side menu, select the “Developer settings” option (yes, you’ll be a developer). On the following one, select the “Personal access tokens” drop-down option. We want the “Tokens (classic)” feature. Click on it and proceed to the next page.\nOn the next page, select the top right corner “Generate new token” button. Again, select the “Generate new token (classic)” option. Provide your GitHub password, to proceed to the next step.\nFill-in the blanks of the form within the next page. For instance, in the “Note” field, add something like “My first token for test purposes.” For the “Expiration” field, select “No expiration” and ignore, for now, the warning message (we can talk about it in more detail through e-mail, if you want to). In the available “scopes”, select the “repo” one. Go to the bottom of the page and click on the “Generate token” button.\nVoilà, your created a GitHub security token. Take a screenshot of the next page and add to your answers; this will be your screenshot number four.\nDon’t forget to copy the long string that is provided in this page. This will be your password to upload local modifications to your GitHub project. We’ll need it in the next step.\n1.5. Add a new file to your project. Back to your local machine, using your terminal, create a new file on your project’s folder. Make sure (with “pwd”, “cd”, and “ls”) that you’re inside the correct folder. You may use any file editor of your preference. In the example below, I’m using “vi” to edit files.\nuser@host: cd \u0026lt;your_project\u0026gt; user@host: vi my_file.txt Don’t forget to replace “\u0026lt;your_project\u0026gt;” with …","date":1670371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670371200,"objectID":"73ca45285d5e02224506f05a265e1175","permalink":"https://danielmoreira.github.io/post/comp141/","publishdate":"2022-12-07T00:00:00Z","relpermalink":"/post/comp141/","section":"post","summary":"Tips to answer Homework","tags":["COMP 141"],"title":"COMP 141, Homework","type":"post"},{"authors":["Daniel Moreira","João Phillipe Cardenuto","Ruiting Shao","Sriram Baireddy","Davide Cozzolino","Diego Gragnaniello","Wael Abd-Almageed","Paolo Bestagini","Stefano Tubaro","Anderson Rocha","Walter Scheirer","Luisa Verdoliva","Edward Delp"],"categories":null,"content":"","date":1667174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667174400,"objectID":"42dcea04046b0f2ca6f50a4ea8ac15a1","permalink":"https://danielmoreira.github.io/publication/2022_scirep/","publishdate":"2022-10-31T00:00:00Z","relpermalink":"/publication/2022_scirep/","section":"publication","summary":"2022 Nature Scientific Reports","tags":["Media Forensics","Scientific Integrity","SILA"],"title":"SILA: a system for scientific image analysis","type":"publication"},{"authors":null,"categories":null,"content":" Details Course: COMP 388-002 / COMP 488-002 Computer Science Topics\nFormat: Seminar\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dmoreira1@luc.edu)\nLectures: MON, 4:15 to 6:45 PM, 117 Cuneo Hall\nOffice Hours: TUE and THR, 5:00 to 7:00 PM, by appointment\nSakai: https://sakai.luc.edu/x/4tCa9j\nGrades are now available.\nOverview How might Google or TinEye reverse image search operate? How can a computer program process the pixel values of images and video frames and classify the depicted scene, or leverage the captured faces to perform person identification? What about manipulated images with tools such as Photoshop? Are there methods to help to debunk these manipulations? These are some of the questions we will be addressing in this course, focusing on state-of-the-art Computer Vision (CV) solutions to reduce the semantic gap between the pixel values and the desired outcome of complex tasks such as content-based image retrieval, content classification and recognition, biometric identification, and media forensics, always with the greater good in mind.\nRequirements to attend this course are basic programming skills (especially Python) and statistics and probability.\nSchedule Date Topic Leaders References Assignment 08/29 Introduction to CV Instructor N.A. N.A. 09/05 Labor Day N.A. N.A. A01, due on 09/15 09/12 Letter Soup: AI, ML, NN, DL, etc. Instructor [1, 2, 3] A02, due on 09/20 09/19 Image Description Instructor [4, 5, 6] A03, due on 09/27 09/26 Image Retrieval Nick and Jesus [7, 8, 9, 10] A04, due on 10/04 10/03 Image Classification Nick and Kenneth [11, 12, 13, 14, 15] A05, due on 10/18 10/10 Fall Break N.A. N.A. N.A. 10/17 Object Detection John and Kenneth [16, 17, 18, 19, 20] A06, due on 10/25 10/24 Image Segmentation Mujtaba and Matt [21, 22, 23, 24, 25] A07, due on 11/01 10/31 Face Detection John and Amol [26, 27, 28, 29] A08, due on 11/08 11/07 Face Recognition Mujtaba and Amol [30, 31, 32, 33, 34] A09, due on 11/15 11/14 Generative Adversarial Nets Jakob and Matt [35, 36, 37, 38, 39] A10, due on 11/29 11/21 Attacks \u0026amp; Deep Fake Detection Instructor [40, 41, 42] N.A. 11/28 Sensitive Video Analysis Instructor [43, 44] N.A. 12/05 Provenance Analysis Jakob and Jesus [45, 46, 47, 48, 49] N.A. 12/12 Final Exam N.A. N.A. N.A. Assignments A01: Image Descriptors [4, 5, 6], due on 09/15 at noon. A02: Image Retrieval, [8, 9, 10], due on 09/20 at noon. A03: Image Classification, [11, 12, 13, 14, 15], due on 09/27 at noon. A04: Object Detection, [16, 17, 18, 19, 20], due on 10/04 at noon. A05: Image Segmentation, [21, 22, 23, 24, 25], due on 10/18 at noon. A06: Face Detection, [26, 27, 28, 29], due on 10/25 at noon. A07: Face Recognition, [30, 31, 32, 33, 34], due on 11/01 at noon. A08: Generative Adversarial Nets, [35, 36, 37, 38, 39], due on 11/08 at noon. A09: Attacks and Sensitive Video Analysis, [40, 41, 42, 43, 44], due on 11/16 at noon. A10: Provenance Analysis, [46, 47, 48, 49], due on 11/29 at noon. Students will have to do at most eight assignments. Each assignment will comprise a particular set of scientific articles. Students will have to choose one of the articles for each assignment and provide a summary on the due date. There is no limit of pages for the summaries. Each summary should contain:\n(1) What is the problem addressed in the article?\n(2) Why is it important to address this problem?\n(3) How do the authors address the problem?\n(4) What are the authors’ claims?\n(5) What methodology did they adopt (e.g., datasets, problem metrics, experiments) to prove their claims?\n(6) Do you agree with the authors’ claims?\n(7) For the graduate students, how do you think you may use this work in your research?\n(8) What open questions do you have about the article?\nDiscussion Leaders Image Retrieval, Nick and Jesus, on 09/26. Image Classification, Nick and Kenneth, on 10/03. Object Detection, John and Kenneth, on 10/17. Image Segmentation, Mujtaba and Matt, on 10/24. Face Detection, John and Amol, on 10/31. Face Recognition, Mujtaba and Amol, on 11/07. Generative Adversarial Networks, Jakob and Matt, on 11/14. Provenance Analysis, Jakob and Jesus, on 12/05. Each student will play the role of discussion leader twice along the course. Students will lead discussion in groups, preferably in pairs of one graduate and one undergraduate student. The graduate students are expected to help their undergraduate peers.\nDiscussion leaders will be responsible for organizing a 1.5-hour presentation of the topic of the day, resorting to slides, videos, and demonstrations. The instructor advises the discussion leaders to share their material with him a couple of days before the presentation day.\nDiscussion leaders will also receive the summaries of the articles and open questions related to their topics from the other students at least 5 days before their presentation.\nThe discussion and assignment topics coincide; as a consequence, discussion leaders are not required to provide summaries for the topics they …","date":1661731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661731200,"objectID":"d7586ab04df07d71e034dcc85e28cf74","permalink":"https://danielmoreira.github.io/teaching/cvapp-aut22/","publishdate":"2022-08-29T00:00:00Z","relpermalink":"/teaching/cvapp-aut22/","section":"teaching","summary":"COMP 388-002 / COMP 488-002 Computer Science Topics","tags":["Teaching","Computer Vision"],"title":"Computer Vision Applications, Fall 2022","type":"teaching"},{"authors":null,"categories":null,"content":" Details Course: COMP 141-001 / COMP 400D-001 Intro to Computing Tool\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dmoreira1@luc.edu)\nTeaching Assistant: Olga Velichko (ovelichko@luc.edu)\nLectures: Asynchronous and fully remote on Sakai\nOffice Hours: WED, 5 to 8 PM, and FRI, 4 to 5 PM, by appointment\nGrades are now available.\nOverview Despite the current era of rich graphical user interfaces (desktop, web, and mobile), the “command line” experience remains important, especially for software developers and computer-aided scientific researchers. Many development scenarios still require command line and fluency in Unix tools, including the modern embedded, cloud, cybersecurity, and supercomputing environments. With mobile computing and Internet of Things, Unix (via Linux) has risen to the level of a ubiquitous platform, owing to its lightweight and open-source nature. While this course does not aim at being a comprehensive programming class, students will master basic programming skills using shell scripting. They will also learn about problem-solving using Unix commands supported by shell scripts.\nPlease refer to Sakai for having access to the materials, assignments, quizzes, announcements, grading, and progress of the course. This page is static and will not be updated.\nHelp with Homework #7 Hints were given here.\nTeam This course is offered in multiple sessions with the following leading and contributing LUC instructors (Fall 2022):\nJohn O’Sullivan Nathan Hishon Allan Miller David Wetzel References Shots, W. The Linux Command Line, 2nd Edition. No Starch Press Book, 2019. Available at https://linuxcommand.org/. ","date":1661644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661644800,"objectID":"fe2c9ca8c5b14df1cc3001a9e3f6a130","permalink":"https://danielmoreira.github.io/teaching/comptool-aut22/","publishdate":"2022-08-28T00:00:00Z","relpermalink":"/teaching/comptool-aut22/","section":"teaching","summary":"COMP 141-001 / COMP 400D-001 Introduction to Computing Tool","tags":["Teaching","Shell","Unix"],"title":"Learning the Shell, Fall 2022","type":"teaching"},{"authors":["Sara Mandelli","Davide Cozzolino","Edoardo Cannas","Joao Cardenuto","Daniel Moreira","Paolo Bestagini","Walter Scheirer","Anderson Rocha","Luisa Verdoliva","Stefano Tubaro","Edward Delp"],"categories":null,"content":"","date":1653868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653868800,"objectID":"24dc52a6df753e3d2cc038090d9ca8f0","permalink":"https://danielmoreira.github.io/publication/2022_ieeeaccess/","publishdate":"2022-05-30T00:00:00Z","relpermalink":"/publication/2022_ieeeaccess/","section":"publication","summary":"2022 IEEE Access","tags":["Media Forensics","Scientific Integrity","GANs"],"title":"Forensic Analysis of Synthetically Generated Western Blot Images","type":"publication"},{"authors":["Daniel Moreira","William Theisen","Walter Scheirer","Aparna Bharati","Joel Brogan","Anderson Rocha"],"categories":null,"content":"","date":1648857600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648857600,"objectID":"784c890c282381057c41d4e51f21e217","permalink":"https://danielmoreira.github.io/publication/2022_chapter/","publishdate":"2022-04-02T00:00:00Z","relpermalink":"/publication/2022_chapter/","section":"publication","summary":"2022 Springer Book Chapter","tags":["Media Forensics","Provenance Analysis","Provenance Filtering","Provenance Graph Construction","Image Clustering"],"title":"Image Provenance Analysis","type":"publication"},{"authors":null,"categories":null,"content":" Details Course: CSE 40537 / 60537 Biometrics\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dhenriq1@nd.edu)\nTeaching Assistant: Jason You (syou@nd.edu)\nLectures: TUE and THR, 3:30 to 4:45 PM, 356A Fitzpatrick Hall\nOffice Hours: Daniel - MON to FRI, 5:00 to 6:00 PM, 182 Fitzpatrick Hall, Jason - WED, 1:00 to 2:00 PM, 150M Fitzpatrick Hall\nSlack: https://nd-biometrics-spr22.slack.com (now deactivated)\nPanopto: https://bit.ly/3A4QEKc\nCourse grades are now available.\nProgress 01/11/2022 - Syllabus, Course details. 01/13/2022 - Basics I, Biometrics, traits, and systems. 01/18/2022 - Basics II, Errors, metrics, and attacks. 01/20/2022 - Basics II (cont.), 1st Coding Class, Metrics. 01/25/2022 - Fingerprint Recog. I, History and features. 01/27/2022 - Fingerprint Recog. II, Acquisition and enhancement. 02/01/2022 - Fingerprint Recog. III, Minutiae detection. 02/03/2022 - Fingerprint Data Collection, password with instructor. 02/08/2022 - Iris Recog. I, Why irises and irises vs. other traits. 02/10/2022 - Iris Recog. II, Acquisition and enhancement. 02/15/2022 - Iris Recog. III, Description and matching. 02/17/2022 - 2nd Coding Class, Fingerprint recognition. 02/22/2022 - Iris Data Collection, password with instructor. 02/24/2022 - 3rd Coding Class, Iris recognition. 03/01/2022 - 1st Invited Talk, Dr. Andrey Kuehlkamp. 03/03/2022 - Midterm exam, grades. 03/08/2022 - Spring Break. 03/10/2022 - Spring Break. 03/15/2022 - Face Recog. I, Why faces and faces vs. other traits. 03/17/2022 - Face Recog. II, Acquisition and enhancement. 03/22/2022 - Face Recog. III, Description and matching. 03/24/2022 - Face Recog. IV, Deep learning face recognition. 03/29/2022 - 4th Coding Class, Face recognition. 03/31/2022 - Feature Indexing, Index building and feature querying. 04/05/2022 - Other Traits, Alternative traits and Soft Biometrics. 04/07/2022 - Multibiometrics, Data fusion. 04/12/2022 - 2nd Invited Talk, Mr. Aidan Boyd. 04/14/2022 - Fingerprint presentation attack day. 04/19/2022 - Iris and face presentation attack day. 04/21/2022 - Grad students’ signature recog. and gender from iris. 05/05/2022 - Final exam, grades. Assignments 01/20/2022 - 1st assignment, good answers, grades. 02/22/2022 - 2nd assignment, good answers, grades. 03/15/2022 - 3rd assignment, good answers, grades. 04/04/2022 - 4th assignment, good answers, grades. Important Dates 01/28/2022 - 1st assignment due date. 02/03/2022 - Fingerprint data collection. 02/22/2022 - Iris data collection. 03/01/2022 - Dr. Andrey Kuehlkamp’s talk. 03/03/2022 - Midterm exam. 03/04/2022 - 2nd assignment due date. 03/25/2022 - 3rd assignment due date. 04/12/2022 - Mr. Aidan Boyd’s talk. 04/14/2022 - Fingerprint presentation attack day. 04/18/2022 - 4th assignment due date. 04/19/2022 - Iris and face presentation attack day. 04/21/2022 - Grad students’ final report presentation. 05/05/2022 - Final exam, 10:30 to 12:30 PM, 356A Fitzpatrick Hall. Invited Talks Dr. Andrey Kuehlkamp Postdoctoral Research Associate at the Center for Research Computing, University of Notre Dame Diverse Aspects in Advancing Iris Recognition Systems Are we ready for widespread, mass-scale adoption of iris recognition systems? Following the miniaturization of fingerprint scanners, these have dominated recognition systems and have even become almost commonplace for unlocking cell phones, but what if in the not-so-far-off future they were replaced with iris scanners, would you be comfortable with it? Since its initial introduction in 1993, automated iris recognition has dramatically grown in popularity and soon could become the dominant method for automated recognition. Take for example the largest recognition system in the world — India’s Aadhaar program — which has collected more than 1.1 billion irises from their citizens to be used as the primary identification for banking, pensions, and welfare programs. Even more recently — in 2017 — Somaliland became the first country in the world to use iris recognition as the means for identification in a public election, which had more than 800,000 registered voters. Although a mature technology in many regards, the drastic increase in iris recognition adoption has revealed many opportunities for improvement. In this talk I present an overview of my research, which focuses on improving iris recognition in three ways: speed, accuracy, and robustness. Mr. Aidan Boyd Ph.D. Candidate at the Department of Computer Science and Engineering, University of Notre Dame Using human perception to train better CNNs Traditional deep learning is a data-driven process. Images are shown to a CNN and it is expected to learn rules that enable it to perform a task efficiently on new unseen images after training. The problem with this approach is that the model can only learn from the supplied training data. Potentially, this training data is not representative of the entire domain. Although the model classifies training images near perfectly, this learned rule may …","date":1641600000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641600000,"objectID":"24aadea06c79d658adaf71213f4263b5","permalink":"https://danielmoreira.github.io/teaching/biometrics-spr22/","publishdate":"2022-01-08T00:00:00Z","relpermalink":"/teaching/biometrics-spr22/","section":"teaching","summary":"CSE 40537 / 60537 Biometrics","tags":["Teaching","Biometrics","Fingerprint Recognition","Iris Recognition","Face Recognition"],"title":"Biometrics, Spring 2022","type":"teaching"},{"authors":["Joel Brogan","Aparna Bharati","Daniel Moreira","Anderson Rocha","Kevin Bowyer","Patrick Flynn","Walter Scheirer"],"categories":null,"content":"","date":1626825600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626825600,"objectID":"1642d311553b4e54a6fcfd9c43414f13","permalink":"https://danielmoreira.github.io/publication/2021_tip/","publishdate":"2021-07-21T00:00:00Z","relpermalink":"/publication/2021_tip/","section":"publication","summary":"2021 IEEE Transactions on Image Processing","tags":["CBIR","Media Forensics","Provenance Analysis","Provenance Filtering"],"title":"Fast Local Spatial Verification for Feature-Agnostic Large-Scale Image Retrieval","type":"publication"},{"authors":null,"categories":null,"content":"Status: Ongoing, Funded by: HHS\nHost: Loyola University Chicago\nThe Scientific Integrity (Sci-Int) project is an endeavor funded by the Department of Health and Human Services (HHS), whose goal is to develop solutions to identify misconduct in scientific research through the detection of image tampering in scientific papers.\nWorking together with the Universities of Purdue, Notre Dame, South California (USC), Campinas (Unicamp), Naples Federico II, and the Politécnico di Milano, our team leads the development of Provenance Analysis to detect and explain how problematic images relate to each other, and how they share content across different papers. Moreover, we also investigate the detection of synthetically generated scientific images, such as false gel blots.\nResearch Team Prof. Edward Delp (Lead PI) Prof. Daniel Moreira (PI) Prof. Walter Scheirer (PI) Prof. Anderson Rocha (PI) João P. Cardenuto (PhD Student) Matt Hyatt (Undergraduate Student) ","date":1622764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622764800,"objectID":"a9d89a042b5261f9823062ae35a22cef","permalink":"https://danielmoreira.github.io/project/sciint/","publishdate":"2021-06-04T00:00:00Z","relpermalink":"/project/sciint/","section":"project","summary":"Assessment of scientific research integrity through the detection of image tampering in scientific papers.","tags":["Media Forensics","Image Manipulation Detection","Provenance Analysis","Synthetic Image Detection"],"title":"Sci-Int","type":"project"},{"authors":null,"categories":null,"content":"Status: Ongoing, Funded by: DARPA\nHost: University of Notre Dame\nThe Semantic Forensics research project (SemaFor) is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA), whose goal is to leverage forensic tools to perform the detection of the existence, atribution of the authorship, and characterization of the intention of manipulated digital media.\nWorking together with the Universities of Purdue, Siena, Campinas (Unicamp), Naples Federico II, and the Politécnico di Milano, our team leads the development of solutions to the problem of digital document analysis (such as scientific papers, news articles, patents, grants, etc.). By combining ideas from the topics of image retrieval, digital image forensics, natural language processing, and deep learning, we aim at proposing multimodal methods to spot semantic inconsistencies within the content of documents.\nResearch Team Prof. Walter Scheirer (PI) Prof. Anderson Rocha (PI) Prof. Kevin Bowyer (PI) Prof. Tim Weninger (PI) Prof. Daniel Moreira (PI) William Theisen (PhD Student) Trenton Ford (PhD Student) Rosaura VidalMata (PhD Student) Priscila Saboia (PhD Student) João P. Cardenuto (PhD Student) ","date":1622678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622678400,"objectID":"0637272bead5fc08c94ecba1be402dcf","permalink":"https://danielmoreira.github.io/project/semafor/","publishdate":"2021-06-03T00:00:00Z","relpermalink":"/project/semafor/","section":"project","summary":"Semantic analysis of digital documents to support forensics.","tags":["Semantic Forensics","Document Analysis"],"title":"SemaFor","type":"project"},{"authors":["William Theisen","Joel Brogan","Pamela Bilo Thomas","Daniel Moreira","Pascal Phoa","Tim Weninger","Walter Scheirer"],"categories":null,"content":"","date":1621641600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621641600,"objectID":"fe3c7fb8d0ddb8e792d99fcbf0529350","permalink":"https://danielmoreira.github.io/publication/2021_icwsm/","publishdate":"2021-05-22T00:00:00Z","relpermalink":"/publication/2021_icwsm/","section":"publication","summary":"2021 AAAI International Conference on Web and Social Media","tags":["Meme Genres","Politics","Image Clustering"],"title":"Automatic Discovery of Political Meme Genres with Diverse Appearances","type":"publication"},{"authors":["Aparna Bharati","Daniel Moreira","Patrick Flynn","Anderson Rocha","Kevin Bowyer","Walter Scheirer"],"categories":null,"content":"","date":1610064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610064000,"objectID":"f69605846e42c0b40155436fcc83a1ab","permalink":"https://danielmoreira.github.io/publication/2021_tifs/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/publication/2021_tifs/","section":"publication","summary":"2021 IEEE Transactions on Information Forensics and Security","tags":["Deep Learning","Media Forensics","Provenance Analysis","Provenance Graph Construction"],"title":"Transformation-Aware Embeddings for Image Provenance","type":"publication"},{"authors":null,"categories":null,"content":" Details Course: CSE 40537 / 60537 Biometrics\nLevel: Undergraduate and Graduate\nInstructor: Daniel Moreira (dhenriq1@nd.edu)\nLectures: TUE and THR, 5:05 to 6:20 PM, 125 DeBartolo Hall1\nOffice Hours: MON and WED, 2:00 to 4:00 PM, 150N Fitzpatrick Hall1\nLectures: TUE and THR, 2:00 to 3:15 PM, at Zoom1\nOffice Hours: TUE and THR, 5:05 to 6:20 PM, at Zoom1\nStudents are not obligated to attend classes at 2:00 pm, but are certainly welcome. All classes are being recorded with Panopto.\nSlack: https://cse-biometrics-spr20.slack.com (now deactivated)\nPanopto: https://bit.ly/33ZkU97\nZoom: https://notredame.zoom.us/my/dmoreira\nCourse grades are now available. Progress 01/14/2020 - Syllabus, Course details. 01/16/2020 - Basics I, Biometrics, traits, and systems. 01/21/2020 - Basics II, Errors, metrics, and attacks. 01/23/2020 - 1st Coding Class, Implementation of metrics. 01/28/2020 - Fingerprint Recog. I, History and features. 01/30/2020 - Fingerprint Recog. II, Acquisition and enhancement. 02/04/2020 - Fingerprint Recog. III, Minutiae detection. 02/06/2020 - Fingerprint Data Collection, password with instructor. 02/11/2020 - 2nd Coding Class, Minutiae-based recognition. 02/13/2020 - 2nd Coding Class, continuation. 02/18/2020 - Face Recog. I, Why faces and faces vs. fingerprints. 02/20/2020 - Face Recog. II, Acquisition and enhancement. 02/25/2020 - Face Recog. III, Description and matching. 02/27/2020 - 3rd Coding Class, Face recognition. 03/03/2020 - Fingerprints assignment, Developers’ day. 03/05/2020 - Fingerprints assignment, Attackers’ day. 03/10/2020 - Spring Break. 03/12/2020 - Spring Break. 03/17/2020 - Extended Spring Break1. 03/18/2020 - Extended Spring Break1. 03/24/2020 - New Course Directions1. 03/26/2020 - Iris Recog. I, Why irises and irises vs. other traits. 03/31/2020 - Iris Recog. II, Acquisition and enhancement. 04/02/2020 - Iris Recog. III, Description and matching. 04/07/2020 - 4th Coding Class, Iris recognition. 04/09/2020 - Multibiometrics, Other traits, data fusion. 04/14/2020 - 1st Invited Talk, Dr. Andrey Kuehlkamp. 04/16/2020 - 2nd Invited Talk, Dr. Adam Czajka. 04/21/2020 - Faces assignment, Developers’ day. 04/23/2020 - Irises assignment, Developers’ day. 04/28/2020 - Assignment Report due date. 05/04/2020 - Final exam, see grades. Important Dates 03/03/2020 - Fingerprints assignment, Developers’ day. 03/05/2020 - Fingerprints assignment, Attackers’ day. 03/31/2020 - Faces assignment, Developers’ day.1 04/02/2020 - Faces assignment, Attackers’ day.1 04/14/2020 - Irises assignment, Developers’ day.1 04/16/2020 - Irises assignment, Attackers’ day.1 04/28/2020 - Last assignment, Collaboration day.1 04/14/2020 (5:05 PM at Zoom) - Dr. Andrey Kuehlkamp’s talk. 04/16/2020 (5:05 PM at Zoom) - Dr. Adam Czajka’s talk. 04/21/2020 - Faces assignment, Developers’ day1. 04/23/2020 - Irises assignment, Developers’ day1. 04/28/2020 - Final Report due date1. 05/04/2020 - Final exam. Invited Talks Dr. Andrey Kuehlkamp Postdoctoral Research Associate at the Center for Research Computing, University of Notre Dame Diverse Aspects in Advancing Iris Recognition Systems Are we ready for widespread, mass-scale adoption of iris recognition systems? Following the miniaturization of fingerprint scanners, these have dominated recognition systems and have even become almost commonplace for unlocking cell phones, but what if in the not-so-far-off future they were replaced with iris scanners, would you be comfortable with it? Since its initial introduction in 1993, automated iris recognition has dramatically grown in popularity and soon could become the dominant method for automated recognition. Take for example the largest recognition system in the world — India’s Aadhaar program — which has collected more than 1.1 billion irises from their citizens to be used as the primary identification for banking, pensions, and welfare programs. Even more recently — November 2017 — Somaliland became the first country in the world to use iris recognition as the means for identification in a public election, which had more than 800,000 registered voters. Although a mature technology in many regards, the drastic increase in iris recognition adoption has revealed many opportunities for improvement. In this talk I present an overview of my research, which focuses on improving iris recognition in three ways: speed, accuracy, and robustness. Dr. Adam Czajka Assistant Professor at the Department of Computer Science and Engineering, University of Notre Dame Is this eye alive or artificial? Oh wait, maybe it’s dead? Detection of unknown presentation attacks in biometrics. Presentation attacks are those physical presentations to a biometric system that aim at driving it into an incorrect decision. Rediscovered recently in general computer vision community (and raising a significant interest; look — for instance — for famous stop sign attacks on deep learning-based object detection models), these attacks are known in biometrics for several …","date":1578960000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578960000,"objectID":"121fb4f8057a9a39884ee21fcdbea52e","permalink":"https://danielmoreira.github.io/teaching/biometrics-spr20/","publishdate":"2020-01-14T00:00:00Z","relpermalink":"/teaching/biometrics-spr20/","section":"teaching","summary":"CSE 40537 / 60537 Biometrics","tags":["Teaching","Biometrics","Fingerprint Recognition","Face Recognition","Iris Recognition"],"title":"Biometrics, Spring 2020","type":"teaching"},{"authors":null,"categories":null,"content":"One of the things I worry about while doing my research is how to drive it towards building a better society. Although the concept of a better society may differ from one culture to the other, I believe any society gets better whenever all of its members experience more freedom to enjoy their rights.\nAmong the untold manners technology can be used to breach people’s rights, five flaws in the way we are doing informatics get my attention. Devices and programs usually suffer from (1) lack of safety, (2) lack of trustworthiness, (3) lack of privacy, (4) ignorance of diversity, and (5) lack of accountability. Not unintentionally, the projects I’ve been contributing to in the past few years tackle one or more of these issues.\nSafety From the many ways safety can be harmed by technology, the improper dissemination of sensitive content (such as pornography or violence), to inadequate audiences (such as kids or unwary spectators), gained my attention while I was developing my PhD, under the supervision of prof. Anderson Rocha (who generously proposed the topic).\nWith the popularity and pervasiveness of online video streams, sensitive scenes depicting suicide, murder, and even rape have been broadcasted on the Internet, raising questions about the safety of these services. Aware of this situation, Samsung has funded us to focus on the development of solutions to detect sensitive video. Rather than aiming at denouncing or morally condemning the lawful consumers of certain types of sensitive content, our intent has always been to support the implementation of filtering and warning features that would make player systems safer (especially in the case of child spectators).\nI’ve had the chance to tackle the lack of safety in video streaming systems through the SMA project.\nTrustworthiness In the era of misinformation and fake news, there is a symptomatic undermining of trust not only in textual but also in visual information. People are conscious of the existence of image editing software (e.g., Photoshop), with which even unskilled users can easily fabricate and manipulate pictures. Although many of these manipulations have benign purposes (no, there is nothing wrong with your memes), some contents are generated with malicious intents, such as general public deception and propaganda.\nThe lack of available solutions to assess the integrity of images and videos allows adversarial manipulated data to have a negative impact on the way people relate to each other on the Internet. They don’t know what to believe or whom to trust anymore. In addition, fraudulent images represent a challenge even for the scientific community. Aware of this scenario, DARPA has been funding us, at CVRL, to conduct research on the development of tools to verify the integrity of digital images.\nI’m having the chance to tackle the lack of trustworthiness in visual media systems through the MediFor and Sci-Int projects.\nPrivacy and Diversity With the advent of deep learning and the necessity for large datasets, visual data collection has become an important step of Computer Vision and Machine Learning research. Due to the popularity of image and video capture devices (such as digital cameras, smartphones, dash cams, etc.), large datasets can now be quickly generated. Nevertheless, a major question that stands out in such a process is how to protect the privacy of people who are eventually being recorded. Imagine, for example, a dash cam that is collecting road data for a self-driving car project. In a major city, plenty of people will certainly be captured in the footages, and it is very unlikely that one will be able to obtain image rights for each individual.\nInterested in such issue, we, at CVRL, investigate the generation of realistic synthetic faces, whose identities do not belong to a real existing person, hence avoiding privacy breaches. The idea is to de-identify the recorded individuals, by replacing their faces with synthetic assets.\nIn addition, collected data may be biased, due to a lack of diversity in the captured individuals. Consider, for instance, training video footages collected in China. It is very unlikely that black people will be represented in such a dataset.\nLimitations of this nature comprise what I call ignorance of diversity and are the potential cause of many technological failures in the presence of underrepresented groups. Unfortunately, glitches like these may go beyond the technological aspects and prejudice the rights of equality in face of diversity. To cope with this problem, similar to the privacy protection strategy, synthetic identities can be used to diversify the recorded individuals by performing face replacement, providing controlled variation of not only ethnicity but also of age and of gender.\nI’m having the chance to tackle the lack of privacy and ignorance of diversity in image and video datasets through the SREFV project.\nAccountability People have the right to understand in details the decisions made …","date":1560384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560384000,"objectID":"07602f928b69d804bda2d657c4b532e7","permalink":"https://danielmoreira.github.io/post/bettersoc/","publishdate":"2019-06-13T00:00:00Z","relpermalink":"/post/bettersoc/","section":"post","summary":"What does a better society mean?","tags":["AI for good"],"title":"A Better Society","type":"post"},{"authors":null,"categories":null,"content":"Status: Concluded, Funded by: DARPA\nAdvisor: Prof. Walter Scheirer\nHost: University of Notre Dame\nThe Media Forensics research project (MediFor) is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA) and the Air Force Research Laboratory (AFRL), whose goal is to develop solutions for the automated assessment of the integrity of digital images.\nWorking together with the Universities of Purdue, South California (USC), New York (NYU), Siena, Campinas (Unicamp), and the Politécnico di Milano, our team leads the development of solutions to the problem of Provenance Analysis. Given a questioned image, namely a probe, and a large corpus of images (such as the Internet), Provenance Analysis aims at two major tasks:\nFinding the images that directly and transitively share content with the probe (a task we call Provenance Filtering).\nBuilding the directed acyclic graph whose nodes individually represent the probe and related images, and whose edges express the edition and content-donation history (e.g., cropping, blurring, removal, splicing, etc.) between pairs of images, linking seminal to generated elements (a task we call Provenance Graph Construction).\nBy combining ideas from the areas of image retrieval, digital image forensics, and graph theory, Provenance Analysis constitutes an interesting interdisciplinary topic that spans the fields of image processing and computer vision.\nResearch Team Prof. Walter Scheirer (PI) Prof. Anderson Rocha (PI) Prof. Kevin Bowyer (PI) Prof. Patrick Flynn (PI) Daniel Moreira (Postdoc) Aparna Bharati (PhD Student) Joel Brogan (PhD Student) Allan Pinto (PhD Student) Michael Parowski (Undergrad Student) Patricia Hale (Undergrad Student) William Badart (Undergrad Student) ","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"2ce2b93ee954a04842b88663b1a80847","permalink":"https://danielmoreira.github.io/project/medifor/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/project/medifor/","section":"project","summary":"Integrity assessment of digital images through content provenance analysis.","tags":["Media Forensics","Provenance Analysis","Provenance Filtering","Provenance Graph Construction"],"title":"MediFor","type":"project"},{"authors":null,"categories":null,"content":"Status: Concluded\nAdvisor: Prof. Patrick Flynn\nHost: University of Notre Dame\nThe SREFV project aims at extending prior research on synthesis of realistic faces, to support the generation of videos containing animated faces with synthetic identities, depicted either frontally or in varying poses.\nBesides the obvious artistic and entertainment purposes, the outcome of this project will constitute an interesting tool to de-identify and diversify the faces depicted in video training datasets, helping to protect the identity of volunteers, and to mitigate eventual age, gender, and ethnic dataset collection biases.\nResearch Team Prof. Patrick Flynn (PI) Prof. Kevin Bowyer (PI) Prof. Adam Czajka (PI) Prof. Walter Scheirer (PI) Daniel Moreira (Postdoc) Sandipan Banerjee (PhD Student) ","date":1559260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559260800,"objectID":"537f8411954a4c4c6b9bc998a07a6d40","permalink":"https://danielmoreira.github.io/project/srefv/","publishdate":"2019-05-31T00:00:00Z","relpermalink":"/project/srefv/","section":"project","summary":"Synthesis of Realistic Example Face Videos.","tags":["Face Synthesis","Identity Synthesis","Video Synthesis","Biometrics"],"title":"SREFV","type":"project"},{"authors":null,"categories":null,"content":"Status: Concluded\nAdvisor: Prof. Adam Czajka\nHost: University of Notre Dame\nThe TSHEPII project aims at developing a software tool to support the human examination of post-mortem iris images. The tool puts together diverse computer vision techniques to automatically process, extract, annotate, and match iris regions from two different eye captures. The idea is to give to the user enough iris texture matching and non-matching information, so they can decided if the two given images depict the same eye or not.\nThe video above depicts a demo of the TSHEPII tool, with all the computer vision techniques added to the software. As the project name suggests (Tool Supporting the Human Examination of Post-Mortem Iris Images), the tool is particularly tuned to the case of comparing post-mortem irises, which, contrary to the common sense, might still be useful for performing iris recognition.\nResearch Team Prof. Adam Czajka (PI) Prof. Patrick Flynn (PI) Prof. Kevin Bowyer (PI) Daniel Moreira (Postdoc) Mateusz Trokielewicz (PhD Student) M.D. Piotr Maciejewicz (Collaborator) ","date":1559088000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559088000,"objectID":"6e56f34183b51fc8d0f9e6ff96491f5d","permalink":"https://danielmoreira.github.io/project/tshepii/","publishdate":"2019-05-29T00:00:00Z","relpermalink":"/project/tshepii/","section":"project","summary":"Tool Supporting the Human Examination of Post-Mortem Iris Images.","tags":["Iris Recognition","Post-Mortem Iris Recognition","Biometrics"],"title":"TSHEPII","type":"project"},{"authors":null,"categories":null,"content":" Status: Concluded, Funded by: Samsung Eletrônica da Amazônia Ltda.\nAdvisor: Prof. Anderson Rocha\nHost: University of Campinas\nAbout Temporal Robust Features (TRoF) comprise a spatiotemporal video content detector and a descriptor developed to present low-memory footprint and small runtime. It was shown to be effective for the tasks of pornography and violence detection. Please refer to both articles for further technical details.\nUsage TRoF executable is available through a docker image, available here. Prior to running it, you have to install docker (available for various OS platforms). Once docker is running, you have to execute the following scripts, in command line:\nyour-computer$ docker run -ti dmoreira/trof bash docker-instance# cd TRoF docker-instance# ./fast_trof_descriptor Follow the printed usage instructions for running TRoF. The software reads a video input file and outputs float feature vectors, one per line, in the following format:\nx y t v1 v2 v3 ... vn Pleaser refer to either here or here, if you want to add videos to a running TRoF docker instance.\nCitation If you are using TRoF, please cite:\n@article{moreira2016fsi, title = {Pornography classification: the hidden clues in video space-time}, author={Daniel Moreira and Sandra Avila and Mauricio Perez and Daniel Moraes and Vanessa Testoni and Eduardo Valle and Siome Goldenstein and Anderson Rocha}, journal = {Elsevier Forensic Science International}, year = {2016}, volume = {268}, number = {1}, pages = {46--61} } Disclaimer This software is provided by the authors as is, with no warranties and no support, for academic purposes only. The authors assume no responsibility or liability for the use of the software. They do not convey any license or title under any patent or copyright, and they reserve the right to make changes in the software without notification.\nAcknowledgments This software was developed through the project “Sensitive Media Analysis”, hosted at the University of Campinas, and sponsored by Samsung Eletronica da Amazonia Ltda., in the framework of the Brazilian law N. 815 8,248/91. We thank the financial support of the Brazilian Council for Scientific and Technological Development - CNPq (Grants #477662/2013-7, #304472/2015-8), the Sao Paulo Research Foundation - Fapesp (DejaVu Grant #2015/19222-9), and the Coordination for the Improvement of Higher Level Education Personnel - CAPES (DeepEyes project).\n","date":1559001600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559001600,"objectID":"1de616391e830170d5282040d55a25f9","permalink":"https://danielmoreira.github.io/project/trof/","publishdate":"2019-05-28T00:00:00Z","relpermalink":"/project/trof/","section":"project","summary":"Temporal Robust Features, a fast spatiotemporal video content detector and descriptor.","tags":["Video Description and Representation","TRoF"],"title":"TRoF","type":"project"},{"authors":null,"categories":null,"content":"Status: Concluded, Funded by: Samsung Eletrônica da Amazônia Ltda.\nAdvisor: Prof. Anderson Rocha\nHost: University of Campinas\nThe Sensitive Media Analysis (SMA) project aims at researching solutions to combine different and complementary data representations and pattern classifiers for detecting sensitive content in digital images and videos.\nSensitive media can be defined as the digital content whose depiction to particular audiences (e.g., children or unwary spectators), at particular places (e.g., at work, at school, in the church) may inflict harm (e.g., trauma, shock, or fear) due to its inappropriateness. Typical representatives include – but are not limited to – scenes depicting pornography and violence, animal cruelty and child abuse, hate speech, etc.\nThe innovation aspects of the project reside on the development of solutions that are amenable to deployment on mobile devices (e.g., smartphones and tablets), observing their constraints of memory footprint, processing power, and runtime responsiveness.\nResearch Team Prof. Anderson Rocha (PI) Prof. Siome Goldenstein (PI) Prof. Eduardo Valle (PI) Dr. Vanessa Testoni (Samsung Collaborator) Dr. Sandra Avila (Postdoc) Daniel Moreira (PhD Student) Mauricio Perez (MSc Student) Daniel Moraes (Developer) ","date":1558915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558915200,"objectID":"8c202c01c9c0cb8865f1f79d879ccdda","permalink":"https://danielmoreira.github.io/project/sma/","publishdate":"2019-05-27T00:00:00Z","relpermalink":"/project/sma/","section":"project","summary":"Sensitive Media Analysis through the detection and localization of sensitive video content.","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection"],"title":"SMA","type":"project"},{"authors":["Sandra Avila","Daniel Moreira","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1548720000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548720000,"objectID":"d5edbd8365c7dddf14bb76b8cdcce3f6","permalink":"https://danielmoreira.github.io/publication/2019_patent/","publishdate":"2019-01-29T00:00:00Z","relpermalink":"/publication/2019_patent/","section":"publication","summary":"2019 US Patent Office","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection","Multimodal Data Fusion"],"title":"Multimodal and real-time method for filtering sensitive media","type":"publication"},{"authors":["Aparna Bharati","Daniel Moreira","Joel Brogan","Patricia Hale","Kevin Bowyer","Patrick Flynn","Anderson Rocha","Walter Scheirer"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546819200,"objectID":"cec704dbc02dcdd4772cdada6dabda4f","permalink":"https://danielmoreira.github.io/publication/2019_wacv_metada/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/2019_wacv_metada/","section":"publication","summary":"2019 IEEE Winter Conference on Applications of Computer Vision","tags":["Media Forensics","Provenance Analysis","Provenance Graph Construction"],"title":"Beyond Pixels: Image Provenance Analysis Leveraging Metadata","type":"publication"},{"authors":["Adam Czajka","Daniel Moreira","Kevin Bowyer","Patrick Flynn"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546819200,"objectID":"8dbd380984ae361a7a51034f1a7fe26c","permalink":"https://danielmoreira.github.io/publication/2019_wacv_bsif/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/2019_wacv_bsif/","section":"publication","summary":"2019 IEEE Winter Conference on Applications of Computer Vision","tags":["Iris Recognition","BSIF","Biometrics"],"title":"Domain-Specific Human-Inspired Binarized Statistical Image Features for Iris Recognition","type":"publication"},{"authors":["Daniel Moreira","Mateusz Trokielewicz","Adam Czajka","Kevin Bowyer","Patrick Flynn"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546819200,"objectID":"fba13bfc64b4a1351fe20af6d9bb8a78","permalink":"https://danielmoreira.github.io/publication/2019_wacv_human/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/2019_wacv_human/","section":"publication","summary":"2019 IEEE Winter Conference on Applications of Computer Vision","tags":["Iris Recognition","Human Performance","Biometrics"],"title":"Performance of Humans in Iris Recognition: The Impact of Iris Condition and Annotation-Driven Verification","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"841df25d6df2414cfad507adb08dbab6","permalink":"https://danielmoreira.github.io/publication/2019_if/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/2019_if/","section":"publication","summary":"2019 Elsevier Information Fusion","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection","Multimodal Data Fusion"],"title":"Multimodal data fusion for sensitive scene localization","type":"publication"},{"authors":["Daniel Moreira","Aparna Bharati","Joel Brogan","Allan Pinto","Michael Parowski","Kevin Bowyer","Patrick Flynn","Anderson Rocha","Walter Scheirer"],"categories":null,"content":"","date":1534377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534377600,"objectID":"4b2f08ef5a215cbc816e2d78b1acc987","permalink":"https://danielmoreira.github.io/publication/2018_tip/","publishdate":"2018-08-16T00:00:00Z","relpermalink":"/publication/2018_tip/","section":"publication","summary":"2018 IEEE Transactions on Image Processing","tags":["CBIR","Media Forensics","Provenance Analysis","Provenance Filtering","Provenance Graph Construction"],"title":"Image Provenance Analysis at Scale","type":"publication"},{"authors":["Nathaniel Blanchard","Daniel Moreira","Aparna Bharati","Walter Scheirer"],"categories":null,"content":"","date":1532044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532044800,"objectID":"02bff565c8b8a0844a62c8358bf0b176","permalink":"https://danielmoreira.github.io/publication/2018_acl/","publishdate":"2018-07-20T00:00:00Z","relpermalink":"/publication/2018_acl/","section":"publication","summary":"2018 ACL Grand Challenge and Workshop on Human Multimodal Language","tags":["Sentiment Classification","Multimodal Data Fusion"],"title":"Getting the subtext without the text: Scalable multimodal sentiment classification from visual and acoustic modalities","type":"publication"},{"authors":["Sandra Avila","Daniel Moreira","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1507593600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1507593600,"objectID":"d081d8e219b281b95d7d562e0344c762","permalink":"https://danielmoreira.github.io/publication/2017_patent/","publishdate":"2017-10-10T00:00:00Z","relpermalink":"/publication/2017_patent/","section":"publication","summary":"2017 BR Instituto Nacional de Propriedade Industrial","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection","Multimodal Data Fusion"],"title":"Método multimodal e em tempo real para filtragem de conteúdo sensível","type":"publication"},{"authors":["Allan Pinto","Daniel Moreira","Aparna Bharati","Joel Brogan","Kevin Bowyer","Patrick Flynn","Walter Scheirer","Anderson Rocha"],"categories":null,"content":"","date":1505865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505865600,"objectID":"01756fc5abf88d5fa03edf5125183c98","permalink":"https://danielmoreira.github.io/publication/2017_icip_filtering/","publishdate":"2017-09-20T00:00:00Z","relpermalink":"/publication/2017_icip_filtering/","section":"publication","summary":"2017 IEEE International Conference on Image Processing","tags":["Media Forensics","Provenance Analysis","Provenance Filtering"],"title":"Provenance filtering for multimedia phylogeny","type":"publication"},{"authors":["Joel Brogan","Paolo Bestagini","Aparna Bharati","Allan Pinto","Daniel Moreira","Kevin Bowyer","Patrick Flynn","Anderson Rocha","Walter Scheirer"],"categories":null,"content":"","date":1505865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505865600,"objectID":"02147cfb5fb75dce768201eadfb88ecb","permalink":"https://danielmoreira.github.io/publication/2017_icip_spotting/","publishdate":"2017-09-20T00:00:00Z","relpermalink":"/publication/2017_icip_spotting/","section":"publication","summary":"2017 IEEE International Conference on Image Processing","tags":["Media Forensics","Provenance Analysis","Provenance Filtering","Forgery Detection","Forgery Localization"],"title":"Spotting the difference: Context retrieval and analysis for improved forgery detection and localization","type":"publication"},{"authors":["Aparna Bharati","Daniel Moreira","Allan Pinto","Joel Brogan","Kevin Bowyer","Patrick Flynn","Walter Scheirer","Anderson Rocha"],"categories":null,"content":"","date":1505865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505865600,"objectID":"e0e55df34f95abd748c49a3c73976a22","permalink":"https://danielmoreira.github.io/publication/2017_icip_uphylogeny/","publishdate":"2017-09-20T00:00:00Z","relpermalink":"/publication/2017_icip_uphylogeny/","section":"publication","summary":"2017 IEEE International Conference on Image Processing","tags":["Media Forensics","Provenance Analysis","Provenance Graph Construction"],"title":"U-Phylogeny: Undirected provenance graph construction in the wild","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":" ","date":1490313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1490313600,"objectID":"d6e6309c8877cb2a9c81810845939da6","permalink":"https://danielmoreira.github.io/publication/2017_wacv/","publishdate":"2017-03-24T00:00:00Z","relpermalink":"/publication/2017_wacv/","section":"publication","summary":"2017 IEEE Winter Conference on Applications of Computer Vision","tags":["Sensitive Media Analysis","Violence Detection","TRoF"],"title":"Temporal Robust Features for Violence Detection","type":"publication"},{"authors":["Mauricio Perez","Sandra Avila","Daniel Moreira","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1490140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1490140800,"objectID":"15191369fe40e5bb02e6086be58c4f73","permalink":"https://danielmoreira.github.io/publication/2017_neurocomputing/","publishdate":"2017-03-22T00:00:00Z","relpermalink":"/publication/2017_neurocomputing/","section":"publication","summary":"2017 Elsevier Neurocomputing","tags":["Sensitive Media Analysis","Pornography Detection","Deep Learning"],"title":"Video pornography detection through deep learning techniques and motion information","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1477958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477958400,"objectID":"7494b3fed906e23b0a676deb4fd9433b","permalink":"https://danielmoreira.github.io/publication/2016_fsi/","publishdate":"2016-11-01T00:00:00Z","relpermalink":"/publication/2016_fsi/","section":"publication","summary":"2016 Elsevier Forensic Science International","tags":["Sensitive Media Analysis","Pornography Detection","TRoF"],"title":"Pornography classification: The hidden clues in video space–time","type":"publication"},{"authors":["Daniel Moreira"],"categories":null,"content":"","date":1468886400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1468886400,"objectID":"d94521536cfd9af15a24e02b6019a4ec","permalink":"https://danielmoreira.github.io/publication/2016_dissertation/","publishdate":"2016-07-19T00:00:00Z","relpermalink":"/publication/2016_dissertation/","section":"publication","summary":"2016 PhD Dissertation","tags":["Sensitive Media Analysis","Pornography Detection","Violence Detection","TRoF"],"title":"Sensitive-Video Analysis","type":"publication"},{"authors":["Daniel Moreira","Sandra Avila","Mauricio Perez","Daniel Moraes","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1444953600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1444953600,"objectID":"7fa554d52ea776bd773cd0077ad60f5a","permalink":"https://danielmoreira.github.io/publication/2015_mediaeval/","publishdate":"2015-10-16T00:00:00Z","relpermalink":"/publication/2015_mediaeval/","section":"publication","summary":"2015 Mediaeval Workshop","tags":["Sensitive Media Analysis","Violence Detection","MediaEval"],"title":"RECOD at MediaEval 2015: Affective Impact of Movies Task","type":"publication"},{"authors":["Sandra Avila","Daniel Moreira","Mauricio Perez","Daniel Moraes","Isabela Cota","Vanessa Testoni","Eduardo Valle","Siome Goldenstein","Anderson Rocha"],"categories":null,"content":"","date":1413417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1413417600,"objectID":"70ffa72781253d07b83dc47ed4e8837b","permalink":"https://danielmoreira.github.io/publication/2014_mediaeval/","publishdate":"2014-10-16T00:00:00Z","relpermalink":"/publication/2014_mediaeval/","section":"publication","summary":"2014 Mediaeval Workshop","tags":["Sensitive Media Analysis","Violence Detection","MediaEval"],"title":"RECOD at MediaEval 2014: Violent Scenes Detection Task","type":"publication"},{"authors":["Daniel Moreira"],"categories":null,"content":"","date":1220486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1220486400,"objectID":"6cef3b4dd19663ea348ea49b1ce314bf","permalink":"https://danielmoreira.github.io/publication/2008_thesis/","publishdate":"2008-09-04T00:00:00Z","relpermalink":"/publication/2008_thesis/","section":"publication","summary":"2008 Master's Thesis (in Portuguese)","tags":["Multi-agent Systems","Multi-agent Patrolling","Multi-agent Benchmarks","Multi-agent Simulators","SimPatrol","Portuguese"],"title":"SimPatrol: um simulador de sistemas multiagentes para o patrulhamento","type":"publication"}]