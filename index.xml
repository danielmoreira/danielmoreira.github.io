<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Daniel Moreira</title>
    <link>https://danielmoreira.github.io/</link>
      <atom:link href="https://danielmoreira.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Daniel Moreira</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 30 Oct 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://danielmoreira.github.io/media/sharing.jpg</url>
      <title>Daniel Moreira</title>
      <link>https://danielmoreira.github.io/</link>
    </image>
    
    <item>
      <title>Unveiling scientific articles from paper mills with provenance analysis</title>
      <link>https://danielmoreira.github.io/publication/2024_plosone/</link>
      <pubDate>Wed, 30 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2024_plosone/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Exploring Saliency Bias in Manipulation Detection</title>
      <link>https://danielmoreira.github.io/publication/2024_icip/</link>
      <pubDate>Fri, 27 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2024_icip/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Biometrics, Fall 2024</title>
      <link>https://danielmoreira.github.io/teaching/biometrics-aut24/</link>
      <pubDate>Wed, 21 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/biometrics-aut24/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/biometrics-aut24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/biometrics-aut24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/biometrics-aut24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 388-002 / COMP 488-002 Computer Science Topics&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;br&gt;
TA: Fiona Nicdao (&lt;a href=&#34;mailto:fnicdao@luc.edu&#34;&gt;fnicdao@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: MON and WED, 4:15 to 5:30 PM, in person at 408 Mundelein Center&lt;br&gt;
Office Hours: MON and WED evenings, and FRI afternoons,&lt;br&gt;
310 Doyle Center or Zoom, &lt;a href=&#34;https://calendly.com/danielmoreira/fall-2024-office-hours&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt;&lt;br&gt;
Sakai: &lt;a href=&#34;https://sakai.luc.edu/x/9WVTcd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://sakai.luc.edu/x/9WVTcd&lt;/a&gt;&lt;/p&gt;
&lt;!-- &gt; Final grades were released on Sakai. Thank you, everyone! --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;!-- ![Presentation attacks done by students.](fake.png) --&gt;
&lt;p&gt;How do computers match a person&amp;rsquo;s fingerprints?
Do they still use the same techniques proposed in the XIX century?
How do computers identify people captured in a video?
Do they leverage the depicted faces only, or can they use other traits such as gait or voice?
How about iris recognition as portrayed in the movies?
Is it really possible?
What happens in the case of people who look very similar, such as identical twins?
Which traits are more reliable and robust to impersonation or prone to falsification?
These are some of the questions we will address in this course, whose main topic is Biometrics.
In a nutshell, Biometrics is the study of techniques to identify individuals through their physical, chemical,
and behavioral traits, such as fingerprints, face, iris, DNA, voice, gait, etc.
Our focus will be on the technical and ethical aspects of computer-aided Biometrics,
discussing the issues of going from simple and benign authentication to the more problematic case of surveillance.
The course will have an intense hands-on approach, with the collection of samples and implementation of fingerprint,
face, and iris recognition.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Requirements to attend this course are basic programming skills (especially Python).
This course and its materials are also available in &lt;a href=&#34;https://sakai.luc.edu/x/9WVTcd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;schedule-tentative&#34;&gt;Schedule &lt;em&gt;(Tentative)&lt;/em&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;08/26 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_01.pdf&#34;&gt;Syllabus,&lt;/a&gt; Course details.&lt;/li&gt;
&lt;li&gt;08/28 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_02.pdf&#34;&gt;Basics I,&lt;/a&gt; Biometrics, traits, and systems.&lt;/li&gt;
&lt;li&gt;09/02 - Labor Day, &lt;em&gt;no classes&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;09/04 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_03.pdf&#34;&gt;Basics II,&lt;/a&gt; Biometric systems, errors, and metrics.&lt;/li&gt;
&lt;li&gt;09/09 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_04.pdf&#34;&gt;1st Coding Class,&lt;/a&gt; Metrics&amp;rsquo; implementation.&lt;/li&gt;
&lt;li&gt;09/11 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_05.pdf&#34;&gt;Fingerprint Recog. I,&lt;/a&gt; History and features.&lt;/li&gt;
&lt;li&gt;09/16 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_06.pdf&#34;&gt;Fingerprint Recog. II,&lt;/a&gt; Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;09/18 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_07.pdf&#34;&gt;Fingerprint Recog. III,&lt;/a&gt; Minutiae detection.&lt;/li&gt;
&lt;li&gt;09/23 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_08.pdf&#34;&gt;Fingerprint Recog. IV,&lt;/a&gt; Data collection.&lt;/li&gt;
&lt;li&gt;09/25 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_08.pdf&#34;&gt;2nd Coding Class&lt;/a&gt;, Fingerprint recognition.&lt;/li&gt;
&lt;li&gt;09/30 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_09.pdf&#34;&gt;Face Recog. I,&lt;/a&gt; Why faces and faces vs. other traits.&lt;/li&gt;
&lt;li&gt;10/02 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_11.pdf&#34;&gt;Midterm Preparation,&lt;/a&gt; Recap and project discussion.&lt;/li&gt;
&lt;li&gt;10/07 - Fall Break, &lt;em&gt;no classes&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;10/09 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/exams/midterm_answers.pdf&#34;&gt;Midterm Exam,&lt;/a&gt; &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/exams/midterm_grades.pdf&#34;&gt;grades.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10/14 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_10.pdf&#34;&gt;Face Recog. II,&lt;/a&gt; Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;10/16 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_12.pdf&#34;&gt;Face Recog. III,&lt;/a&gt; Description and matching.&lt;/li&gt;
&lt;li&gt;10/21 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_13.pdf&#34;&gt;Face Recog. IV,&lt;/a&gt; Deep learning face recognition.&lt;/li&gt;
&lt;li&gt;10/23 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_14.pdf&#34;&gt;3rd Coding Class,&lt;/a&gt; Face recognition.&lt;/li&gt;
&lt;li&gt;10/28 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_15.pdf&#34;&gt;Iris Recog. I,&lt;/a&gt; Why irises and irises vs. other traits.&lt;/li&gt;
&lt;li&gt;10/30 - &lt;a href=&#34;#reading&#34;&gt;Reading Activity,&lt;/a&gt; &lt;em&gt;no classes&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;11/04 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_16.pdf&#34;&gt;Iris Recog. II,&lt;/a&gt; Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;11/04 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/slides/lecture_17.pdf&#34;&gt;Iris Recog. III,&lt;/a&gt; Description and matching.&lt;/li&gt;
&lt;li&gt;11/06 - 4th Coding Class, Iris recognition.&lt;/li&gt;
&lt;li&gt;11/11 - Other Traits, Alternative traits and Soft Biometrics.&lt;/li&gt;
&lt;li&gt;11/13 - Multibiometrics, Data fusion.&lt;/li&gt;
&lt;li&gt;11/18 - 1st Invited Talk, Dr. Adam Czajka. &lt;!-- ,](#abharati) Dr. Aparna Bharati. --&gt;&lt;/li&gt;
&lt;li&gt;11/20 - 2nd Invited Talk, Dr. Dinko Bačić. &lt;!-- ,](#aczajka) Dr. Adam Czajka. --&gt;&lt;/li&gt;
&lt;li&gt;11/25 - Feature Indexing, Index building and feature querying.&lt;/li&gt;
&lt;li&gt;11/27 - Thanksgiving, &lt;em&gt;no classes&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;12/02 - Office Hours to Conclude Projects, &lt;em&gt;no classes&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;12/04 - &lt;a href=&#34;#project&#34;&gt;Project presentations.&lt;/a&gt; &lt;!-- , 5 groups present. --&gt;&lt;/li&gt;
&lt;li&gt;12/09 - Final Exam. &lt;!-- Grades on Sakai. --&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;important-dates&#34;&gt;Important Dates&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;08/26 - First Class.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;09/02 - Labor Day, no classes.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;09/09 - 1st Coding Class.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;09/25 - 2nd Coding Class and 1st Assignment deadline.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;10/07 - Fall Break, no classes.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;10/09 - Midterm Exam.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;10/23 - 3rd Coding Class.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;10/24 - 2nd Assignment deadline.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;11/06 - 4th Coding Class.&lt;/li&gt;
&lt;li&gt;11/12 - 3rd Assignment deadline.&lt;/li&gt;
&lt;li&gt;11/18 - Dr. Czajka&amp;rsquo;s Talk.&lt;/li&gt;
&lt;li&gt;11/20 - Dr. Bačić&amp;rsquo;s Talk.&lt;/li&gt;
&lt;li&gt;11/27 - Thanksgiving, no classes.&lt;/li&gt;
&lt;li&gt;12/04 - Project presentations.&lt;/li&gt;
&lt;li&gt;12/09 - Final Exam.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- * ~~10/02 - 1st Assignment deadline.~~ --&gt;
&lt;!-- * ~~10/16 - 2nd Assignment deadline.~~ --&gt;
&lt;!-- * ~~11/13 - 3rd Assignment deadline.~~ --&gt;
&lt;!-- * ~~11/27 - Dr. Aparna Bharati’s talk.~~ --&gt;
&lt;!-- * ~~12/06 - Dr. Adam Czajka’s talk.~~ --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;notebooks-for-coding-classes&#34;&gt;Notebooks &lt;em&gt;(for coding classes)&lt;/em&gt;&lt;/h2&gt;
&lt;!-- *Online notebooks will be linked here as we move forward with the classes.* --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1Yd-C7m8bhHP7-QcJH70iJyyjgrKOBaNT&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 01,&lt;/a&gt; Metrics&amp;rsquo; implementation.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1a6JdRkwRAMtyRif2LTIchtMCgsa7KL9l&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 02,&lt;/a&gt; Fingerprint recognition.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/18-PZJTQt1v7Pej37uVmZYNTZFdiiM2cG&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 03,&lt;/a&gt; Face recognition.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- * [Notebook 04,](https://colab.research.google.com/drive/1rJ5vjm48eMAg5ZdHApazo3X_IVMvIDKc) Iris recognition. --&gt;
&lt;hr&gt;
&lt;!-- &lt;a name=&#34;abharati&#34;&gt;&lt;/a&gt; --&gt;
&lt;h2 id=&#34;invited-talks&#34;&gt;Invited Talks&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Information about the talks will be added here as soon as they are settled.&lt;/em&gt;&lt;/p&gt;
&lt;!--
|                                     |                                                                                                                                                          |
|-------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|
| ![Dr. Aparna Bharati](bharati.jpg)  | [Dr. Aparna Bharati](https://www.aparnabharati.com/)&lt;/br&gt; Assistant Professor&lt;/br&gt; Department of Computer Science and Engineering&lt;/br&gt; Lehigh University |

|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| &lt;b&gt;Synthetic Data in Face Biometrics&lt;/b&gt;&lt;/br&gt;&lt;/br&gt; How do image manipulations affect face recognition? How can computer-aided solutions detect and profile these manipulations? In this talk, I will present my recent work and the findings obtained while trying to answer these questions. We will discuss solutions to detect retouched faces by a variety of methods, including smartphone apps, as well as evaluate when face retouching is a problem for face recognition and our society. Moreover, we will talk about the recent trend of generating synthetic faces and how one can measure identity leakage from the training set to the generated samples, a major privacy issue that indeed deserves attention. Lastly, I introduce our recent work on SynthProv, which allies provenance analysis to synthetic face detection and identity leakage evaluation. &lt;a name=&#34;aczajka&#34;&gt;&lt;/a&gt; |

|                                |                                                                                                                                                                               |
|--------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| ![Dr. Adam Czajka](czajka.jpg) | [Dr. Adam Czajka](https://engineering.nd.edu/faculty/adam-czajka/)&lt;/br&gt; Associate Professor&lt;/br&gt; Department of Computer Science and Engineering&lt;/br&gt; University of Notre Dame |

|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| &lt;b&gt;Do you want a better presentation attack detection algorithm? Tell it where to look!&lt;/b&gt;&lt;/br&gt;&lt;/br&gt; This lecture will discuss the topic of human-machine pairing for building trustworthy and human-interpretable iris recognition and biometric presentation attack detection methods. We will discuss approaches of guiding modern Artificial Intelligence models towards features salient for humans comparing irises (including forensic samples) and detecting spoofing attacks. Such guidance allows the AI methods to generalize to unknown attack types, and to create human-interpretable solutions assisting human examiners. We will discuss also selected approaches for effective use of always-limited human salience information (e.g., utilization of human salience in a teacher-student training paradigm) to scale this methodology to large datasets not accompanied by human annotations.  |
--&gt;
&lt;hr&gt;
&lt;h2 id=&#34;grading&#34;&gt;Grading&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%) &lt;/th&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%) &lt;/th&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%) &lt;/th&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;[96, 100)&lt;/td&gt;
&lt;td&gt;B+&lt;/td&gt;
&lt;td&gt;[88, 92)&lt;/td&gt;
&lt;td&gt;C+&lt;/td&gt;
&lt;td&gt;[76, 80)&lt;/td&gt;
&lt;td&gt;D+&lt;/td&gt;
&lt;td&gt;[64, 68)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A-&lt;/td&gt;
&lt;td&gt;[92, 96)&lt;/td&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;[84, 88)&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;[72, 76)&lt;/td&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;[60, 64)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;B-&lt;/td&gt;
&lt;td&gt;[80, 84)&lt;/td&gt;
&lt;td&gt;C-&lt;/td&gt;
&lt;td&gt;[68, 72)&lt;/td&gt;
&lt;td&gt;F&lt;/td&gt;
&lt;td&gt;(0, 60)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;distribution&#34;&gt;Distribution&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Undergraduate (COMP 388-002)  &lt;/th&gt;
&lt;th&gt;Graduate (COMP 488-002)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Assignments (4)  &lt;/td&gt;
&lt;td&gt;40%&lt;/td&gt;
&lt;td&gt;25%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exams (2)&lt;/td&gt;
&lt;td&gt;50%&lt;/td&gt;
&lt;td&gt;40%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Project&lt;/td&gt;
&lt;td&gt;+10% (optional and extra)&lt;/td&gt;
&lt;td&gt;25%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Participation&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;On the News&lt;/td&gt;
&lt;td&gt;+1% (extra)&lt;/td&gt;
&lt;td&gt;+1% (extra)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;assignments&#34;&gt;Assignments&lt;/h3&gt;
&lt;!-- *Assignment material will be linked here as we move forward with the classes.* --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/assignments/assign_01.pdf&#34;&gt;Assignment 1,&lt;/a&gt; &lt;a href=&#34;https://tinyurl.com/yzewsd94&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;data,&lt;/a&gt; &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/assignments/assign_01_answers.pdf&#34;&gt;good answers.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/assignments/assign_02.pdf&#34;&gt;Assignment 2,&lt;/a&gt; &lt;a href=&#34;https://tinyurl.com/hrpxu62e&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;data,&lt;/a&gt; due on Oct 24.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/assignments/assign_03.pdf&#34;&gt;Assignment 3,&lt;/a&gt; &lt;a href=&#34;https://bit.ly/3Qb9iYY&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;data,&lt;/a&gt; due on Nov 12.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- XyPK04;579?) --&gt;
&lt;!--
* [Assignment 1](/teaching/biometrics-aut23/assign_01.pdf), [data](/teaching/biometrics-aut23/assign_01.zip), [good answers](/teaching/biometrics-aut23/assign_01_answers.pdf).
* [Assignment 2](/teaching/biometrics-aut23/assign_02.pdf), [data](/teaching/biometrics-aut23/assign_02.zip), [good answers](/teaching/biometrics-aut23/assign_02_answers.pdf).
* [Assignment 3](/teaching/biometrics-aut23/assign_03.pdf), [data](/teaching/biometrics-aut23/assign_03_data.zip), [good answers](/teaching/biometrics-aut23/assign_03_answers.pdf).
* [Assignment 4](/teaching/biometrics-aut23/assign_04.pdf), [data](/teaching/biometrics-aut23/assign_04_data.zip), [good answers](/teaching/biometrics-aut23/assign_04_answers.pdf).
--&gt;
&lt;!-- XyPK04;579?) --&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Late Policy&lt;/strong&gt;&lt;br&gt;
Deduction of 10% of the maximum possible grade for each day of delay.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;exams&#34;&gt;Exams&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Midterm Exam (
10/09), &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/exams/midterm_answers.pdf&#34;&gt;good answers,&lt;/a&gt; &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/exams/midterm_grades.pdf&#34;&gt;grades.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Final Exam, 12/09. &lt;!-- , [good answers](/teaching/biometrics-aut23/final_answers.pdf). --&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a name=&#34;project&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;project&#34;&gt;Project&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Written report and presentation, work alone or in groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Possible Topics&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implementation of &lt;em&gt;complete&lt;/em&gt; class attendance system.&lt;/li&gt;
&lt;li&gt;Presentation attack (performance, detection, and mitigation) of fingerprint recognition.&lt;/li&gt;
&lt;li&gt;Presentation attack of face recognition.&lt;/li&gt;
&lt;li&gt;Presentation attack of iris recognition.&lt;/li&gt;
&lt;li&gt;Implementation of recognition of traits other than fingerprints, face, and iris.&lt;/li&gt;
&lt;li&gt;Presentation and implementation of state-of-the-art scientific publications.&lt;/li&gt;
&lt;li&gt;Discussion about the ethical aspects of Biometrics and surveillance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;!-- 
*Chosen Topics*
| Team          | Topic                            | Presentation                                   |
|---------------|----------------------------------|------------------------------------------------|
| Team 1 &amp;emsp; | The Ethics of Biometrics &amp;emsp;  | [slides](/teaching/biometrics-aut23/pres1.pdf) |
| Team 2        | Fingerprint Spoofing             | [slides](/teaching/biometrics-aut23/pres2.pdf) |
| Team 3        | Iris Spoofing                    | [slides](/teaching/biometrics-aut23/pres3.pdf) |
| Team 4        | Iris Obfuscation                 | [slides](/teaching/biometrics-aut23/pres4.pdf) |
| Team 5        | Speaker Recognition              | [slides](/teaching/biometrics-aut23/pres5.pdf) |
--&gt;
&lt;p&gt;&lt;a name=&#34;part&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;participation&#34;&gt;Participation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Class Attendance: every presence counts.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Today-I-missed&lt;/em&gt; Statements: every submission counts.&lt;/li&gt;
&lt;li&gt;Grace Cards: use them to pardon class absence or late work.&lt;/li&gt;
&lt;li&gt;Religious holidays will be honored according to the student&amp;rsquo;s faith, as stated in &lt;a href=&#34;https://tinyurl.com/4uujcuw2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://tinyurl.com/4uujcuw2&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Today-I-missed&lt;/em&gt; Statements&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After every attended class, each student will have to submit (through Sakai) a short paragraph answering one of the
following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What is your biggest question after class? &lt;strong&gt;OR&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;What was the most interesting point you learned today?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Inspired by  &lt;a href=&#34;https://www.ic.unicamp.br/~sandra/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Sandra Avila&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Today I missed&amp;amp;hellip;&#34;
           src=&#34;https://danielmoreira.github.io/teaching/biometrics-aut24/point.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Grace Cards&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Each student has three Grace Cards, which will allow them to avoid losing points because of class absence.
They might also use their cards to excuse late-delivered assignments and give a one-week extension.
The cards are not valid to dismiss or postpone exam and final project dates.
Students may use their cards at their own discretion, as long as they clearly communicate the instructor.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Life happens, be wise.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- ![Oopsie card.](card.gif) --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;biometrics-on-the-news&#34;&gt;Biometrics on the News&lt;/h2&gt;
&lt;p&gt;Posted by the students and the instructor on Sakai.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://sakai.luc.edu/access/content/group/COMP_388_002_4321_1246/student-uploads/cprevost__2024.01.24_China_Ethics_Biometrics_20240827104004049.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ethical Problems continue to plague biometric studies of Chinese minority groups.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://diabetesjournals.org/care/article-pdf/14/7/612/341538/14-7-612a.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Illegible Fingerprints.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pbs.org/wgbh/nova/article/koala-fingerprints/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Koalas have fingerprints almost identical to ours.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.iso.org/news/2016/07/Ref2094.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The mystery of the Phantom of Heilbronn.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.theguardian.com/technology/2019/aug/14/major-breach-found-in-biometrics-system-used-by-banks-uk-police-and-defence-firms&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Major breach found in biometrics system.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.proquest.com/docview/2928355934?_oafollow=false&amp;amp;accountid=12163&amp;amp;pq-origsite=primo&amp;amp;sourcetype=Newspapers&amp;amp;parentSessionId=UrKJjyL4XZnwytTpLctTnIShc9ZWKoUamREyNxYvk20%3D&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;On Airports&amp;rsquo; Horizon: Facial Recognition.&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- *Links will be added here as they appear on Sakai.* --&gt;
&lt;!-- 
1. [Koalas have fingerprints almost identical to ours.](https://www.pbs.org/wgbh/nova/article/koala-fingerprints/)
2. [Brazilian thief spoofed victims faces.](https://www.dailymail.co.uk/news/article-12210813/Brazilian-thief-taped-photos-victims-faces-DUMMY-bypass-facial-recognition.html)
3. [Fingerprint cloning: myth or reality?](https://blog.talosintelligence.com/fingerprint-research/)
4. [Data leak of 1M people&#39;s biometric data in UK.](https://www.technologyreview.com/2019/08/14/133723/data-leak-exposes-unchangeable-biometric-data-of-over-1-million-people/)
5. [Samsung phones use ultrasonic fingerprint device.](https://www.theverge.com/2019/10/23/20929178/samsung-galaxy-s10-note-1o-fingerprint-recognition-issue-patch-ultrasonic-sensor)
6. [Apple uses capacitive fingerprint device (with 500 ppi).](https://en.wikipedia.org/wiki/Touch_ID)
7. [Racial Discrimination in Face Recognition Technology.](https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/)
8. [What is Facial Recognition Technology?](https://www.ajl.org/facial-recognition-technology)
9. [Boston Bans Use Of Facial Recognition Technology.](https://www.wbur.org/news/2020/06/23/boston-facial-recognition-ban)
10. [Adversarial Attack on ArcFace.](https://www.youtube.com/watch?v=a4iNg0wWBsQ)
11. [Scrutiny of Iris-scanning Crypto Project Grows.](https://www.reuters.com/technology/scrutiny-iris-scanning-crypto-project-worldcoin-grows-2023-09-01/)
12. [Scammers used AI to replicate son’s voice.](https://twitter.com/notcapnamerica/status/1725901659270742084)
--&gt;
&lt;hr&gt;
&lt;h2 id=&#34;useful-links&#34;&gt;Useful Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://vision.ucsd.edu/content/yale-face-database&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yale face dataset,&lt;/a&gt; used in the 3rd assignment.&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;reading&#34;&gt;&lt;/a&gt; &lt;a href=&#34;https://ieeexplore.ieee.org/document/8658624&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Human performance in iris recognition,&lt;/a&gt; used in extra reading activity on 10/30.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Jain, Ross, and Nandakumar. &lt;em&gt;Introduction to Biometrics&lt;/em&gt;. Springer Books, 2011.&lt;/li&gt;
&lt;li&gt;Jain, Flynn, and Ross. &lt;em&gt;Handbook of Biometrics&lt;/em&gt;. Springer Books, 2008.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;learning-outcomes&#34;&gt;Learning Outcomes&lt;/h2&gt;
&lt;p&gt;At the end of the course, students will master the theoretical foundations, key techniques, and applications of
Biometrics to real-world scenarios.
Their repertoire will include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understanding the fundamentals of Biometrics.&lt;/li&gt;
&lt;li&gt;Developing and implementing Biometric algorithms.&lt;/li&gt;
&lt;li&gt;Assessing the performance of Biometric systems.&lt;/li&gt;
&lt;li&gt;Applying Biometrics to real-world applications.&lt;/li&gt;
&lt;li&gt;Identifying the privacy and ethics issues of Biometric systems.&lt;/li&gt;
&lt;li&gt;Being up-to-date with emerging trends in Biometrics.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Graduate students (within COMP 488-002), in particular, will acquire the following extra skills:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reading, peer-reviewing, and writing scientific papers about Biometrics.&lt;/li&gt;
&lt;li&gt;Conducting research in Biometrics, from the design of hypotheses, development of solutions, and comparison to
existing baselines, to the design and execution of experiments.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;academic-integrity&#34;&gt;Academic Integrity&lt;/h2&gt;
&lt;p&gt;Students are expected to adhere to the LUC statements on academic integrity available at &lt;a href=&#34;https://tinyurl.com/5n6ru62s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://tinyurl.com/5n6ru62s&lt;/a&gt;.
These policies fully apply to this course.
The penalty for task-wise academic misconduct is losing all the task&amp;rsquo;s points.
Multiple events of misconduct will incur in failing the entire course (with an F grade).
All cases of academic misconduct will be reported to the proper department offices.
Lastly, students are not allowed to use AI assisted technology (such as &lt;a href=&#34;https://chat.openai.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ChatGPT&lt;/a&gt;) along the
entirety of the course, unless explicitly authorized by the instructor.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;accommodations&#34;&gt;Accommodations&lt;/h2&gt;
&lt;p&gt;Students who have disabilities and wish to request academic accommodations are advised to contact the
&lt;em&gt;Student Accessibility Center&lt;/em&gt; (SAC) at 773-508-3700 or &lt;a href=&#34;mailto:sac@luc.edu&#34;&gt;sac@luc.edu&lt;/a&gt; as soon as possible.
SAC will provide accommodation letters that, once shared with the instructor, will be fully honored
as per the terms of their content with no further questions and total confidentiality.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning the Shell, Fall 2024</title>
      <link>https://danielmoreira.github.io/teaching/comptool-aut24/</link>
      <pubDate>Fri, 16 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/comptool-aut24/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/comptool-aut24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/comptool-aut24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/comptool-aut24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/comptool-aut24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 141-001 / COMP 400D-001 Intro to Computing Tools and Techniques&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;br&gt;
Teaching Assistants: Erik Pautsch (&lt;a href=&#34;mailto:epautsch@luc.edu&#34;&gt;epautsch@luc.edu&lt;/a&gt;) and&lt;br&gt;
Sagar Pyakurel (&lt;a href=&#34;mailto:spyakurel@luc.edu&#34;&gt;spyakurel@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: TUE, 4:15 to 5:30 PM, &lt;a href=&#34;https://luc.zoom.us/j/86020500730&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online&lt;/a&gt;&lt;br&gt;
Office Hours: MON and WED evenings, and FRI afternoons,&lt;br&gt;
310 Doyle Center or Zoom, &lt;a href=&#34;https://calendly.com/danielmoreira/fall-2024-office-hours&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt;&lt;br&gt;
Sakai: &lt;a href=&#34;https://sakai.luc.edu/x/EFvnb4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://sakai.luc.edu/x/EFvnb4&lt;/a&gt;&lt;/p&gt;
&lt;!-- &gt; Grades are now [available](/teaching/comptool-aut23/grades.pdf). --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Shell terminal.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/comptool-aut24/terminal.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Despite the current era of rich graphical user interfaces (desktop, web, and mobile), the &amp;ldquo;command line&amp;rdquo; experience
remains important, especially for software developers and computer-aided scientific researchers.
Many development scenarios still require command line and fluency in Unix tools, including the modern embedded,
cloud, cybersecurity, and supercomputing environments. With mobile computing and Internet of Things, Unix (notably via Linux)
has risen to the level of a ubiquitous platform, owing to its lightweight and open-source nature.
While this course does not aim at being a comprehensive programming class, students will master basic programming
skills using shell scripting.
They will also learn about problem-solving using Unix commands supported by shell scripts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Please refer to &lt;a href=&#34;https://sakai.luc.edu/x/EFvnb4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt; for having access to the materials, assignments, quizzes,
announcements, grading, and progress of the course. This page is static and will not be updated.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt;
&lt;p&gt;This course is offered in multiple sessions with the following leading and contributing LUC instructors (Fall 2024):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Corby Schmitz&lt;/li&gt;
&lt;li&gt;George Thiruvathukal&lt;/li&gt;
&lt;li&gt;John O&amp;rsquo;Sullivan&lt;/li&gt;
&lt;li&gt;Satyaki Sikdar&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shots, W. &lt;em&gt;The Linux Command Line, 2nd Edition&lt;/em&gt;. No Starch Press Book, 2019. Available at &lt;a href=&#34;https://linuxcommand.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://linuxcommand.org/&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Synthetic Realities and Artificial Intelligence-Generated Contents</title>
      <link>https://danielmoreira.github.io/publication/2024_sp/</link>
      <pubDate>Fri, 17 May 2024 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2024_sp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Machine Learning, Spring 2024</title>
      <link>https://danielmoreira.github.io/teaching/ml-spr24/</link>
      <pubDate>Wed, 17 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/ml-spr24/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/ml-spr24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/ml-spr24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/ml-spr24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/ml-spr24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 379-001 / COMP 479-001 Machine Learning&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: THR, 4:15 to 6:45 PM, 123 Institute of Environmental Sustainability&lt;br&gt;
Office Hours: FRI, 8 AM to 5 PM, 310 Doyle Center or Zoom,
&lt;a href=&#34;https://calendly.com/danielmoreira/spring-2024&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt;&lt;br&gt;
Sakai: &lt;a href=&#34;https://sakai.luc.edu/x/Od0gze&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://sakai.luc.edu/x/Od0gze&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Final grades were released on Sakai. Thank you, everyone!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Presentation attacks done by students.&#34; srcset=&#34;
               /teaching/ml-spr24/ml_hub8d24dd5fb3e0e44a9c633968263ace6_65864_81122346f9f283a17fd248cb3bb8350a.webp 400w,
               /teaching/ml-spr24/ml_hub8d24dd5fb3e0e44a9c633968263ace6_65864_1102fa7df0243b7e9cdc32a02870a619.webp 760w,
               /teaching/ml-spr24/ml_hub8d24dd5fb3e0e44a9c633968263ace6_65864_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/ml-spr24/ml_hub8d24dd5fb3e0e44a9c633968263ace6_65864_81122346f9f283a17fd248cb3bb8350a.webp&#34;
               width=&#34;760&#34;
               height=&#34;322&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ndash; Arthur Samuel, 1959&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Even though Samuel&amp;rsquo;s definition is now more than six decades old, it still holds true.
With the recent advances in computer processing power, memory, and storage, machine learning has stressed its
learn-by-example data-driven aspect, and is available — commonly as a black box — to everyone.&lt;/p&gt;
&lt;p&gt;Annotated high-quality datasets can be easily harnessed to train a multitude of models to solve very specific problems
under the different paradigms of supervised, unsupervised, hybrid (e.g., semi-supervised and self-supervised), and
reinforcement learning. This course will cover these paradigms, trying to establish a balance between theory and
practice. While students will be exposed to the theories that fight the black-box and irresponsible usage of machine
learning, hands-on activities leveraging real-world data will prepare them for industrial, academic, and societal
needs.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Let&amp;rsquo;s learn how the machines learn!&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Requirements to attend this course are basic programming skills (especially Python), data structures, math
fundamentals (such as linear algebra and calculus), and probability and statistics.
This course and its materials are available in &lt;a href=&#34;https://sakai.luc.edu/x/Od0gze&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;schedule-materials-in-sakaihttpssakailuceduxcuz5vo&#34;&gt;Schedule &lt;em&gt;(materials in &lt;a href=&#34;https://sakai.luc.edu/x/cuz5vo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt;)&lt;/em&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;01/18 - Syllabus and Intro&lt;/li&gt;
&lt;li&gt;01/25 - Data-driven Aspects&lt;/li&gt;
&lt;li&gt;02/01 - Data-driven Aspects (cont.)&lt;/li&gt;
&lt;li&gt;02/08 - Principal Component Analysis&lt;/li&gt;
&lt;li&gt;02/15 - Linear Regression&lt;/li&gt;
&lt;li&gt;02/22 - Linear Regression (cont.)&lt;/li&gt;
&lt;li&gt;02/29 - Logistic Regression&lt;/li&gt;
&lt;li&gt;03/07 - Spring Break, &lt;em&gt;no classes&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;03/14 - Classification Metrics&lt;/li&gt;
&lt;li&gt;03/21 - Classification Methods (K-Nearest Neighbors, Decision Trees)&lt;/li&gt;
&lt;li&gt;03/28 - Easter Break, &lt;em&gt;no classes&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;04/04 - Classification Methods (cont., Support Vector Machines)&lt;/li&gt;
&lt;li&gt;04/11 - Neural Nets&lt;/li&gt;
&lt;li&gt;04/18 - Convolutional Neural Nets&lt;/li&gt;
&lt;li&gt;04/25 - Graduate Students&amp;rsquo; Lectures and Wrap-up&lt;/li&gt;
&lt;li&gt;05/02 - Project Presentation&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;important-dates&#34;&gt;Important Dates&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;02/15 - Definition of project groups.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;02/29 - Definition of project topics.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;03/07 - Spring Break.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;03/21 - Midterm Exam.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;03/21 - Definition of project plan.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;03/28 - Easter Break.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/11 - Report of project status.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/25 - Graduate students&amp;rsquo; lectures.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;05/02 - Project presentation.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;notebooks-for-hands-on-activities&#34;&gt;Notebooks &lt;em&gt;(for hands-on activities)&lt;/em&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/17IATgNji8ZNZCN4fNUMpvMqigexztO7z&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 01,&lt;/a&gt; Data-driven Aspects.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1Q6DnkGYbjX1UQ_CL_lnWUSH6CEvvNPK9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 02,&lt;/a&gt; Principal Component Analysis.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1XHF9C1gQJZ36eax2V5Gm01icU70LY3O0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 03,&lt;/a&gt; Linear Regression.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1DfJxYXXqmZNTgVg3Q2LFNPLp0Gw4n9mJ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 04,&lt;/a&gt; Logistic Regression.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1puZqLAXuRfjRpnuosbhR-aCEe55CxALA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 05,&lt;/a&gt; Classification Methods.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1KEYKKVqdmGhX-pDBLZ2V2ZpzoxHwG7pK&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 06,&lt;/a&gt; Neural Networks.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;grading&#34;&gt;Grading&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%) &lt;/th&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%) &lt;/th&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%) &lt;/th&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;[96, 100)&lt;/td&gt;
&lt;td&gt;B+&lt;/td&gt;
&lt;td&gt;[88, 92)&lt;/td&gt;
&lt;td&gt;C+&lt;/td&gt;
&lt;td&gt;[76, 80)&lt;/td&gt;
&lt;td&gt;D+&lt;/td&gt;
&lt;td&gt;[64, 68)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A-&lt;/td&gt;
&lt;td&gt;[92, 96)&lt;/td&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;[84, 88)&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;[72, 76)&lt;/td&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;[60, 64)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;B-&lt;/td&gt;
&lt;td&gt;[80, 84)&lt;/td&gt;
&lt;td&gt;C-&lt;/td&gt;
&lt;td&gt;[68, 72)&lt;/td&gt;
&lt;td&gt;F&lt;/td&gt;
&lt;td&gt;(0, 60)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;distribution&#34;&gt;Distribution&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Undergraduate  &lt;/th&gt;
&lt;th&gt;Graduate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Assignments (3)  &lt;/td&gt;
&lt;td&gt;30%&lt;/td&gt;
&lt;td&gt;25%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exams &lt;del&gt;(2)&lt;/del&gt; (1)&lt;/td&gt;
&lt;td&gt;30%&lt;/td&gt;
&lt;td&gt;25%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Project&lt;/td&gt;
&lt;td&gt;30%&lt;/td&gt;
&lt;td&gt;25%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Participation&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Topic Lecture&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;15%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;On the News&lt;/td&gt;
&lt;td&gt;+1% (extra)&lt;/td&gt;
&lt;td&gt;+1% (extra)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;assignments-materials-in-sakaihttpssakailuceduxx50tjo&#34;&gt;Assignments &lt;em&gt;(materials in &lt;a href=&#34;https://sakai.luc.edu/x/x50TJo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt;)&lt;/em&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Assignment 1, Data-driven Aspects, Notebook 01.&lt;/li&gt;
&lt;li&gt;Assignment 2, PCA and Linear Regression, Notebooks 02 and 03.&lt;/li&gt;
&lt;li&gt;Assignment 3, Logistic Regression and Classification Methods, Notebooks 04 and 05.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Late Policy&lt;/strong&gt;&lt;br&gt;
Deduction of 10% of the maximum possible grade for each day of delay.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;exams&#34;&gt;Exams&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Midterm Exam, 03/21, &lt;a href=&#34;https://danielmoreira.github.io/teaching/ml-spr24/midterm-answers.pdf&#34;&gt;good answers&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Final Exam&lt;/del&gt; &lt;em&gt;Final Project Presentation&lt;/em&gt;, 05/02.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a name=&#34;project&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;project&#34;&gt;Project&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Written report (and presentation), work alone or in groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- &gt; **Possible Topics**  
&gt; * Presentation attack (performance, detection, and mitigation) of fingerprint recognition.
&gt; * Presentation attack of face recognition.
&gt; * Presentation attack of iris recognition.
&gt; * Implementation of *complete* class attendance system.
&gt; * Implementation of recognition of traits other than fingerprints, face, and iris.
&gt; * Presentation and implementation of state-of-the-art scientific publications.
&gt; * Discussion about the ethical aspects of Biometrics and surveillance. --&gt;
&lt;p&gt;&lt;em&gt;Chosen Topics&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Group&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Group&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Team 01  &lt;/td&gt;
&lt;td&gt;Breast Cancer Detector&lt;/td&gt;
&lt;td&gt;Team 11  &lt;/td&gt;
&lt;td&gt;March Madness Standings Predictor&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 02&lt;/td&gt;
&lt;td&gt;Car Price Estimator&lt;/td&gt;
&lt;td&gt;Team 12&lt;/td&gt;
&lt;td&gt;House Price Estimator&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 03&lt;/td&gt;
&lt;td&gt;Real Estate Predictor&lt;/td&gt;
&lt;td&gt;Team 13&lt;/td&gt;
&lt;td&gt;Music Source Separator&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 04&lt;/td&gt;
&lt;td&gt;LUC Ranking Estimator&lt;/td&gt;
&lt;td&gt;Team 14&lt;/td&gt;
&lt;td&gt;Soccer Player Transference Value Estimator&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 05&lt;/td&gt;
&lt;td&gt;Bitcoin Trading Advisor&lt;/td&gt;
&lt;td&gt;Team 15&lt;/td&gt;
&lt;td&gt;Lawyer Recommendation System&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 06&lt;/td&gt;
&lt;td&gt;Car Emission Estimator&lt;/td&gt;
&lt;td&gt;Team 16&lt;/td&gt;
&lt;td&gt;Music Genre Classifier&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 07&lt;/td&gt;
&lt;td&gt;NBA MVP Predictor&lt;/td&gt;
&lt;td&gt;Team 17&lt;/td&gt;
&lt;td&gt;Heart Condition Classifier&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 08&lt;/td&gt;
&lt;td&gt;Twitter Sentiment Analyzer&lt;/td&gt;
&lt;td&gt;Team 18&lt;/td&gt;
&lt;td&gt;Person&amp;rsquo;s Age Prediction from MR&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 09&lt;/td&gt;
&lt;td&gt;Diabetes Condition Classifier  &lt;/td&gt;
&lt;td&gt;Team 19&lt;/td&gt;
&lt;td&gt;Credit Condition Classifier&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 10&lt;/td&gt;
&lt;td&gt;Credit Card Fraud Detector&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a name=&#34;part&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;participation&#34;&gt;Participation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Class Attendance: every presence counts.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Today-I-missed&lt;/em&gt; Statements: every submission counts.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Today-I-missed&lt;/em&gt; Statements&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After every attended class, each student will have to submit (through Sakai) a short paragraph answering one of the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What is your biggest question after class? &lt;strong&gt;OR&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;What was the most interesting point you learned today?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Inspired by  &lt;a href=&#34;https://www.ic.unicamp.br/~sandra/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Sandra Avila&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Today I missed&amp;amp;hellip;&#34;
           src=&#34;https://danielmoreira.github.io/teaching/ml-spr24/point.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Oopsie&lt;/em&gt; Cards&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Each student has two &lt;em&gt;&amp;ldquo;Oopsie&amp;rdquo;&lt;/em&gt; Cards, which will allow them to avoid losing points because of late delivered work.
The cards are not valid to dismiss or postpone exams, topic lectures (graduate students), or final project dates.
Students may use their cards at their own discretion, as long as they clearly communicate the instructor.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Life happens, be wise.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Oopsie card.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/ml-spr24/card.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;ml-on-the-news&#34;&gt;ML on the News&lt;/h2&gt;
&lt;p&gt;Posted by the students on Sakai.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://openai.com/sora&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAI Sora.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.japantimes.co.jp/business/2024/03/06/tech/inoue-uber-eats-robot/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Self-driving delivery robots.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://time.com/6903563/eu-ai-act-law-aritificial-intelligence-passes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EU AI Law.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://opencv.org/blog/devin-ai-software-engineer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Devin - AI Software Engineer.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/pulse/automl-revolution-future-automated-machine-learning-transforming-j75sc?trk=public_post_main-feed-card_feed-article-content#:~:text=The%20landscape%20of%20AutoML%20is,accessible%20to%20a%20broader%20audience&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AutoML - Automated ML model development.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.wsj.com/articles/open-source-companies-are-sharing-their-ai-free-can-they-crack-openais-dominance-26149e9c?mod=ai_news_article_pos5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open-Source Companies Are Sharing Their AI Free. Can They Crack OpenAI’s Dominance?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://timesofindia.indiatimes.com/gadgets-news/bharatgpt-hanooman-all-you-need-to-know-about-the-ai-model-developed-by-reliance-and-9-iits-ac&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BharatGPT Hanooman.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.mit.edu/2024/brain-surgery-training-avatar-0229&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Remote Brain Surgery Training.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.figure.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Figure.ai.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openai.com/dall-e-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DALL-E 2: Create realistic images and art from a description in natural language.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/Xintao/GFPGAN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GFP-GAN : Photo Restoration.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sciencealert.com/machine-learning-uncovers-new-ways-to-kill-bacteria-with-non-antibiotic-drugs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Machine Learning Uncovers New Ways to Kill Bacteria With Non-Antibiotic Drugs.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://news.mit.edu/2024/building-better-ai-helper-starts-with-modeling-irrational-behavior-0419&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;To build a better AI helper, start by modeling the irrational behavior of humans.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://about.fb.com/news/2024/04/meta-ai-assistant-built-with-llama-3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Meet Your New Assistant: Meta AI, Built With Llama 3.&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rasbt/python-machine-learning-book&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Python Machine Learning&lt;/a&gt; book, code repository.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ageron/handson-ml3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow&lt;/a&gt; book, code repository,&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hastie.su.domains/ISLP/ISLP_website.pdf.download.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;An Introduction to Statistical Learning with Applications in Python&lt;/a&gt; book, online version.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;academic-integrity&#34;&gt;Academic Integrity&lt;/h2&gt;
&lt;p&gt;Students are expected to adhere to the LUC statements on academic integrity available at &lt;a href=&#34;https://bit.ly/3TmiQkQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3TmiQkQ&lt;/a&gt;.
These policies fully apply to this course.
The penalty for task-wise academic misconduct is losing all the task&amp;rsquo;s points.
Multiple events of misconduct will incur in failing the entire course (with an F grade).
All cases of academic misconduct will be reported to the proper department offices.
Lastly, students are not allowed to use AI assisted technology (such as &lt;a href=&#34;https://chat.openai.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ChatGPT&lt;/a&gt;) along the
entirety of the course, unless explicitly authorized by the instructor.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;accommodations&#34;&gt;Accommodations&lt;/h2&gt;
&lt;p&gt;Students who have disabilities and wish to request academic accommodations are advised to contact the
&lt;em&gt;Services for Students With Disabilities&lt;/em&gt; (SSWD) office at 773-508-3700 or &lt;a href=&#34;mailto:SSWD@luc.edu&#34;&gt;SSWD@luc.edu&lt;/a&gt; as soon as possible.
The SSWD office will provide accommodation letters that, once shared with the instructor, will be fully accommodated
as per the terms of their content with no further questions.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;I would like to sincerely thank Professors &lt;a href=&#34;https://www.ic.unicamp.br/~sandra/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sandra Avila&lt;/a&gt; and
&lt;a href=&#34;https://www.dmitriydligach.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dmitriy Dligach&lt;/a&gt; for kindly sharing their
Machine Learning course materials with me. I relied upon their content
and experience to constitute this course.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning the Shell, Spring 2024</title>
      <link>https://danielmoreira.github.io/teaching/comptool-spr24/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/comptool-spr24/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/comptool-spr24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/comptool-spr24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/comptool-spr24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/comptool-spr24/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 141-001 / COMP 400D-001 Intro to Computing Tools and Techniques&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;br&gt;
Teaching Assistant: Bright Duffour (&lt;a href=&#34;mailto:bduffour@luc.edu&#34;&gt;bduffour@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: MON, 4:15 to 5:30 PM, &lt;a href=&#34;https://luc.zoom.us/j/86256187649&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online&lt;/a&gt;&lt;br&gt;
Office Hours: FRI, 8:00 AM to 5:00 PM, 310 Doyle Center or Zoom, &lt;a href=&#34;https://calendly.com/danielmoreira/spring-2024&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt;&lt;br&gt;
Sakai: &lt;a href=&#34;https://sakai.luc.edu/x/xaQGV2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://sakai.luc.edu/x/xaQGV2&lt;/a&gt;&lt;/p&gt;
&lt;!-- &gt; Grades are now [available](/teaching/comptool-aut23/grades.pdf). --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Shell terminal.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/comptool-spr24/terminal.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Despite the current era of rich graphical user interfaces (desktop, web, and mobile), the &amp;ldquo;command line&amp;rdquo; experience
remains important, especially for software developers and computer-aided scientific researchers.
Many development scenarios still require command line and fluency in Unix tools, including the modern embedded,
cloud, cybersecurity, and supercomputing environments. With mobile computing and Internet of Things, Unix (via Linux)
has risen to the level of a ubiquitous platform, owing to its lightweight and open-source nature.
While this course does not aim at being a comprehensive programming class, students will master basic programming
skills using shell scripting.
They will also learn about problem-solving using Unix commands supported by shell scripts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Please refer to &lt;a href=&#34;https://sakai.luc.edu/x/xaQGV2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt; for having access to the materials, assignments, quizzes,
announcements, grading, and progress of the course. This page is static and will not be updated.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt;
&lt;p&gt;This course is offered in multiple sessions with the following leading and contributing LUC instructors (Spring 2024):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;John O&amp;rsquo;Sullivan&lt;/li&gt;
&lt;li&gt;Konstantin Läufer&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shots, W. &lt;em&gt;The Linux Command Line, 2nd Edition&lt;/em&gt;. No Starch Press Book, 2019. Available at &lt;a href=&#34;https://linuxcommand.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://linuxcommand.org/&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The Age of Synthetic Realities: Challenges and Opportunities</title>
      <link>https://danielmoreira.github.io/publication/2023_apsipa/</link>
      <pubDate>Mon, 06 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2023_apsipa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Biometrics, Fall 2023</title>
      <link>https://danielmoreira.github.io/teaching/biometrics-aut23/</link>
      <pubDate>Wed, 23 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/biometrics-aut23/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/biometrics-aut23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/biometrics-aut23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/biometrics-aut23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 388-002 / COMP 488-002 Computer Science Topics&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: MON and WED, 4:15 to 5:30 PM, 218 Cuneo Hall&lt;br&gt;
Office Hours: MON and TUE evenings, 6 to 8 PM, and WED mornings, 8 AM to noon, 310 Doyle Center or Zoom,
&lt;a href=&#34;https://bit.ly/3KUUaND&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt;&lt;br&gt;
Sakai: &lt;a href=&#34;https://sakai.luc.edu/x/gUHhNw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://sakai.luc.edu/x/gUHhNw&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Final grades were released on Sakai. Thank you, everyone!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Presentation attacks done by students.&#34; srcset=&#34;
               /teaching/biometrics-aut23/fake_hu74daeec1aed29769f400179182090b1f_888064_d304008315fb1f609c885d3bc468f443.webp 400w,
               /teaching/biometrics-aut23/fake_hu74daeec1aed29769f400179182090b1f_888064_af986f3354173976aee232e2c98f4be7.webp 760w,
               /teaching/biometrics-aut23/fake_hu74daeec1aed29769f400179182090b1f_888064_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/fake_hu74daeec1aed29769f400179182090b1f_888064_d304008315fb1f609c885d3bc468f443.webp&#34;
               width=&#34;760&#34;
               height=&#34;381&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;How do computers match a person&amp;rsquo;s fingerprints?
Do they still use the same techniques proposed in the XIX century?
How do computers identify people captured in a video?
Do they leverage the depicted faces only, or can they use other traits such as gait or voice?
How about iris recognition as portrayed in the movies?
Is it really possible?
What happens in the case of people who look very similar, such as identical twins?
Which traits are more reliable and robust to impersonation or prone to falsification?
These are some of the questions we will address in this course, whose main topic is Biometrics.
In a nutshell, Biometrics is the study of techniques to identify individuals through their physical, chemical,
and behavioral traits, such as fingerprints, face, iris, DNA, voice, gait, etc.
Our focus will be on the technical and ethical aspects of computer-aided Biometrics,
discussing the issues of going from simple and benign authentication to the more problematic case of surveillance.
The course will have an intense hands-on approach, with the collection of samples and implementation of fingerprint,
face, and iris recognition.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Requirements to attend this course are basic programming skills (especially Python).
This course and its materials are also available in &lt;a href=&#34;https://sakai.luc.edu/x/gUHhNw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;progress&#34;&gt;Progress&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;08/28 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_01.pdf&#34;&gt;Syllabus,&lt;/a&gt; Course details.&lt;/li&gt;
&lt;li&gt;08/30 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_02.pdf&#34;&gt;Basics I,&lt;/a&gt; Biometrics, traits, and systems.&lt;/li&gt;
&lt;li&gt;09/04 - Labor Day, &lt;em&gt;no classes&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;09/06 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_03.pdf&#34;&gt;Basics II,&lt;/a&gt; Biometric systems, errors, and metrics.&lt;/li&gt;
&lt;li&gt;09/11 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_04.pdf&#34;&gt;1st Coding Class,&lt;/a&gt; Metrics&amp;rsquo; implementation.&lt;/li&gt;
&lt;li&gt;09/13 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_05.pdf&#34;&gt;Fingerprint Recog. I,&lt;/a&gt; History and features.&lt;/li&gt;
&lt;li&gt;09/18 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_06.pdf&#34;&gt;Fingerprint Recog. II,&lt;/a&gt; Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;09/20 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_07.pdf&#34;&gt;Fingerprint Recog. III,&lt;/a&gt; Minutiae detection.&lt;/li&gt;
&lt;li&gt;09/25 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_08.pdf&#34;&gt;Fingerprint Recog. IV,&lt;/a&gt; Data collection.&lt;/li&gt;
&lt;li&gt;09/27 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_09.pdf&#34;&gt;2nd Coding Class,&lt;/a&gt; Fingerprint recognition.&lt;/li&gt;
&lt;li&gt;10/02 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_10.pdf&#34;&gt;Midterm Preparation,&lt;/a&gt; Project discussion and recap.&lt;/li&gt;
&lt;li&gt;10/04 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/midterm_answers.pdf&#34;&gt;Midterm Exam,&lt;/a&gt; Grades on Sakai.&lt;/li&gt;
&lt;li&gt;10/09 - Fall Break, &lt;em&gt;no classes&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;10/11 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_11.pdf&#34;&gt;Face Recog. I,&lt;/a&gt; Why faces and faces vs. other traits.&lt;/li&gt;
&lt;li&gt;10/16 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_12.pdf&#34;&gt;Face Recog. II,&lt;/a&gt; Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;10/18 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_13.pdf&#34;&gt;Face Recog. III,&lt;/a&gt; Description and matching.&lt;/li&gt;
&lt;li&gt;10/23 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_14.pdf&#34;&gt;Face Recog. IV,&lt;/a&gt; Deep learning face recognition.&lt;/li&gt;
&lt;li&gt;10/25 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_15.pdf&#34;&gt;3rd Coding Class,&lt;/a&gt; Face recognition.&lt;/li&gt;
&lt;li&gt;10/30 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_16.pdf&#34;&gt;Iris Recog. I,&lt;/a&gt; Why irises and irises vs. other traits.&lt;/li&gt;
&lt;li&gt;11/01 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_17.pdf&#34;&gt;Iris Recog. II,&lt;/a&gt; Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;11/06 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_18.pdf&#34;&gt;Iris Recog. III,&lt;/a&gt; Description and matching.&lt;/li&gt;
&lt;li&gt;11/08 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_19.pdf&#34;&gt;4th Coding Class,&lt;/a&gt; Iris recognition.&lt;/li&gt;
&lt;li&gt;11/13 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_20.pdf&#34;&gt;Other Traits&lt;/a&gt;, Alternative traits and Soft Biometrics.&lt;/li&gt;
&lt;li&gt;11/15 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_21.pdf&#34;&gt;Multibiometrics&lt;/a&gt;, Data fusion.&lt;/li&gt;
&lt;li&gt;11/20 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/lecture_22.pdf&#34;&gt;Feature Indexing&lt;/a&gt;, Index building and feature querying.&lt;/li&gt;
&lt;li&gt;11/22 - Thanksgiving, &lt;em&gt;no classes&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;11/27 - &lt;a href=&#34;#abharati&#34;&gt;1st Invited Talk,&lt;/a&gt; Dr. Aparna Bharati.&lt;/li&gt;
&lt;li&gt;11/29 - Office Hours to Conclude Projects, &lt;em&gt;no classes&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;12/04 - &lt;a href=&#34;#project&#34;&gt;Project presentations&lt;/a&gt;, 5 groups present.&lt;/li&gt;
&lt;li&gt;12/06 - &lt;a href=&#34;#aczajka&#34;&gt;2nd Invited Talk,&lt;/a&gt; Dr. Adam Czajka.&lt;/li&gt;
&lt;li&gt;12/11 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/final_answers.pdf&#34;&gt;Final Exam,&lt;/a&gt; Grades on Sakai.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;important-dates&#34;&gt;Important Dates&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;08/28 - First Class.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;09/04 - Labor Day, no classes.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;09/11 - 1st Coding Class.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;09/25 - 2nd Coding Class and Fingerprint Collection.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;10/02 - 1st Assignment deadline.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;10/04 - Midterm Exam.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;10/09 - Fall Break, no classes.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;10/16 - 2nd Assignment deadline.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;10/25 - 3rd Coding Class.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;11/08 - 4th Coding Class.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;11/13 - 3rd Assignment deadline.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;11/22 - Thanksgiving, no classes.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;11/27 - Dr. Aparna Bharati’s talk.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;12/04 - Project presentations.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;12/06 - Dr. Adam Czajka’s talk.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;12/11 - Final Exam.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;notebooks-for-coding-classes&#34;&gt;Notebooks &lt;em&gt;(for coding classes)&lt;/em&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1Yd-C7m8bhHP7-QcJH70iJyyjgrKOBaNT&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 01,&lt;/a&gt; Metrics&amp;rsquo; implementation.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1a6JdRkwRAMtyRif2LTIchtMCgsa7KL9l&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 02,&lt;/a&gt; Fingerprint recognition.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/18-PZJTQt1v7Pej37uVmZYNTZFdiiM2cG&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 03,&lt;/a&gt; Face recognition.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/drive/1rJ5vjm48eMAg5ZdHApazo3X_IVMvIDKc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Notebook 04,&lt;/a&gt; Iris recognition.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a name=&#34;abharati&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;invited-talks&#34;&gt;Invited Talks&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Dr. Aparna Bharati&#34; srcset=&#34;
               /teaching/biometrics-aut23/bharati_hu682a673afd755555ad7d1c04f5cdb12d_5630_f76963ea3d8c46fbaee41b7c15acfcc9.webp 400w,
               /teaching/biometrics-aut23/bharati_hu682a673afd755555ad7d1c04f5cdb12d_5630_05846f0c5b76511d6c366d7174197f6f.webp 760w,
               /teaching/biometrics-aut23/bharati_hu682a673afd755555ad7d1c04f5cdb12d_5630_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/bharati_hu682a673afd755555ad7d1c04f5cdb12d_5630_f76963ea3d8c46fbaee41b7c15acfcc9.webp&#34;
               width=&#34;100&#34;
               height=&#34;120&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.aparnabharati.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Aparna Bharati&lt;/a&gt;&lt;/br&gt; Assistant Professor&lt;/br&gt; Department of Computer Science and Engineering&lt;/br&gt; Lehigh University&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Synthetic Data in Face Biometrics&lt;/b&gt;&lt;/br&gt;&lt;/br&gt; How do image manipulations affect face recognition? How can computer-aided solutions detect and profile these manipulations? In this talk, I will present my recent work and the findings obtained while trying to answer these questions. We will discuss solutions to detect retouched faces by a variety of methods, including smartphone apps, as well as evaluate when face retouching is a problem for face recognition and our society. Moreover, we will talk about the recent trend of generating synthetic faces and how one can measure identity leakage from the training set to the generated samples, a major privacy issue that indeed deserves attention. Lastly, I introduce our recent work on SynthProv, which allies provenance analysis to synthetic face detection and identity leakage evaluation. &lt;a name=&#34;aczajka&#34;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Dr. Adam Czajka&#34; srcset=&#34;
               /teaching/biometrics-aut23/czajka_hua56767b233d4ac23bce131738d751b09_4473_5e340d6c75c6a539b40a1cc35e79e1d5.webp 400w,
               /teaching/biometrics-aut23/czajka_hua56767b233d4ac23bce131738d751b09_4473_ccd09ede64b65d0435b3900a03dc0f6d.webp 760w,
               /teaching/biometrics-aut23/czajka_hua56767b233d4ac23bce131738d751b09_4473_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/czajka_hua56767b233d4ac23bce131738d751b09_4473_5e340d6c75c6a539b40a1cc35e79e1d5.webp&#34;
               width=&#34;100&#34;
               height=&#34;120&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://engineering.nd.edu/faculty/adam-czajka/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Adam Czajka&lt;/a&gt;&lt;/br&gt; Associate Professor&lt;/br&gt; Department of Computer Science and Engineering&lt;/br&gt; University of Notre Dame&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Do you want a better presentation attack detection algorithm? Tell it where to look!&lt;/b&gt;&lt;/br&gt;&lt;/br&gt; This lecture will discuss the topic of human-machine pairing for building trustworthy and human-interpretable iris recognition and biometric presentation attack detection methods. We will discuss approaches of guiding modern Artificial Intelligence models towards features salient for humans comparing irises (including forensic samples) and detecting spoofing attacks. Such guidance allows the AI methods to generalize to unknown attack types, and to create human-interpretable solutions assisting human examiners. We will discuss also selected approaches for effective use of always-limited human salience information (e.g., utilization of human salience in a teacher-student training paradigm) to scale this methodology to large datasets not accompanied by human annotations.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;grading&#34;&gt;Grading&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%) &lt;/th&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%) &lt;/th&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%) &lt;/th&gt;
&lt;th&gt;Concept &lt;/th&gt;
&lt;th&gt;Interval (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;[96, 100)&lt;/td&gt;
&lt;td&gt;B+&lt;/td&gt;
&lt;td&gt;[88, 92)&lt;/td&gt;
&lt;td&gt;C+&lt;/td&gt;
&lt;td&gt;[76, 80)&lt;/td&gt;
&lt;td&gt;D+&lt;/td&gt;
&lt;td&gt;[64, 68)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A-&lt;/td&gt;
&lt;td&gt;[92, 96)&lt;/td&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;[84, 88)&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;[72, 76)&lt;/td&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;[60, 64)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;B-&lt;/td&gt;
&lt;td&gt;[80, 84)&lt;/td&gt;
&lt;td&gt;C-&lt;/td&gt;
&lt;td&gt;[68, 72)&lt;/td&gt;
&lt;td&gt;F&lt;/td&gt;
&lt;td&gt;(0, 60)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;distribution&#34;&gt;Distribution&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Undergraduate  &lt;/th&gt;
&lt;th&gt;Graduate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Assignments (4)  &lt;/td&gt;
&lt;td&gt;40%&lt;/td&gt;
&lt;td&gt;25%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exams (2)&lt;/td&gt;
&lt;td&gt;50%&lt;/td&gt;
&lt;td&gt;40%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Project&lt;/td&gt;
&lt;td&gt;+10% (extra)&lt;/td&gt;
&lt;td&gt;25%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Participation&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;On the News&lt;/td&gt;
&lt;td&gt;+1% (extra)&lt;/td&gt;
&lt;td&gt;+1% (extra)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;assignments&#34;&gt;Assignments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_01.pdf&#34;&gt;Assignment 1&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_01.zip&#34;&gt;data&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_01_answers.pdf&#34;&gt;good answers&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_02.pdf&#34;&gt;Assignment 2&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_02.zip&#34;&gt;data&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_02_answers.pdf&#34;&gt;good answers&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_03.pdf&#34;&gt;Assignment 3&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_03_data.zip&#34;&gt;data&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_03_answers.pdf&#34;&gt;good answers&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_04.pdf&#34;&gt;Assignment 4&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_04_data.zip&#34;&gt;data&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/assign_04_answers.pdf&#34;&gt;good answers&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- XyPK04;579?) --&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Late Policy&lt;/strong&gt;&lt;br&gt;
Deduction of 10% of the maximum possible grade for each day of delay.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;exams&#34;&gt;Exams&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Midterm Exam, 10/04, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/midterm_answers.pdf&#34;&gt;good answers&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Final Exam, 12/11, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/final_answers.pdf&#34;&gt;good answers&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a name=&#34;project&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;project&#34;&gt;Project&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Written report and presentation, work alone or in pairs.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Possible Topics&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Presentation attack (performance, detection, and mitigation) of fingerprint recognition.&lt;/li&gt;
&lt;li&gt;Presentation attack of face recognition.&lt;/li&gt;
&lt;li&gt;Presentation attack of iris recognition.&lt;/li&gt;
&lt;li&gt;Implementation of &lt;em&gt;complete&lt;/em&gt; class attendance system.&lt;/li&gt;
&lt;li&gt;Implementation of recognition of traits other than fingerprints, face, and iris.&lt;/li&gt;
&lt;li&gt;Presentation and implementation of state-of-the-art scientific publications.&lt;/li&gt;
&lt;li&gt;Discussion about the ethical aspects of Biometrics and surveillance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;Chosen Topics&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Team&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Presentation&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Team 1  &lt;/td&gt;
&lt;td&gt;The Ethics of Biometrics  &lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/pres1.pdf&#34;&gt;slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 2&lt;/td&gt;
&lt;td&gt;Fingerprint Spoofing&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/pres2.pdf&#34;&gt;slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 3&lt;/td&gt;
&lt;td&gt;Iris Spoofing&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/pres3.pdf&#34;&gt;slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 4&lt;/td&gt;
&lt;td&gt;Iris Obfuscation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/pres4.pdf&#34;&gt;slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Team 5&lt;/td&gt;
&lt;td&gt;Speaker Recognition&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/pres5.pdf&#34;&gt;slides&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a name=&#34;part&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;participation&#34;&gt;Participation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Class Attendance: every presence counts.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Today-I-missed&lt;/em&gt; Statements: every submission counts.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Today-I-missed&lt;/em&gt; Statements&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After every attended class, each student will have to submit (through Sakai) a short paragraph answering one of the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What is your biggest question after class? &lt;strong&gt;OR&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;What was the most interesting point you learned today?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Inspired by  &lt;a href=&#34;https://www.ic.unicamp.br/~sandra/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Sandra Avila&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Today I missed&amp;amp;hellip;&#34;
           src=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/point.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Oopsie&lt;/em&gt; Cards&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Each student has three &lt;em&gt;&amp;ldquo;Oopsie&amp;rdquo;&lt;/em&gt; Cards, which will allow them to avoid losing points because of class absence
and lack of &lt;em&gt;Today-I-missed&lt;/em&gt; Statement submissions.
They might also use their cards to excuse late-delivered assignments.
The cards are not valid to dismiss or postpone exam and final project dates.
Students may use their three cards at their own discretion, as long as they clearly communicate the instructor.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Life happens, be wise.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Oopsie card.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/biometrics-aut23/card.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;biometrics-on-the-news&#34;&gt;Biometrics on the News&lt;/h2&gt;
&lt;p&gt;Posted by the students and the instructor on Sakai.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pbs.org/wgbh/nova/article/koala-fingerprints/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Koalas have fingerprints almost identical to ours.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dailymail.co.uk/news/article-12210813/Brazilian-thief-taped-photos-victims-faces-DUMMY-bypass-facial-recognition.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brazilian thief spoofed victims faces.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.talosintelligence.com/fingerprint-research/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fingerprint cloning: myth or reality?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.technologyreview.com/2019/08/14/133723/data-leak-exposes-unchangeable-biometric-data-of-over-1-million-people/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data leak of 1M people&amp;rsquo;s biometric data in UK.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.theverge.com/2019/10/23/20929178/samsung-galaxy-s10-note-1o-fingerprint-recognition-issue-patch-ultrasonic-sensor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Samsung phones use ultrasonic fingerprint device.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Touch_ID&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apple uses capacitive fingerprint device (with 500 ppi).&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Racial Discrimination in Face Recognition Technology.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ajl.org/facial-recognition-technology&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;What is Facial Recognition Technology?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.wbur.org/news/2020/06/23/boston-facial-recognition-ban&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Boston Bans Use Of Facial Recognition Technology.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=a4iNg0wWBsQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adversarial Attack on ArcFace.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.reuters.com/technology/scrutiny-iris-scanning-crypto-project-worldcoin-grows-2023-09-01/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scrutiny of Iris-scanning Crypto Project Grows.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://twitter.com/notcapnamerica/status/1725901659270742084&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Scammers used AI to replicate son’s voice.&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://vision.ucsd.edu/content/yale-face-database&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yale face dataset&lt;/a&gt;, used in the 3rd assignment.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;academic-integrity&#34;&gt;Academic Integrity&lt;/h2&gt;
&lt;p&gt;Students are expected to adhere to the LUC statements on academic integrity available at &lt;a href=&#34;https://bit.ly/3TmiQkQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3TmiQkQ&lt;/a&gt;.
These policies fully apply to this course.
The penalty for task-wise academic misconduct is losing all the task&amp;rsquo;s points.
Multiple events of misconduct will incur in failing the entire course (with an F grade).
All cases of academic misconduct will be reported to the proper department offices.
Lastly, students are not allowed to use AI assisted technology (such as &lt;a href=&#34;https://chat.openai.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ChatGPT&lt;/a&gt;) along the entirety of the course,
unless explicitly authorized by the instructor.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;accommodations&#34;&gt;Accommodations&lt;/h2&gt;
&lt;p&gt;Students who have disabilities and wish to request academic accommodations are advised to contact the
&lt;em&gt;Services for Students With Disabilities&lt;/em&gt; (SSWD) office at 773-508-3700 or &lt;a href=&#34;mailto:SSWD@luc.edu&#34;&gt;SSWD@luc.edu&lt;/a&gt; as soon as possible.
The SSWD office will provide accommodation letters that, once shared with the instructor, will be fully accommodated
as per the terms of their content with no further questions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning the Shell, Fall 2023</title>
      <link>https://danielmoreira.github.io/teaching/comptool-aut23/</link>
      <pubDate>Sun, 20 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/comptool-aut23/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/comptool-aut23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/comptool-aut23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/comptool-aut23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/comptool-aut23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 141-001 / COMP 400D-001 Intro to Computing Tools and Techniques&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;br&gt;
Teaching Assistants: Alvaro Delandaluce (&lt;a href=&#34;mailto:adelandaluce@luc.edu&#34;&gt;adelandaluce@luc.edu&lt;/a&gt;) and Bright Duffour (&lt;a href=&#34;mailto:bduffour@luc.edu&#34;&gt;bduffour@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: TUE, 4:15 to 5:30 PM, &lt;a href=&#34;https://luc.zoom.us/j/83489970255&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online&lt;/a&gt;&lt;br&gt;
Office Hours: MON and TUE evenings, 6 to 8 PM, and WED mornings, 8 AM to noon, 310 Doyle Center or Zoom,
&lt;a href=&#34;https://bit.ly/3KUUaND&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt; &lt;br&gt;
Sakai: &lt;a href=&#34;https://sakai.luc.edu/x/Qzs2kZ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://sakai.luc.edu/x/Qzs2kZ&lt;/a&gt;&lt;/p&gt;
&lt;!--- &gt; Announcements. --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Shell terminal.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/comptool-aut23/terminal.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Despite the current era of rich graphical user interfaces (desktop, web, and mobile), the &amp;ldquo;command line&amp;rdquo; experience
remains important, especially for software developers and computer-aided scientific researchers.
Many development scenarios still require command line and fluency in Unix tools, including the modern embedded,
cloud, cybersecurity, and supercomputing environments. With mobile computing and Internet of Things, Unix (via Linux)
has risen to the level of a ubiquitous platform, owing to its lightweight and open-source nature.
While this course does not aim at being a comprehensive programming class, students will master basic programming
skills using shell scripting. They will also learn about problem-solving using Unix commands supported by shell scripts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Please refer to &lt;a href=&#34;https://sakai.luc.edu/x/Qzs2kZ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt; for having access to the materials, assignments, quizzes,
announcements, grading, and progress of the course. This page is static and will not be updated.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt;
&lt;p&gt;This course is offered in multiple sessions with the following leading and contributing LUC instructors (Spring 2023):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;John O&amp;rsquo;Sullivan&lt;/li&gt;
&lt;li&gt;Nathan Hishon&lt;/li&gt;
&lt;li&gt;Leo Irakliotis&lt;/li&gt;
&lt;li&gt;Konstantin Läufer&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shots, W. &lt;em&gt;The Linux Command Line, 2nd Edition&lt;/em&gt;. No Starch Press Book, 2019. Available at &lt;a href=&#34;https://linuxcommand.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://linuxcommand.org/&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>IH&amp;MMSec &#39;23: Proceedings of the 2023 ACM Workshop on Information Hiding and Multimedia Security</title>
      <link>https://danielmoreira.github.io/publication/2023_ihmmsec/</link>
      <pubDate>Wed, 28 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2023_ihmmsec/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Computing for the Sciences, Spring 2023</title>
      <link>https://danielmoreira.github.io/teaching/compsci-spr23/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/compsci-spr23/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/compsci-spr23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/compsci-spr23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/compsci-spr23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/compsci-spr23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 180-001 Computing and Data Analysis for the Sciences&lt;br&gt;
Level: Undergraduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;br&gt;
Teaching Assistant: Jerome Santos (&lt;a href=&#34;mailto:msantos@luc.edu&#34;&gt;msantos@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: TUE, 4:15 to 6:45 PM, 103 Cuneo Hall&lt;br&gt;
Office Hours: THR, 6:00 to 8:00 PM, and FRI, 10:00 AM to 12:00 PM, &lt;a href=&#34;https://calendly.com/danielmoreira/comp-180-office-hours&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt;&lt;br&gt;
Sakai: &lt;a href=&#34;https://sakai.luc.edu/x/ouBYMu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://sakai.luc.edu/x/ouBYMu&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Grades are now &lt;a href=&#34;https://danielmoreira.github.io/teaching/compsci-spr23/grades.pdf&#34;&gt;available&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Food establishments in Chicago.&#34; srcset=&#34;
               /teaching/compsci-spr23/food_map_hud0aaa8180fa6f7d63b082ff22f25d22b_224304_5eef7d1b82b7bac505077a9ad02bffe1.webp 400w,
               /teaching/compsci-spr23/food_map_hud0aaa8180fa6f7d63b082ff22f25d22b_224304_bc0267bce262123bad26b84b25cedda2.webp 760w,
               /teaching/compsci-spr23/food_map_hud0aaa8180fa6f7d63b082ff22f25d22b_224304_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/compsci-spr23/food_map_hud0aaa8180fa6f7d63b082ff22f25d22b_224304_5eef7d1b82b7bac505077a9ad02bffe1.webp&#34;
               width=&#34;600&#34;
               height=&#34;546&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p style=&#34;text-align: center;&#34;&gt;&lt;font size=&#34;1&#34;&gt;Map with inspected Chicago food establishments generated during the course.&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;Regardless of their field, scientists&amp;rsquo; work generates and consumes large troves of research data,
whose effective, efficient, and reliable storage, management, processing, interpretation, presentation, and sharing
are mostly possible due to the current computer systems.
Besides mastering one&amp;rsquo;s own scientific area of research, mastering the usage of the available computing power
to analyze data has become essential to foster steady and solid scientific progress.
This course aims at training attendees to use modern computing tools and techniques to perform rapid
data analysis and rich data presentation, both within collaborative environments and in scientific contexts.
At the end of the course, students shall be well-versed in writing their own programs and leveraging up-to-date
scientific libraries to collaboratively analyze their research data and richly present their findings.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Attending students are required to have taken MATH 117 (College Algebra) or have been placed in MATH 118
(Precalculus) or higher.
Please refer to &lt;a href=&#34;https://sakai.luc.edu/x/ouBYMu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt; for having access to the materials, assignments, quizzes,
announcements, grading, and progress of the course. This page is static and will not be updated.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;This course is heavily based on Dr. &lt;a href=&#34;https://abuhamad.cs.luc.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mohammed Abuhamad’s&lt;/a&gt; previous course.
I sincerely thank Mohammed for kindly allowing me to rely upon his materials.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Harrington, A. &lt;em&gt;Hands-on Python Tutorial&lt;/em&gt;. Available at &lt;a href=&#34;https://anh.cs.luc.edu/python/hands-on/3.1/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://anh.cs.luc.edu/python/hands-on/3.1/index.html&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The City of Chicago. &lt;em&gt;Chicago Food Inspections Dataset&lt;/em&gt;. Available at: &lt;a href=&#34;https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Learning the Shell, Spring 2023</title>
      <link>https://danielmoreira.github.io/teaching/comptool-spr23/</link>
      <pubDate>Fri, 27 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/comptool-spr23/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/comptool-spr23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/comptool-spr23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/comptool-spr23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/comptool-spr23/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 141-001 / COMP 400D-001 Intro to Computing Tools and Techniques&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;br&gt;
Teaching Assistants: Brianna Chou (&lt;a href=&#34;mailto:bchou@luc.edu&#34;&gt;bchou@luc.edu&lt;/a&gt;) and Jerome Santos (&lt;a href=&#34;mailto:msantos@luc.edu&#34;&gt;msantos@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: MON, 4:15 to 5:30 PM, &lt;a href=&#34;https://luc.zoom.us/j/81055987601&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online&lt;/a&gt;&lt;br&gt;
Office Hours: WED, 6:00 to 8:00 PM, and FRI, 8:00 to 10:00 AM, &lt;a href=&#34;https://calendly.com/danielmoreira/comp-141-office-hours&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt;&lt;br&gt;
Sakai: &lt;a href=&#34;https://sakai.luc.edu/x/HxHiwy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://sakai.luc.edu/x/HxHiwy&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Grades are now &lt;a href=&#34;https://danielmoreira.github.io/teaching/comptool-aut23/grades.pdf&#34;&gt;available&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Shell terminal.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/comptool-spr23/terminal.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Despite the current era of rich graphical user interfaces (desktop, web, and mobile), the &amp;ldquo;command line&amp;rdquo; experience
remains important, especially for software developers and computer-aided scientific researchers.
Many development scenarios still require command line and fluency in Unix tools, including the modern embedded,
cloud, cybersecurity, and supercomputing environments. With mobile computing and Internet of Things, Unix (via Linux)
has risen to the level of a ubiquitous platform, owing to its lightweight and open-source nature.
While this course does not aim at being a comprehensive programming class, students will master basic programming
skills using shell scripting.
They will also learn about problem-solving using Unix commands supported by shell scripts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Please refer to &lt;a href=&#34;https://sakai.luc.edu/x/HxHiwy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt; for having access to the materials, assignments, quizzes,
announcements, grading, and progress of the course. This page is static and will not be updated.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt;
&lt;p&gt;This course is offered in multiple sessions with the following leading and contributing LUC instructors (Spring 2023):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nathan Hishon&lt;/li&gt;
&lt;li&gt;John O&amp;rsquo;Sullivan&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shots, W. &lt;em&gt;The Linux Command Line, 2nd Edition&lt;/em&gt;. No Starch Press Book, 2019. Available at &lt;a href=&#34;https://linuxcommand.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://linuxcommand.org/&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Motif Mining: Finding and Summarizing Remixed Image Content</title>
      <link>https://danielmoreira.github.io/publication/2023_wacv_motif/</link>
      <pubDate>Thu, 05 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2023_wacv_motif/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Human Saliency-driven Patch-based Matching for Interpretable Post-mortem Iris Recognition</title>
      <link>https://danielmoreira.github.io/publication/2023_wacv_human/</link>
      <pubDate>Wed, 04 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2023_wacv_human/</guid>
      <description></description>
    </item>
    
    <item>
      <title>COMP 141, Homework</title>
      <link>https://danielmoreira.github.io/post/comp141/</link>
      <pubDate>Wed, 07 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/post/comp141/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Dear COMP 141 Students,&lt;/p&gt;
&lt;p&gt;Please find below some tips to answer Homework #7.
I acknowledge this is a more challenging assignment,
in particular given the course&amp;rsquo;s asynchronous and fully remote nature.
Because of this, I&amp;rsquo;d like to give you some hints that might be useful to answer it.&lt;/p&gt;
&lt;p&gt;May you have any questions, please let me know.&lt;br&gt;
&amp;ndash; Daniel (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;question-1&#34;&gt;Question 1&lt;/h2&gt;
&lt;p&gt;The steps below will give you some structure to answer this question.&lt;/p&gt;
&lt;h3 id=&#34;11-create-a-username-on-github&#34;&gt;1.1. Create a username on GitHub.&lt;/h3&gt;
&lt;p&gt;You can do this at &lt;a href=&#34;https://github.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com&lt;/a&gt;, using the &amp;ldquo;Sign Up&amp;rdquo; button in the top right corner
of the page.
Follow the steps and provide a screenshot with your new GitHub profile.
This will be your screenshot number one.&lt;/p&gt;
&lt;p&gt;Mine is below, for your reference.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/comp141/f1_hu35fb43e64cbb18d57e943d37f0b21ab4_251672_135826c5eb7f71df4779ea2d1305420d.webp 400w,
               /post/comp141/f1_hu35fb43e64cbb18d57e943d37f0b21ab4_251672_3f2d22d8ec9b48f5ddc1d02a64061f22.webp 760w,
               /post/comp141/f1_hu35fb43e64cbb18d57e943d37f0b21ab4_251672_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/post/comp141/f1_hu35fb43e64cbb18d57e943d37f0b21ab4_251672_135826c5eb7f71df4779ea2d1305420d.webp&#34;
               width=&#34;600px&#34;
               height=&#34;403&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;12-create-a-project-on-github&#34;&gt;1.2. Create a project on GitHub.&lt;/h3&gt;
&lt;p&gt;This can be done through the GitHub web interface, from your GitHub profile page
that you&amp;rsquo;ve just used to generate a screenshot.
In the top right corner of your profile page, there is button with a plus sign.
Click there and select the &amp;ldquo;New repository&amp;rdquo; option.&lt;/p&gt;
&lt;p&gt;In the following page, provide a &amp;ldquo;Repository name&amp;rdquo;, and mark it as &amp;ldquo;Public&amp;rdquo; (so that everybody,
including the TA and me, can access it).
Don&amp;rsquo;t forget to select the &amp;ldquo;Add a README file&amp;rdquo; option, so your project is not empty.
You may also provide a project &amp;ldquo;Description&amp;rdquo;, if you want.
This will be useful once you get to the point where you have lots of projects.
A possible description is &amp;ldquo;My first GitHub project for Comp 141.&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;After doing this, go to the bottom of the page, and click on the &amp;ldquo;Create repository&amp;rdquo; button.
Voilà, you now have your new project on GitHub, on the web.
Provide a screenshot of the current project page; this will be you screenshot number two.&lt;/p&gt;
&lt;h3 id=&#34;13-clone-the-project-from-github-on-the-web-to-your-local-computer&#34;&gt;1.3. Clone the project from GitHub (on the web) to your local computer.&lt;/h3&gt;
&lt;p&gt;On your computer, open the terminal screen.
Make sure you have git installed:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: git --version
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;If you don&amp;rsquo;t, install it with either apt-get or homebrew, depending on your OS.
For Linux users (your COMP 141 Virtual Machine is Linux):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: sudo apt install git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For macOS users:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% brew install git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Clone the project from GitHub to your local machine.
Go to your project GitHub page (the one you&amp;rsquo;ve just used to generate the last screenshot),
and click on the &amp;ldquo;&amp;lt;&amp;gt; Code&amp;rdquo; button on the top mid-right portion of the screen.
Select the &amp;ldquo;HTTPS&amp;rdquo; option on the &amp;ldquo;Clone&amp;rdquo; function and copy the
&amp;ldquo;&lt;code&gt;https://gtihub.com/&amp;lt;your_name&amp;gt;/&amp;lt;your_project&amp;gt;&lt;/code&gt;&amp;rdquo; link.&lt;/p&gt;
&lt;p&gt;Go back to the terminal and type:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: git clone https://gtihub.com/&amp;lt;your_name&amp;gt;/&amp;lt;your_project&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Don&amp;rsquo;t forget to paste and replace &amp;ldquo;&lt;code&gt;https://gtihub.com/&amp;lt;your_name&amp;gt;/&amp;lt;your_project&amp;gt;&lt;/code&gt;&amp;rdquo;
with the content you&amp;rsquo;ve just copied from your GitHub project page.&lt;/p&gt;
&lt;p&gt;Voilà, your project was copied to your local computer.
Execute the &amp;ldquo;ls&amp;rdquo; command on your terminal and localize your project folder;
the folder&amp;rsquo;s name will be the same as your project&amp;rsquo;s.
Generate a screenshot of your terminal with this content and add to your answers;
this will be your screenshot number three.&lt;/p&gt;
&lt;h3 id=&#34;14-setup-an-authentication-token-so-you-can-upload-things-to-your-github-project&#34;&gt;1.4. Setup an authentication token, so you can upload things to your GitHub project.&lt;/h3&gt;
&lt;p&gt;This is a step with security purposes, to avoid people inadvertently messing up with your project.
Go to your GitHub profile page (the one you&amp;rsquo;ve used to generate the first screenshot).
Click on your profile picture in the top right corner of the page.
Select the &amp;ldquo;Settings&amp;rdquo; option on the drop-down menu.&lt;/p&gt;
&lt;p&gt;On the following page, on the left-side menu, select the &amp;ldquo;Developer settings&amp;rdquo; option
(yes, you&amp;rsquo;ll be a developer).
On the following one, select the &amp;ldquo;Personal access tokens&amp;rdquo; drop-down option.
We want the &amp;ldquo;Tokens (classic)&amp;rdquo; feature.
Click on it and proceed to the next page.&lt;/p&gt;
&lt;p&gt;On the next page, select the top right corner &amp;ldquo;Generate new token&amp;rdquo; button.
Again, select the &amp;ldquo;Generate new token (classic)&amp;rdquo; option.
Provide your GitHub password, to proceed to the next step.&lt;/p&gt;
&lt;p&gt;Fill-in the blanks of the form within the next page.
For instance, in the &amp;ldquo;Note&amp;rdquo; field, add something like &amp;ldquo;My first token for test purposes.&amp;rdquo;
For the &amp;ldquo;Expiration&amp;rdquo; field, select &amp;ldquo;No expiration&amp;rdquo; and ignore, for now, the warning message
(we can talk about it in more detail through e-mail, if you want to).
In the available &amp;ldquo;scopes&amp;rdquo;, select the &amp;ldquo;repo&amp;rdquo; one.
Go to the bottom of the page and click on the &amp;ldquo;Generate token&amp;rdquo; button.&lt;/p&gt;
&lt;p&gt;Voilà, your created a GitHub security token.
Take a screenshot of the next page and add to your answers; this will be your screenshot number four.&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t forget to copy the long string that is provided in this page.
This will be your password to upload local modifications to your GitHub project.
We&amp;rsquo;ll need it in the next step.&lt;/p&gt;
&lt;h3 id=&#34;15-add-a-new-file-to-your-project&#34;&gt;1.5. Add a new file to your project.&lt;/h3&gt;
&lt;p&gt;Back to your local machine, using your terminal, create a new file on your project&amp;rsquo;s folder.
Make sure (with &amp;ldquo;pwd&amp;rdquo;, &amp;ldquo;cd&amp;rdquo;, and &amp;ldquo;ls&amp;rdquo;) that you&amp;rsquo;re inside the correct folder.
You may use any file editor of your preference.
In the example below, I&amp;rsquo;m using &amp;ldquo;vi&amp;rdquo; to edit files.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: cd &amp;lt;your_project&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: vi my_file.txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Don&amp;rsquo;t forget to replace &amp;ldquo;&amp;lt;your_project&amp;gt;&amp;rdquo; with your project&amp;rsquo;s folder.&lt;/p&gt;
&lt;p&gt;Type some content to &amp;ldquo;my_file.txt&amp;rdquo; and save it.
In the real world, you&amp;rsquo;ll be doing this over a program source code, adding lines of
commands and program configurations.
Save the file and quit the file editor.&lt;/p&gt;
&lt;p&gt;Now it&amp;rsquo;s time to &amp;ldquo;upload&amp;rdquo; the local file to your project on Git.
In your local terminal, inside the folder of your project, execute the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: git add my_file.txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This command is telling the GitHub application that you want to include the file
you&amp;rsquo;ve just created to your project.
After doing this, &amp;ldquo;commit&amp;rdquo; the added file to a new version of your project:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: git commit my_file.txt -m &amp;#34;Adding my_file.txt to the project.&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Observe that the message given to &amp;ldquo;-m&amp;rdquo; can be any string and should be descriptive of
what you&amp;rsquo;re doing with your project.&lt;/p&gt;
&lt;p&gt;Now comes the time to upload the new project version (with the local modifications).
You can do it by using the &amp;ldquo;git push&amp;rdquo; command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: git push origin main
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This command will request your GitHub username (the same you used in your profile), and a password.
Provide the long string generated in the previous step as the password.
If successful, this command will upload &amp;ldquo;my_file.txt&amp;rdquo; to the GitHub project web page, in the &amp;ldquo;main&amp;rdquo;
branch of your project.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Other branches are possible (for different versions of the program being developed), but this is
something you&amp;rsquo;ll learn in your future as a developer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Go to your GitHub project page (the one that you&amp;rsquo;ve used to generate the second screenshot)
and verify that &amp;ldquo;my_file.txt&amp;rdquo; is available there, together with the &amp;ldquo;README.md&amp;rdquo; file.
Take a screenshot of this status and add to your answers; this will be your screenshot number five.&lt;/p&gt;
&lt;h3 id=&#34;16-watch-the-content-of-httpswwwyoutubecomwatchv0fkg7e37bqe&#34;&gt;1.6. Watch the content of &lt;a href=&#34;https://www.youtube.com/watch?v=0fKg7e37bQE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.youtube.com/watch?v=0fKg7e37bQE&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Watch the content of the GitHub tutorial and try to make a parallel with the steps above.
May you have any questions about the video and the steps, please let me know.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;GitHub is an amazing tool that you must use in your coding career.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;question-2&#34;&gt;Question 2&lt;/h2&gt;
&lt;p&gt;The steps below will give you some structure to answer this question.&lt;/p&gt;
&lt;h3 id=&#34;21-create-a-json-file-using-your-local-terminal&#34;&gt;2.1. Create a JSON file using your local terminal.&lt;/h3&gt;
&lt;p&gt;JSON files are text files in &amp;ldquo;JavaScript Object Notation&amp;rdquo; (&lt;a href=&#34;https://www.json.org/json-en.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;JSON&lt;/a&gt;)
whose content is structured in a more human-readable format.
JSON files aim at storing data about the elements of a problem domain, whose reading is easy to people.
In the example below, downloaded from this &lt;a href=&#34;https://drive.google.com/file/d/1TVf-Von3auR2B3WPy585SoCb8WEM4auU/view&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;,
we have data about cats that might be useful for a veterinary app.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Abyssinian&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;country&amp;#34;: &amp;#34;Ethiopia&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;origin&amp;#34;: &amp;#34;Natural\/Standard&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;coat&amp;#34;: &amp;#34;Short&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pattern&amp;#34;: &amp;#34;Ticked&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Aegean&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;country&amp;#34;: &amp;#34;Greece&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;origin&amp;#34;: &amp;#34;Natural\/Standard&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;coat&amp;#34;: &amp;#34;Semi-long&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pattern&amp;#34;: &amp;#34;Bi- or tri-colored&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;American Curl&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;country&amp;#34;: &amp;#34;United States&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;origin&amp;#34;: &amp;#34;Mutation&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;coat&amp;#34;: &amp;#34;Short\/Long&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pattern&amp;#34;: &amp;#34;All&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;American Bobtail&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;country&amp;#34;: &amp;#34;United States&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;origin&amp;#34;: &amp;#34;Mutation&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;coat&amp;#34;: &amp;#34;Short\/Long&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pattern&amp;#34;: &amp;#34;All&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;American Shorthair&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;country&amp;#34;: &amp;#34;United States&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;origin&amp;#34;: &amp;#34;Natural&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;coat&amp;#34;: &amp;#34;Short&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pattern&amp;#34;: &amp;#34;All but colorpoint&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;American Wirehair&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;country&amp;#34;: &amp;#34;United States&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;origin&amp;#34;: &amp;#34;Mutation&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;coat&amp;#34;: &amp;#34;Rex&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pattern&amp;#34;: &amp;#34;All but colorpoint&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Arabian Mau&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;country&amp;#34;: &amp;#34;Arabian Peninsula&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;origin&amp;#34;: &amp;#34;Natural&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;coat&amp;#34;: &amp;#34;Short&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pattern&amp;#34;: &amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Australian Mist&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;country&amp;#34;: &amp;#34;Australia&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;origin&amp;#34;: &amp;#34;Crossbreed&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;coat&amp;#34;: &amp;#34;Short&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pattern&amp;#34;: &amp;#34;Spotted and Classic tabby&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Asian&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;country&amp;#34;: &amp;#34;developed in the United Kingdom (founding stock from Asia)&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;origin&amp;#34;: &amp;#34;&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;coat&amp;#34;: &amp;#34;Short&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pattern&amp;#34;: &amp;#34;Evenly solid&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Asian Semi-longhair&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;country&amp;#34;: &amp;#34;United Kingdom&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;origin&amp;#34;: &amp;#34;Crossbreed&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;coat&amp;#34;: &amp;#34;Semi-long&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;pattern&amp;#34;: &amp;#34;Solid&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As you might observe, this file depicts a list with 10 cats.
Each cat has information about its &amp;ldquo;breed&amp;rdquo;, &amp;ldquo;country&amp;rdquo;, &amp;ldquo;origin&amp;rdquo;, &amp;ldquo;coat&amp;rdquo;, and fur &amp;ldquo;pattern&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;The objective of this and of the following questions is to write shellscripts that read this type of file.
To answer question 2, start by opening your local terminal and creating a file named &amp;ldquo;catfacts.json&amp;rdquo;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: vi catfacts.json
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is my screen with &amp;ldquo;vi&amp;rdquo; open and the creation of &amp;ldquo;catfacts.json&amp;rdquo;.
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/comp141/f2_hu1c0b472ad7601c0ecbac2cb20f5ca62f_95942_9e17139c8b96e7d7978cd66ccf3b6ae2.webp 400w,
               /post/comp141/f2_hu1c0b472ad7601c0ecbac2cb20f5ca62f_95942_64b2cd74041e530aa5beb1f7f06dab90.webp 760w,
               /post/comp141/f2_hu1c0b472ad7601c0ecbac2cb20f5ca62f_95942_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/post/comp141/f2_hu1c0b472ad7601c0ecbac2cb20f5ca62f_95942_9e17139c8b96e7d7978cd66ccf3b6ae2.webp&#34;
               width=&#34;600px&#34;
               height=&#34;507&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;22-create-a-shellscript-to-extract-data-from-catfactsjson-in-your-local-terminal&#34;&gt;2.2. Create a shellscript to extract data from &amp;ldquo;catfacts.json&amp;rdquo; in your local terminal.&lt;/h3&gt;
&lt;p&gt;In the next step, let&amp;rsquo;s create a shellscript to extract information from &amp;ldquo;catfacts.json&amp;rdquo;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: vi catfacts.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s say we want to extract all the breeds stored in the file (type inside the &amp;ldquo;catfacts.sh&amp;rdquo; file):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# shellscript to gather all the breeds stored inside catfacts.json
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;grep &amp;#39;&amp;#34;breed&amp;#34;:&amp;#39; catfacts.json | uniq | sort
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After saving the shellscript file and quiting the file editor, make it executable with &amp;ldquo;chmod&amp;rdquo;
(on the terminal):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: chmod +x catfacts.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Execute the shellscript (on the terminal):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: ./catfacts.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The expected output is all the breeds stored within &amp;ldquo;catfacts.json&amp;rdquo;, without repetitions (uniq)
and alphabetically sorted (sort):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Abyssinian&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Aegean&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;American Bobtail&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;American Curl&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;American Shorthair&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;American Wirehair&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Arabian Mau&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Asian Semi-longhair&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Asian&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &amp;#34;breed&amp;#34;: &amp;#34;Australian Mist&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Provide a screenshot with the output above on your terminal as your answer to question 2.&lt;/p&gt;
&lt;h2 id=&#34;question-3&#34;&gt;Question 3&lt;/h2&gt;
&lt;p&gt;The steps below will give you some structure to answer this question.&lt;/p&gt;
&lt;h3 id=&#34;31-install-jq-in-your-local-system&#34;&gt;3.1. Install JQ in your local system.&lt;/h3&gt;
&lt;p&gt;To answer questions 3-6, install &lt;a href=&#34;https://stedolan.github.io/jq/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;JQ&lt;/a&gt; in your system.
For Linux users (your COMP 141 Virtual Machine is Linux):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host: sudo apt install jq
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For macOS users:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% brew install jq
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;JQ (JSON Query) is a library of shellscript commands that makes it easy to extract information
from files in JSON format.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Test JQ on your machine:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% jq --version
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;32-create-a-json-file-with-folks-information&#34;&gt;3.2. Create a JSON file with folks&amp;rsquo; information.&lt;/h3&gt;
&lt;p&gt;Create &amp;ldquo;folks.json&amp;rdquo; using your local terminal:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% vi folks.json
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is the content you must add to &amp;ldquo;folks.json&amp;rdquo; (type inside the file):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   { &amp;#34;first&amp;#34;: &amp;#34;John&amp;#34;, &amp;#34;last&amp;#34;: &amp;#34;Doe&amp;#34;, &amp;#34;age&amp;#34;: 25 },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   { &amp;#34;first&amp;#34;: &amp;#34;Mary&amp;#34;, &amp;#34;last&amp;#34;: &amp;#34;Doe&amp;#34;, &amp;#34;age&amp;#34;: 24 },
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   { &amp;#34;first&amp;#34;: &amp;#34;Jack&amp;#34;, &amp;#34;last&amp;#34;: &amp;#34;Jones&amp;#34;, &amp;#34;age&amp;#34;: 22 }
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;]   
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;This JSON file stores data about three people, namely John, Mary, and Jack.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Make sure &amp;ldquo;folks.json&amp;rdquo; has the expected content:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% cat folks.json
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;33-answer-question-3&#34;&gt;3.3. Answer question 3.&lt;/h3&gt;
&lt;p&gt;How would you extract a specific element from an array?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We&amp;rsquo;ve done this in question 2.
You can use grep or other commands written to a shellscript (&amp;quot;.sh&amp;quot; file).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To introduce JQ to you, here is an example of how you can extract the last names from &amp;ldquo;folks.json&amp;rdquo;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% jq &amp;#39;.[].last&amp;#39; folks.json
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is the expected output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;#34;Doe&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;#34;Doe&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;#34;Jones&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is an example of how you can extract everybody whose last name is &amp;ldquo;Doe&amp;rdquo;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% jq &amp;#39;.[] | select(.last == &amp;#34;Doe&amp;#34;)&amp;#39; folks.json
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The expected output is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;first&amp;#34;: &amp;#34;John&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;last&amp;#34;: &amp;#34;Doe&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;age&amp;#34;: 25
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;first&amp;#34;: &amp;#34;Mary&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;last&amp;#34;: &amp;#34;Doe&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;age&amp;#34;: 24
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And here is an example of how you can extract the age of the second person (the one at position &amp;ldquo;.[1]&amp;rdquo;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% jq &amp;#39;.[1].age&amp;#39; folks.json
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;4-get-folks-with-age-equal-to-25&#34;&gt;4. Get folks with age equal to 25?&lt;/h2&gt;
&lt;p&gt;Here is the JQ command for that:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% jq &amp;#39;.[] | select(.age == 25)&amp;#39; folks.json
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;To make it a script, add the command above to a new file named &amp;ldquo;age25.sh&amp;rdquo;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% vi age25.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here is my screenshot saving this file with &amp;ldquo;vi&amp;rdquo;:
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/comp141/f3_hu581ad0ff28c95cfb4569e8cd89fd38f8_21974_fd69a2d46d4672567254c274117f1dc5.webp 400w,
               /post/comp141/f3_hu581ad0ff28c95cfb4569e8cd89fd38f8_21974_87c7d36f45a63c1d67a299215cc49eaa.webp 760w,
               /post/comp141/f3_hu581ad0ff28c95cfb4569e8cd89fd38f8_21974_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/post/comp141/f3_hu581ad0ff28c95cfb4569e8cd89fd38f8_21974_fd69a2d46d4672567254c274117f1dc5.webp&#34;
               width=&#34;450px&#34;
               height=&#34;186&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t forget to make the shellscript file executable before using it:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% chmod +x age25.sh
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% ./age25.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;The next two questions are very similar, so I&amp;rsquo;m providing only the JQ command.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;5-remove-keyvalue-pair&#34;&gt;5. Remove key/value pair?&lt;/h2&gt;
&lt;p&gt;The command below removes the first name from the &lt;strong&gt;first&lt;/strong&gt; person (position &amp;ldquo;.[0]&amp;rdquo;):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% jq &amp;#39;del(.[0].first)&amp;#39; folks.json
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;You can do the same thing for the last person, using &amp;ldquo;del(.[2].first)&amp;rdquo;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;6-get-sum-of-ages&#34;&gt;6. Get sum of ages?&lt;/h2&gt;
&lt;p&gt;The command below sums up all the ages in the JSON file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;user@host% jq &amp;#39;.[0].age+.[1].age+.[2].age&amp;#39; folks.json
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;Observe that &amp;ldquo;.[0]&amp;rdquo; refers to the 1st person, while &amp;ldquo;.[1]&amp;rdquo; refers to the 2nd, and &amp;ldquo;.[2]&amp;rdquo;
refers to the 3rd and last.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;following-questions&#34;&gt;Following Questions&lt;/h2&gt;
&lt;p&gt;Questions 7-11 are more straightforward, but may you have any issues, let me know.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SILA: a system for scientific image analysis</title>
      <link>https://danielmoreira.github.io/publication/2022_scirep/</link>
      <pubDate>Mon, 31 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2022_scirep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Computer Vision Applications, Fall 2022</title>
      <link>https://danielmoreira.github.io/teaching/cvapp-aut22/</link>
      <pubDate>Mon, 29 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/cvapp-aut22/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/cvapp-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/cvapp-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/cvapp-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 388-002 / COMP 488-002 Computer Science Topics&lt;br&gt;
Format: Seminar&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: MON, 4:15 to 6:45 PM, 117 Cuneo Hall&lt;br&gt;
Office Hours: TUE and THR, 5:00 to 7:00 PM, &lt;a href=&#34;https://bit.ly/3Tos8wx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt;&lt;br&gt;
Sakai: &lt;a href=&#34;https://sakai.luc.edu/x/4tCa9j&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://sakai.luc.edu/x/4tCa9j&lt;/a&gt;&lt;/p&gt;
&lt;!--- &gt; Announcements. --&gt;
&lt;blockquote&gt;
&lt;p&gt;Grades are now &lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/grades.pdf&#34;&gt;available&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Computer Vision then and now.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/cv-then-now.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;How might Google or TinEye reverse image search operate?
How can a computer program process the pixel values of images and video frames and classify the depicted scene,
or leverage the captured faces to perform person identification?
What about manipulated images with tools such as Photoshop?
Are there methods to help to debunk these manipulations?
These are some of the questions we will be addressing in this course,
focusing on state-of-the-art Computer Vision (CV) solutions to reduce the semantic gap
between the pixel values and the desired outcome of complex tasks such as content-based image retrieval,
content classification and recognition, biometric identification, and media forensics,
always with the &lt;a href=&#34;https://danielmoreira.github.io/post/bettersoc/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;greater good&lt;/a&gt; in mind.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Requirements to attend this course are basic programming skills (especially Python) and statistics and probability.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;schedule&#34;&gt;Schedule&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Leaders&lt;/th&gt;
&lt;th&gt;References&lt;/th&gt;
&lt;th&gt;Assignment&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;08/29&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_01.pdf&#34;&gt;Introduction to CV&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instructor&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09/05&lt;/td&gt;
&lt;td&gt;&lt;em&gt;Labor Day&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a01&#34;&gt;A01&lt;/a&gt;, due on 09/15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09/12&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_02.pdf&#34;&gt;Letter Soup: AI, ML, NN, DL, etc.&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instructor&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref123&#34;&gt;[1, 2, 3]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a02&#34;&gt;A02&lt;/a&gt;, due on 09/20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09/19&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_03.pdf&#34;&gt;Image Description&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instructor&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref456&#34;&gt;[4, 5, 6]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a03&#34;&gt;A03&lt;/a&gt;, due on 09/27&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09/26&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_04.pdf&#34;&gt;Image Retrieval&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Nick and Jesus&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref78910&#34;&gt;[7, 8, 9, 10]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a04&#34;&gt;A04&lt;/a&gt;, due on 10/04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10/03&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_05.pdf&#34;&gt;Image Classification&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Nick and Kenneth&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref1112131415&#34;&gt;[11, 12, 13, 14, 15]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a05&#34;&gt;A05&lt;/a&gt;, due on 10/18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10/10&lt;/td&gt;
&lt;td&gt;&lt;em&gt;Fall Break&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10/17&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_06.pdf&#34;&gt;Object Detection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;John and Kenneth&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref1617181920&#34;&gt;[16, 17, 18, 19, 20]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a06&#34;&gt;A06&lt;/a&gt;, due on 10/25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10/24&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_07.pdf&#34;&gt;Image Segmentation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mujtaba and Matt&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref2122232425&#34;&gt;[21, 22, 23, 24, 25]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a07&#34;&gt;A07&lt;/a&gt;, due on 11/01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10/31&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_08.pdf&#34;&gt;Face Detection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;John and Amol&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref26272829&#34;&gt;[26, 27, 28, 29]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a08&#34;&gt;A08&lt;/a&gt;, due on 11/08&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11/07&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_09.pdf&#34;&gt;Face Recognition&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Mujtaba and Amol&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref3031323334&#34;&gt;[30, 31, 32, 33, 34]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a09&#34;&gt;A09&lt;/a&gt;, due on 11/15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11/14&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_10.pdf&#34;&gt;Generative Adversarial Nets&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Jakob and Matt&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref3536373839&#34;&gt;[35, 36, 37, 38, 39]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#a10&#34;&gt;A10&lt;/a&gt;, due on 11/29&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11/21&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_11.pdf&#34;&gt;Attacks &amp;amp; Deep Fake Detection&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instructor&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref404142&#34;&gt;[40, 41, 42]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11/28&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_12.pdf&#34;&gt;Sensitive Video Analysis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Instructor&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref4344&#34;&gt;[43, 44]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12/05&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/lecture_13.pdf&#34;&gt;Provenance Analysis&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Jakob and Jesus&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;#ref4546474849&#34;&gt;[45, 46, 47, 48, 49]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12/12&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/final_exam.pdf&#34;&gt;&lt;em&gt;Final Exam&lt;/em&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;td&gt;N.A.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;assignments&#34;&gt;Assignments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a name=&#34;a01&#34;&gt;&lt;/a&gt; &lt;del&gt;A01: Image Descriptors &lt;a href=&#34;#ref456&#34;&gt;[4, 5, 6]&lt;/a&gt;, due on 09/15 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a02&#34;&gt;&lt;/a&gt; &lt;del&gt;A02: Image Retrieval, &lt;a href=&#34;#ref78910&#34;&gt;[8, 9, 10]&lt;/a&gt;, due on 09/20 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a03&#34;&gt;&lt;/a&gt; &lt;del&gt;A03: Image Classification, &lt;a href=&#34;#ref1112131415&#34;&gt;[11, 12, 13, 14, 15]&lt;/a&gt;, due on 09/27 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a04&#34;&gt;&lt;/a&gt; &lt;del&gt;A04: Object Detection, &lt;a href=&#34;#ref1617181920&#34;&gt;[16, 17, 18, 19, 20]&lt;/a&gt;, due on 10/04 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a05&#34;&gt;&lt;/a&gt; &lt;del&gt;A05: Image Segmentation, &lt;a href=&#34;#ref2122232425&#34;&gt;[21, 22, 23, 24, 25]&lt;/a&gt;, due on 10/18 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a06&#34;&gt;&lt;/a&gt; &lt;del&gt;A06: Face Detection, &lt;a href=&#34;#ref26272829&#34;&gt;[26, 27, 28, 29]&lt;/a&gt;, due on 10/25 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a07&#34;&gt;&lt;/a&gt; &lt;del&gt;A07: Face Recognition, &lt;a href=&#34;#ref3031323334&#34;&gt;[30, 31, 32, 33, 34]&lt;/a&gt;, due on 11/01 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a08&#34;&gt;&lt;/a&gt; &lt;del&gt;A08: Generative Adversarial Nets, &lt;a href=&#34;#ref3536373839&#34;&gt;[35, 36, 37, 38, 39]&lt;/a&gt;, due on 11/08 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a09&#34;&gt;&lt;/a&gt; &lt;del&gt;A09: Attacks and Sensitive Video Analysis, &lt;a href=&#34;#ref404142&#34;&gt;[40, 41, 42, 43, 44]&lt;/a&gt;, due on 11/16 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a name=&#34;a10&#34;&gt;&lt;/a&gt; &lt;del&gt;A10: Provenance Analysis, &lt;a href=&#34;#ref4546474849&#34;&gt;[46, 47, 48, 49]&lt;/a&gt;, due on 11/29 at noon.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Students will have to do at most eight assignments.
Each assignment will comprise a particular set of scientific articles.
Students will have to choose one of the articles for each assignment and provide a summary on the due date.
There is no limit of pages for the summaries.
Each summary should contain:&lt;br&gt;
(1) &lt;strong&gt;What&lt;/strong&gt; is the problem addressed in the article?&lt;br&gt;
(2) &lt;strong&gt;Why&lt;/strong&gt; is it important to address this problem?&lt;br&gt;
(3) &lt;strong&gt;How&lt;/strong&gt; do the authors address the problem?&lt;br&gt;
(4) What are the authors&amp;rsquo; &lt;strong&gt;claims&lt;/strong&gt;?&lt;br&gt;
(5) What &lt;strong&gt;methodology&lt;/strong&gt; did they adopt (e.g., datasets, problem metrics, experiments) to prove their claims?&lt;br&gt;
(6) Do you agree with the authors&amp;rsquo; claims?&lt;br&gt;
(7) For the graduate students, how do you think you may use this work in your research?&lt;br&gt;
(8) What open questions do you have about the article?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;discussion-leaders&#34;&gt;Discussion Leaders&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;Image Retrieval, Nick and Jesus, on 09/26.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Image Classification, Nick and Kenneth, on 10/03.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Object Detection, John and Kenneth, on 10/17.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Image Segmentation, Mujtaba and Matt, on 10/24.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Face Detection, John and Amol, on 10/31.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Face Recognition, Mujtaba and Amol, on 11/07.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Generative Adversarial Networks, Jakob and Matt, on 11/14.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;Provenance Analysis, Jakob and Jesus, on 12/05.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Each student will play the role of &lt;em&gt;discussion leader&lt;/em&gt; twice along the course.
Students will lead discussion in groups, preferably in pairs of one graduate and one undergraduate student.
The graduate students are expected to help their undergraduate peers.&lt;/p&gt;
&lt;p&gt;Discussion leaders will be responsible for organizing a 1.5-hour presentation of the topic of the day,
resorting to slides, videos, and demonstrations.
The instructor advises the discussion leaders to share their material with him
a couple of days before the presentation day.&lt;br&gt;
Discussion leaders will also receive the summaries of the articles and open questions related to their topics
from the other students at least 5 days before their presentation.&lt;/p&gt;
&lt;p&gt;The discussion and assignment topics coincide; as a consequence, discussion leaders are not required to
provide summaries for the topics they will present.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;final-exam&#34;&gt;Final Exam&lt;/h2&gt;
&lt;p&gt;Date and Local: 12/12, 4:15 PM, 117 Cuneo Hall&lt;br&gt;
Format: Oral quiz, questions &lt;a href=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/material/final_exam.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;grading&#34;&gt;Grading&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point Interval&lt;/th&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point Interval&lt;/th&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point Interval&lt;/th&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point Interval&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;[94, 100)&lt;/td&gt;
&lt;td&gt;B+&lt;/td&gt;
&lt;td&gt;[88, 89]&lt;/td&gt;
&lt;td&gt;C+&lt;/td&gt;
&lt;td&gt;[78, 79]&lt;/td&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;[60, 69]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A-&lt;/td&gt;
&lt;td&gt;[90, 93]&lt;/td&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;[84, 87]&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;[74, 77]&lt;/td&gt;
&lt;td&gt;F&lt;/td&gt;
&lt;td&gt;[0, 59]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;B-&lt;/td&gt;
&lt;td&gt;[80, 83]&lt;/td&gt;
&lt;td&gt;C-&lt;/td&gt;
&lt;td&gt;[70, 73]&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;distribution&#34;&gt;Distribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Total&lt;/strong&gt;: 100 points&lt;/li&gt;
&lt;li&gt;Class Presence and Participation: 6 points (x13)&lt;/li&gt;
&lt;li&gt;Assignments: 1 point (x8)&lt;/li&gt;
&lt;li&gt;Discussion Leadership: 3 points (x2)&lt;/li&gt;
&lt;li&gt;Final Exam: 8 points&lt;/li&gt;
&lt;li&gt;&lt;em&gt;CV-on-the-news&lt;/em&gt; Post: 1 point (extra)&lt;/li&gt;
&lt;li&gt;Demonstration on Discussion Day: 5 points (extra)&lt;/li&gt;
&lt;li&gt;Late Assignments: -0.1 point per day&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Grading.&#34; srcset=&#34;
               /teaching/cvapp-aut22/grading_hu3a9cdd06fb4f6267548ce78325163976_526278_92026d99672eb47ccd334acf0a51fc6a.webp 400w,
               /teaching/cvapp-aut22/grading_hu3a9cdd06fb4f6267548ce78325163976_526278_b3811655f7faf03136557ce3593313b3.webp 760w,
               /teaching/cvapp-aut22/grading_hu3a9cdd06fb4f6267548ce78325163976_526278_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/grading_hu3a9cdd06fb4f6267548ce78325163976_526278_92026d99672eb47ccd334acf0a51fc6a.webp&#34;
               width=&#34;760&#34;
               height=&#34;236&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Each student has two &lt;em&gt;&amp;ldquo;Oopsie&amp;rdquo;&lt;/em&gt; cards (OC), which will allow them to either avoid losing points because of absence
or extend due dates until 12/11.
They may use an OC at their discretion for any task, except for their assigned days of discussion leadership
and final exam.
Please let the instructor know you want to use your OC.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Oopsie card.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/cvapp-aut22/card.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;cv-on-the-news&#34;&gt;CV On the News&lt;/h2&gt;
&lt;p&gt;Posted by the students on Sakai.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://bit.ly/3HebdsS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3HebdsS&lt;/a&gt; (Matt&amp;rsquo;s submission).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://intel.ly/3B2o5hS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://intel.ly/3B2o5hS&lt;/a&gt; (Jakob&amp;rsquo;s).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://yhoo.it/3Fl3sjx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://yhoo.it/3Fl3sjx&lt;/a&gt; (Nick&amp;rsquo;s).&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;google-colab&#34;&gt;Google Colab&lt;/h2&gt;
&lt;p&gt;Practical material used in class.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Harris&amp;rsquo; corner detector (&lt;a href=&#34;https://bit.ly/3gRv0E2%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3gRv0E2)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;SIFT detector (&lt;a href=&#34;https://bit.ly/3gXsZWL%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3gXsZWL)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;SURF detector (&lt;a href=&#34;https://bit.ly/3B7dNxg%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3B7dNxg)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Face recognition (&lt;a href=&#34;https://bit.ly/3F4D5NM%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3F4D5NM)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;FGSM (&lt;a href=&#34;https://bit.ly/3Fl4Oe7%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3Fl4Oe7)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Lippe&amp;rsquo;s FGSM (&lt;a href=&#34;https://bit.ly/3FmvbAD%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3FmvbAD)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Final Exam Raffler (&lt;a href=&#34;https://bit.ly/3BQEBBY%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3BQEBBY)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref123&#34;&gt;&lt;/a&gt; LeCun, Y., Bengio, Y., Hinton, G. &lt;em&gt;Deep learning&lt;/em&gt;.
Nature 521 (1), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hearst, M., Dumais, S., Osuna, E., Platt, J., Scholkopf, B. &lt;em&gt;Support vector machines&lt;/em&gt;.
IEEE Intelligent Systems and their Applications 13 (4), 1998.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ho, T. &lt;em&gt;The Random Subspace Method for Constructing Decision Forests&lt;/em&gt;.
IEEE Transactions on Pattern Analysis and Machine Intelligence 20 (8), 1998.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref456&#34;&gt;&lt;/a&gt; Lowe, D. &lt;em&gt;Distinctive Image Features from Scale-Invariant Keypoints&lt;/em&gt;.
Springer International Journal of Computer Vision 60 (2), 2004.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bay, H., Tuytelaars, T., Van Gool, L. &lt;em&gt;SURF: Speeded Up Robust Features&lt;/em&gt;.
Springer European Conference on Computer Vision (ECCV), 2006&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Noh, H., Araujo, A., Sim, J., Weyand, T., Han, B. &lt;em&gt;Large-Scale Image Retrieval with Attentive Deep Local Features&lt;/em&gt;.
IEEE International Conference on Computer Vision (ICCV), 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref78910&#34;&gt;&lt;/a&gt; Jegou, H., Douze, M., Johnson, J. &lt;em&gt;Faiss: A library for efficient similarity search&lt;/em&gt;.
Available at &lt;a href=&#34;https://bit.ly/3BiGYg9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3BiGYg9&lt;/a&gt;. Meta Platforms, Inc., 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Brogan, J., Bharati, A., Moreira, D., Rocha, A., Bowyer, K., Flynn, P., Scheirer, W.
&lt;em&gt;Fast Local Spatial Verification for Feature-Agnostic Large-Scale Image Retrieval&lt;/em&gt;.
IEEE Transactions on Image Processing 30 (1), 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Kalantidis, Y., Avrithis, Y. &lt;em&gt;Locally Optimized Product Quantization for Approximate Nearest Neighbor Search&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Jegou, H., Douze, M., Schmid, C. &lt;em&gt;Product quantization for nearest neighbor search&lt;/em&gt;.
IEEE Transactions on Pattern Analysis and Machine Intelligence 33 (1), 2010.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref1112131415&#34;&gt;&lt;/a&gt; Howard, A., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H.
&lt;em&gt;Mobilenets: Efficient convolutional neural networks for mobile vision applications&lt;/em&gt;.
ArXiv Preprint, 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Krizhevsky, A., Sutskever, I., Hinton, G. &lt;em&gt;Imagenet classification with deep convolutional neural networks&lt;/em&gt;.
ACM Communications 60 (6), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;He, K., Zhang, X., Ren, S., Sun, J. &lt;em&gt;Deep residual learning for image recognition&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.
&lt;em&gt;Going deeper with convolutions&lt;/em&gt;. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simonyan, K., Zisserman, A.
&lt;em&gt;Very deep convolutional networks for large-scale image recognition&lt;/em&gt;.
International Conference on Learning Representations (ICLR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref1617181920&#34;&gt;&lt;/a&gt; Lin, T-Y., Goyal, P., Girshick, R., He, K., Dollar, P. &lt;em&gt;Focal loss for dense object detection&lt;/em&gt;.
IEEE International Conference on Computer Vision (ICCV), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Redmon, J., Divvala, S., Girshick, R., and Farhadi, A. &lt;em&gt;You only look once: Unified, real-time object detection&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ren, S., He, K., Girshick, R., Sun, J.
&lt;em&gt;Faster R-CNN: Towards real-time object detection with region proposal networks&lt;/em&gt;.
Advances in Neural Information Processing Systems 28 (1), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Girshick, R. &lt;em&gt;Fast R-CNN&lt;/em&gt;. IEEE International Conference on Computer Vision (ICCV), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Girshick, R., Donahue, J., Darrell, T., Malik, J.
&lt;em&gt;Rich feature hierarchies for accurate object detection and semantic segmentation&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref2122232425&#34;&gt;&lt;/a&gt; Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., Fu, Y., Feng, J., Xiang, T., Torr, P., Zhang, L.
&lt;em&gt;Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;He, K., Gkioxari, G., Dollar, P., Girshick, R. &lt;em&gt;Mask R-CNN&lt;/em&gt;.
IEEE International Conference on Computer Vision (ICCV), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Badrinarayanan, V., Kendall, A., Cipolla, R.
&lt;em&gt;SegNet: A deep convolutional encoder-decoder architecture for image segmentation&lt;/em&gt;.
IEEE Transactions on Pattern Analysis and Machine Intelligence 39 (12), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Long, J., Shelhamer, E., Darrell, T.
&lt;em&gt;Fully convolutional networks for semantic segmentation&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ronneberger, O., Fischer, P., Brox, T.
&lt;em&gt;U-net: Convolutional networks for biomedical image segmentation&lt;/em&gt;.
Springer International Conference on Medical Image Computing and Computer-assisted Intervention (MICCAI), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref26272829&#34;&gt;&lt;/a&gt; Viola, P., Jones, M. &lt;em&gt;Robust real-time face detection&lt;/em&gt;.
Springer International Journal of Computer Vision 57 (2), 2004.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Li, H., Lin, Z., Shen, X., Brandt, J., Hua, G. &lt;em&gt;A convolutional neural network cascade for face detection&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Xu, X., Kakadiaris, I.
&lt;em&gt;Joint head pose estimation and face alignment framework using global and local CNN features&lt;/em&gt;.
IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Albiero, V., Chen, X., Yin, X., Pang, G., Hassner, T.
&lt;em&gt;img2pose: Face alignment and detection via 6dof, face pose estimation&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref3031323334&#34;&gt;&lt;/a&gt; Parkhi, O., Vedaldi, A., Zisserman, A. &lt;em&gt;Deep face recognition&lt;/em&gt;.
British Machine Vision Conference (BMVC), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Schroff, F., Kalenichenko, D., Philbin, J.
&lt;em&gt;Facenet: A unified embedding for face recognition and clustering&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wen, Y., Zhang, K., Li, Z., Qiao, Y.
&lt;em&gt;A discriminative feature learning approach for deep face recognition&lt;/em&gt;.
Springer European Conference on Computer Vision (ECCV), 2016.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Liu, W., Wen, Y., Yu, Z., Li, M., Raj, B., Song, L.
&lt;em&gt;Sphereface: Deep hypersphere embedding for face recognition&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deng, J., Guo, J., Xue, N., Zafeiriou, S.
&lt;em&gt;Arcface: Additive angular margin loss for deep face recognition&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref3536373839&#34;&gt;&lt;/a&gt; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.
&lt;em&gt;Generative adversarial nets&lt;/em&gt;. ArXiv preprint (&lt;a href=&#34;https://bit.ly/3OXpCvn%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3OXpCvn)&lt;/a&gt;, 2014.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mirza, M., Osindero, S. &lt;em&gt;Conditional generative adversarial nets&lt;/em&gt;.
ArXiv preprint (&lt;a href=&#34;https://bit.ly/3OZwM2j%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3OZwM2j)&lt;/a&gt;, 2014.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Isola, P., Zhu, J., Zhou, T., Efros, A. &lt;em&gt;Image-to-image translation with conditional adversarial networks&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Zhu, J., Park, T., Isola, P., Efros, A.
&lt;em&gt;Unpaired image-to-image translation using cycle-consistent adversarial networks&lt;/em&gt;.
IEEE International Conference on Computer Vision (ICCV), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Karras, T., Laine, S., Aila, T. &lt;em&gt;A style-based generator architecture for generative adversarial networks&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref404142&#34;&gt;&lt;/a&gt; Goodfellow, I., Shlens, J., Szegedy, C. &lt;em&gt;Explaining and harnessing adversarial examples&lt;/em&gt;.
International Conference on Learning Representations (ICLR), 2015.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bai, T., Zhao, J., Zhu, J., Han, S., Chen, J., Li, B., Kot, A.
&lt;em&gt;AI-gan: Attack-inspired generation of adversarial examples&lt;/em&gt;.
IEEE International Conference on Image Processing (ICIP), 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wang, S., Wang, O., Zhang, R., Owens, A., Efros, A.
&lt;em&gt;CNN-generated images are surprisingly easy to spot&amp;hellip; for now&lt;/em&gt;.
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref4344&#34;&gt;&lt;/a&gt; Perez, M., Avila, S., Moreira, D., Moraes, D., Testoni, V., Valle, E., Goldenstein, S., Rocha, A.
&lt;em&gt;Video pornography detection through deep learning techniques and motion information&lt;/em&gt;.
Elsevier Neurocomputing 230 (1), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Moreira, D., Avila, S., Perez, M., Moraes, D., Testoni, V., Valle, E., Goldenstein, S., Rocha, A.
&lt;em&gt;Temporal robust features for violence detection&lt;/em&gt;.
IEEE Winter Conference on Applications of Computer Vision (WACV), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a name=&#34;ref4546474849&#34;&gt;&lt;/a&gt; Moreira, D., Theisen, W., Scheirer, W., Bharati, A., Brogan, J., Rocha, A. &lt;em&gt;Image Provenance Analysis&lt;/em&gt;.
Springer Multimedia Forensics (Book), 2022.
Available at &lt;a href=&#34;https://bit.ly/3ESzK5q&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3ESzK5q&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pinto, A., Moreira, D., Bharati, A., Brogan, J., Bowyer, K., Flynn, P., Scheirer, W., Rocha, A.
&lt;em&gt;Provenance filtering for multimedia phylogeny&lt;/em&gt;. IEEE International Conference on Image Processing (ICIP), 2017.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Moreira, D., Bharati, A., Brogan, J., Pinto, A., Parowski, M., Bowyer, K., Flynn, P., Rocha, A., Scheirer, W.
&lt;em&gt;Image provenance analysis at scale&lt;/em&gt;. IEEE Transactions on Image Processing 27 (12), 2018.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bharati, A., Moreira, D., Brogan, J., Hale, P., Bowyer, K., Flynn, P., Rocha, A., Scheirer, W.
&lt;em&gt;Beyond pixels: Image provenance analysis leveraging metadata&lt;/em&gt;.
IEEE Winter Conference on Applications of Computer Vision (WACV), 2019.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bharati, A., Moreira, D., Flynn, P., Rocha, A., Bowyer, K., Scheirer, W.
&lt;em&gt;Transformation-aware embeddings for image provenance&lt;/em&gt;.
IEEE Transactions on Information Forensics and Security 16 (1), 2021.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;academic-integrity&#34;&gt;Academic Integrity&lt;/h2&gt;
&lt;p&gt;Students are expected to adhere to the LUC statements on academic integrity available at &lt;a href=&#34;https://bit.ly/3TmiQkQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3TmiQkQ&lt;/a&gt;.
These policies fully apply to this course.
The penalty for task-wise academic misconduct is zero points.
Multiple events of misconduct will incur in failing the entire course (with an F grade).
All cases of academic misconduct will be reported to the proper department offices.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;accommodations&#34;&gt;Accommodations&lt;/h2&gt;
&lt;p&gt;Students who have disabilities and wish to request academic accommodations are advised to contact the
&lt;em&gt;Services for Students With Disabilities&lt;/em&gt; (SSWD) office at 773-508-3700 or &lt;a href=&#34;mailto:SSWD@luc.edu&#34;&gt;SSWD@luc.edu&lt;/a&gt; as soon as possible.
The SSWD office will provide accommodation letters that, once shared with the instructor, will be fully accommodated
as per the terms of their content with no further questions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning the Shell, Fall 2022</title>
      <link>https://danielmoreira.github.io/teaching/comptool-aut22/</link>
      <pubDate>Sun, 28 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/comptool-aut22/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/comptool-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp 400w,
               /teaching/comptool-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_e51b41172736727dd7a34ff04a09a9a2.webp 760w,
               /teaching/comptool-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/comptool-aut22/luc_hu9eb1c109e0914ceadff222ece6a1d872_7759_2ae554ab12a8e6233cd3bf1480fc4a45.webp&#34;
               width=&#34;250px&#34;
               height=&#34;116&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: COMP 141-001 / COMP 400D-001 Intro to Computing Tools and Techniques&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dmoreira1@luc.edu&#34;&gt;dmoreira1@luc.edu&lt;/a&gt;)&lt;br&gt;
Teaching Assistant: Olga Velichko (&lt;a href=&#34;mailto:ovelichko@luc.edu&#34;&gt;ovelichko@luc.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: Asynchronous and fully remote on &lt;a href=&#34;https://sakai.luc.edu/x/QxXrXd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt;&lt;br&gt;
Office Hours: WED, 5 to 8 PM, and FRI, 4 to 5 PM, &lt;a href=&#34;https://bit.ly/3BDuEID&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by appointment&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Grades are now &lt;a href=&#34;https://danielmoreira.github.io/teaching/comptool-aut22/grades.pdf&#34;&gt;available&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Shell terminal.&#34;
           src=&#34;https://danielmoreira.github.io/teaching/comptool-aut22/terminal.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Despite the current era of rich graphical user interfaces (desktop, web, and mobile), the &amp;ldquo;command line&amp;rdquo; experience
remains important, especially for software developers and computer-aided scientific researchers.
Many development scenarios still require command line and fluency in Unix tools, including the modern embedded,
cloud, cybersecurity, and supercomputing environments. With mobile computing and Internet of Things, Unix (via Linux)
has risen to the level of a ubiquitous platform, owing to its lightweight and open-source nature.
While this course does not aim at being a comprehensive programming class, students will master basic programming
skills using shell scripting.
They will also learn about problem-solving using Unix commands supported by shell scripts.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Please refer to &lt;a href=&#34;https://sakai.luc.edu/x/QxXrXd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sakai&lt;/a&gt; for having access to the materials, assignments, quizzes,
announcements, grading, and progress of the course. This page is static and will not be updated.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;help-with-homework-7&#34;&gt;Help with Homework #7&lt;/h2&gt;
&lt;p&gt;Hints were given &lt;a href=&#34;https://danielmoreira.github.io/post/comp141/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;team&#34;&gt;Team&lt;/h2&gt;
&lt;p&gt;This course is offered in multiple sessions with the following leading and contributing LUC instructors (Fall 2022):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;John O&amp;rsquo;Sullivan&lt;/li&gt;
&lt;li&gt;Nathan Hishon&lt;/li&gt;
&lt;li&gt;Allan Miller&lt;/li&gt;
&lt;li&gt;David Wetzel&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shots, W. &lt;em&gt;The Linux Command Line, 2nd Edition&lt;/em&gt;. No Starch Press Book, 2019. Available at &lt;a href=&#34;https://linuxcommand.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://linuxcommand.org/&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Forensic Analysis of Synthetically Generated Western Blot Images</title>
      <link>https://danielmoreira.github.io/publication/2022_ieeeaccess/</link>
      <pubDate>Mon, 30 May 2022 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2022_ieeeaccess/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image Provenance Analysis</title>
      <link>https://danielmoreira.github.io/publication/2022_chapter/</link>
      <pubDate>Sat, 02 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2022_chapter/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Biometrics, Spring 2022</title>
      <link>https://danielmoreira.github.io/teaching/biometrics-spr22/</link>
      <pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/biometrics-spr22/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/biometrics-spr22/nd_hud2e645e058d5066bddd46eafc5baca2c_58116_24dd1c36b7a34ebfe9b9e2952867b278.webp 400w,
               /teaching/biometrics-spr22/nd_hud2e645e058d5066bddd46eafc5baca2c_58116_c7771669807438d62685d1c21c995ac4.webp 760w,
               /teaching/biometrics-spr22/nd_hud2e645e058d5066bddd46eafc5baca2c_58116_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/nd_hud2e645e058d5066bddd46eafc5baca2c_58116_24dd1c36b7a34ebfe9b9e2952867b278.webp&#34;
               width=&#34;250px&#34;
               height=&#34;197&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: CSE 40537 / 60537 Biometrics&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dhenriq1@nd.edu&#34;&gt;dhenriq1@nd.edu&lt;/a&gt;)&lt;br&gt;
Teaching Assistant: Jason You (&lt;a href=&#34;mailto:syou@nd.edu&#34;&gt;syou@nd.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Lectures: TUE and THR, 3:30 to 4:45 PM, 356A Fitzpatrick Hall&lt;br&gt;
Office Hours: Daniel - MON to FRI, 5:00 to 6:00 PM, 182 Fitzpatrick Hall, Jason - WED, 1:00 to 2:00 PM, 150M Fitzpatrick Hall&lt;/p&gt;
&lt;p&gt;&lt;del&gt;Slack: &lt;a href=&#34;https://nd-biometrics-spr22.slack.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://nd-biometrics-spr22.slack.com&lt;/a&gt;&lt;/del&gt; &lt;em&gt;(now deactivated)&lt;/em&gt;&lt;br&gt;
Panopto: &lt;a href=&#34;https://bit.ly/3A4QEKc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/3A4QEKc&lt;/a&gt;&lt;/p&gt;
&lt;!--- Zoom: https://bit.ly/3JS9zMA/ --&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Different attacks made by students.&#34; srcset=&#34;
               /teaching/biometrics-spr22/fake_hu832e1f5d9d218979753d086994377cb1_4211911_39320c73b5c8f597cfbe7689a49de125.webp 400w,
               /teaching/biometrics-spr22/fake_hu832e1f5d9d218979753d086994377cb1_4211911_e869c853dca9cbd8838e7c769b6b97b2.webp 760w,
               /teaching/biometrics-spr22/fake_hu832e1f5d9d218979753d086994377cb1_4211911_1200x1200_fit_q90_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/fake_hu832e1f5d9d218979753d086994377cb1_4211911_39320c73b5c8f597cfbe7689a49de125.webp&#34;
               width=&#34;760&#34;
               height=&#34;367&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Course grades are now &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/total_grades.pdf&#34;&gt;available&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;progress&#34;&gt;Progress&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;01/11/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_00.pdf&#34;&gt;Syllabus&lt;/a&gt;, Course details.&lt;/li&gt;
&lt;li&gt;01/13/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_01.pdf&#34;&gt;Basics I&lt;/a&gt;, Biometrics, traits, and systems.&lt;/li&gt;
&lt;li&gt;01/18/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_02.pdf&#34;&gt;Basics II&lt;/a&gt;, Errors, metrics, and attacks.&lt;/li&gt;
&lt;li&gt;01/20/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_03.pdf&#34;&gt;Basics II (cont.)&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_03.zip&#34;&gt;1st Coding Class&lt;/a&gt;, Metrics.&lt;/li&gt;
&lt;li&gt;01/25/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_04.pdf&#34;&gt;Fingerprint Recog. I&lt;/a&gt;, History and features.&lt;/li&gt;
&lt;li&gt;01/27/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_05.pdf&#34;&gt;Fingerprint Recog. II&lt;/a&gt;, Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;02/01/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_06.pdf&#34;&gt;Fingerprint Recog. III&lt;/a&gt;, Minutiae detection.&lt;/li&gt;
&lt;li&gt;02/03/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_07.zip&#34;&gt;Fingerprint Data Collection&lt;/a&gt;, password with instructor.&lt;/li&gt;
&lt;li&gt;02/08/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_08.pdf&#34;&gt;Iris Recog. I&lt;/a&gt;, Why irises and irises vs. other traits.&lt;/li&gt;
&lt;li&gt;02/10/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_09.pdf&#34;&gt;Iris Recog. II&lt;/a&gt;, Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;02/15/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_10.pdf&#34;&gt;Iris Recog. III&lt;/a&gt;, Description and matching.&lt;/li&gt;
&lt;li&gt;02/17/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_11.zip&#34;&gt;2nd Coding Class&lt;/a&gt;, Fingerprint recognition.&lt;/li&gt;
&lt;li&gt;02/22/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_12.zip&#34;&gt;Iris Data Collection&lt;/a&gt;, password with instructor.&lt;/li&gt;
&lt;li&gt;02/24/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_13.zip&#34;&gt;3rd Coding Class&lt;/a&gt;, Iris recognition.&lt;/li&gt;
&lt;li&gt;03/01/2022 - &lt;a href=&#34;#kuehlkamp&#34;&gt;1st Invited Talk,&lt;/a&gt; Dr. Andrey Kuehlkamp.&lt;/li&gt;
&lt;li&gt;03/03/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/midterm.pdf&#34;&gt;Midterm exam&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/midterm_grades.pdf&#34;&gt;grades&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;03/08/2022 - Spring Break.&lt;/li&gt;
&lt;li&gt;03/10/2022 - Spring Break.&lt;/li&gt;
&lt;li&gt;03/15/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_14.pdf&#34;&gt;Face Recog. I&lt;/a&gt;, Why faces and faces vs. other traits.&lt;/li&gt;
&lt;li&gt;03/17/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_15.pdf&#34;&gt;Face Recog. II&lt;/a&gt;, Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;03/22/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_16.pdf&#34;&gt;Face Recog. III&lt;/a&gt;, Description and matching.&lt;/li&gt;
&lt;li&gt;03/24/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_17.pdf&#34;&gt;Face Recog. IV&lt;/a&gt;, Deep learning face recognition.&lt;/li&gt;
&lt;li&gt;03/29/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_18.zip&#34;&gt;4th Coding Class&lt;/a&gt;, Face recognition.&lt;/li&gt;
&lt;li&gt;03/31/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_19.pdf&#34;&gt;Feature Indexing&lt;/a&gt;, Index building and feature querying.&lt;/li&gt;
&lt;li&gt;04/05/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_20.pdf&#34;&gt;Other Traits&lt;/a&gt;, Alternative traits and Soft Biometrics.&lt;/li&gt;
&lt;li&gt;04/07/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/lecture_21.pdf&#34;&gt;Multibiometrics&lt;/a&gt;, Data fusion.&lt;/li&gt;
&lt;li&gt;04/12/2022 - &lt;a href=&#34;#boyd&#34;&gt;2nd Invited Talk,&lt;/a&gt; Mr. Aidan Boyd.&lt;/li&gt;
&lt;li&gt;04/14/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/slides_fingerprint.pdf&#34;&gt;Fingerprint&lt;/a&gt; presentation attack day.&lt;/li&gt;
&lt;li&gt;04/19/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/slides_iris.pdf&#34;&gt;Iris&lt;/a&gt; and &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/slides_face.pdf&#34;&gt;face&lt;/a&gt; presentation attack day.&lt;/li&gt;
&lt;li&gt;04/21/2022 - Grad students&amp;rsquo; &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/slides_signature.pdf&#34;&gt;signature recog.&lt;/a&gt; and &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/slides_gfi.pdf&#34;&gt;gender from iris&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;05/05/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/final.pdf&#34;&gt;Final exam&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/final_grades.pdf&#34;&gt;grades&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;!--- bdgX4&amp;A?q];8?Up7 --&gt;
&lt;hr&gt;
&lt;h2 id=&#34;assignments&#34;&gt;Assignments&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;01/20/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_1.pdf&#34;&gt;1st assignment&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_1_answers.pdf&#34;&gt;good answers&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_1_grades.pdf&#34;&gt;grades&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;02/22/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_2.pdf&#34;&gt;2nd assignment&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_2_answers.pdf&#34;&gt;good answers&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_2_grades.pdf&#34;&gt;grades&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;03/15/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_3.pdf&#34;&gt;3rd assignment&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_3_answers.pdf&#34;&gt;good answers&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_3_grades.pdf&#34;&gt;grades&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;04/04/2022 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_4.pdf&#34;&gt;4th assignment&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_4_answers.pdf&#34;&gt;good answers&lt;/a&gt;, &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/assig_4_grades.pdf&#34;&gt;grades&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;important-dates&#34;&gt;Important Dates&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;01/28/2022 - 1st assignment due date.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;02/03/2022 - Fingerprint data collection.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;02/22/2022 - Iris data collection.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;03/01/2022 - Dr. Andrey Kuehlkamp’s talk.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;03/03/2022 - Midterm exam.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;03/04/2022 - 2nd assignment due date.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;03/25/2022 - 3rd assignment due date.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/12/2022 - Mr. Aidan Boyd&amp;rsquo;s talk.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/14/2022 - Fingerprint presentation attack day.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/18/2022 - 4th assignment due date.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/19/2022 - Iris and face presentation attack day.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/21/2022 - Grad students&amp;rsquo; final report presentation.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;05/05/2022 - Final exam, 10:30 to 12:30 PM, 356A Fitzpatrick Hall.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a name=&#34;kuehlkamp&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;invited-talks&#34;&gt;Invited Talks&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Dr. Andrey Kuehlkamp&#34; srcset=&#34;
               /teaching/biometrics-spr22/kuehlkamp_hu0bcbd370411708a3ffbc5bfa3e480ebe_5020_f9e9a1d1fcbaf26c7bd2613a33337b27.webp 400w,
               /teaching/biometrics-spr22/kuehlkamp_hu0bcbd370411708a3ffbc5bfa3e480ebe_5020_e1180eff5c20c3de1d54f643fc937f98.webp 760w,
               /teaching/biometrics-spr22/kuehlkamp_hu0bcbd370411708a3ffbc5bfa3e480ebe_5020_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/kuehlkamp_hu0bcbd370411708a3ffbc5bfa3e480ebe_5020_f9e9a1d1fcbaf26c7bd2613a33337b27.webp&#34;
               width=&#34;100&#34;
               height=&#34;125&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://crc.nd.edu/about/people/andrey-kuehlkamp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Andrey Kuehlkamp&lt;/a&gt;&lt;/br&gt; Postdoctoral Research Associate at the Center for Research Computing, University of Notre Dame&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Diverse Aspects in Advancing Iris Recognition Systems&lt;/b&gt;&lt;/br&gt;&lt;/br&gt; Are we ready for widespread, mass-scale adoption of iris recognition systems? Following the miniaturization of fingerprint scanners, these have dominated recognition systems and have even become almost commonplace for unlocking cell phones, but what if in the not-so-far-off future they were replaced with iris scanners, would you be comfortable with it? Since its initial introduction in 1993, automated iris recognition has dramatically grown in popularity and soon could become the dominant method for automated recognition. Take for example the largest recognition system in the world &amp;mdash; India’s Aadhaar program &amp;mdash; which has collected more than 1.1 billion irises from their citizens to be used as the primary identification for banking, pensions, and welfare programs. Even more recently &amp;mdash; in 2017 &amp;mdash; Somaliland became the first country in the world to use iris recognition as the means for identification in a public election, which had more than 800,000 registered voters. Although a mature technology in many regards, the drastic increase in iris recognition adoption has revealed many opportunities for improvement. In this talk I present an overview of my research, which focuses on improving iris recognition in three ways: speed, accuracy, and robustness. &lt;a name=&#34;boyd&#34;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Mr. Aidan Boyd&#34; srcset=&#34;
               /teaching/biometrics-spr22/boyd_hu9c71555c2dab4f53bfd88f71a1ded5aa_5709_f03df5e802c2106863e858bb1310e481.webp 400w,
               /teaching/biometrics-spr22/boyd_hu9c71555c2dab4f53bfd88f71a1ded5aa_5709_4d28190796a719a302d50d07df8aa3bf.webp 760w,
               /teaching/biometrics-spr22/boyd_hu9c71555c2dab4f53bfd88f71a1ded5aa_5709_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/boyd_hu9c71555c2dab4f53bfd88f71a1ded5aa_5709_f03df5e802c2106863e858bb1310e481.webp&#34;
               width=&#34;100&#34;
               height=&#34;125&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/BoydAidan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mr. Aidan Boyd&lt;/a&gt;&lt;/br&gt; Ph.D. Candidate at the Department of Computer Science and Engineering, University of Notre Dame&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Using human perception to train better CNNs&lt;/b&gt;&lt;/br&gt;&lt;/br&gt; Traditional deep learning is a data-driven process. Images are shown to a CNN and it is expected to learn rules that enable it to perform a task efficiently on new unseen images after training. The problem with this approach is that the model can only learn from the supplied training data. Potentially, this training data is not representative of the entire domain. Although the model classifies training images near perfectly, this learned rule may actually just be coincidental to this data, rather than applying to all images in that task. Additionally, the decision making of these models can be ambiguous and not explainable, meaning it can be difficult to trust the classifications. Humans, however, possess great ability to generalize what they have seen in the past and apply it to the current task. Humans don’t focus on incidental features in data, instead we tend to look at more obvious occurrences that can be easily explained.&lt;/br&gt; &lt;/br&gt; This talk will cover two of my recent works where we investigated whether the incorporation of human perception into the training of deep learning models results in better performance on unseen data. Each of these works approach this in different ways, both showing promising results. In the second work, we also investigate whether the models we have trained in this way are more “human-like” in their decision making. These approaches are applied to the domains of iris presentation attack detection and synthetically generated face detection (see &lt;a href=&#34;https://www.thispersondoesnotexist.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.thispersondoesnotexist.com&lt;/a&gt; for examples of synthetically generated faces).&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;grading&#34;&gt;Grading&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point interval&lt;/th&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point interval&lt;/th&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point interval&lt;/th&gt;
&lt;th&gt;Concept&lt;/th&gt;
&lt;th&gt;Point interval&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;[94, 100)&lt;/td&gt;
&lt;td&gt;B+&lt;/td&gt;
&lt;td&gt;[88, 89]&lt;/td&gt;
&lt;td&gt;C+&lt;/td&gt;
&lt;td&gt;[78, 79]&lt;/td&gt;
&lt;td&gt;D&lt;/td&gt;
&lt;td&gt;[60, 69]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A-&lt;/td&gt;
&lt;td&gt;[90, 93]&lt;/td&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;[84, 87]&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;[74, 77]&lt;/td&gt;
&lt;td&gt;F&lt;/td&gt;
&lt;td&gt;[0, 59]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;B-&lt;/td&gt;
&lt;td&gt;[80, 83]&lt;/td&gt;
&lt;td&gt;C-&lt;/td&gt;
&lt;td&gt;[70, 73]&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;distribution&#34;&gt;Distribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Total&lt;/strong&gt;: 100 points&lt;/li&gt;
&lt;li&gt;Assignments: 10 points (x4)&lt;/li&gt;
&lt;li&gt;Presentation attack detection report: 20 points&lt;/li&gt;
&lt;li&gt;Midterm exam: 20 points&lt;/li&gt;
&lt;li&gt;Final exam: 20 points&lt;/li&gt;
&lt;li&gt;Late assignments: -1 point per day&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Final project &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/project_grades.pdf&#34;&gt;grades&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr22/panopto.pdf&#34;&gt;Classroom recording notification.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://vision.ucsd.edu/content/yale-face-database&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yale face dataset&lt;/a&gt;, used in the 4th assignment.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;biometrics-on-the-news&#34;&gt;Biometrics on the News&lt;/h2&gt;
&lt;p&gt;Posted by the students and instructor on Slack:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://fortune.com/2021/10/22/crypto-worldcoin-cryptocurrency-eye-scan-biometrics-orb/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://fortune.com/2021/10/22/crypto-worldcoin-cryptocurrency-eye-scan-biometrics-orb/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.biometricupdate.com/202201/attacks-countermeasures-and-pulses-of-blood-in-remote-identity-proofing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biometricupdate.com/202201/attacks-countermeasures-and-pulses-of-blood-in-remote-identity-proofing&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.yahoo.com/news/irs-wants-scan-face-171738919.html?.tsrc=fp_deeplink&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.yahoo.com/news/irs-wants-scan-face-171738919.html?.tsrc=fp_deeplink&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.irs.gov/newsroom/irs-announces-transition-away-from-use-of-third-party-verification-involving-facial-recognition&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.irs.gov/newsroom/irs-announces-transition-away-from-use-of-third-party-verification-involving-facial-recognition&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nytimes.com/2022/02/14/technology/texas-facebook-facial-recognition-lawsuit.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nytimes.com/2022/02/14/technology/texas-facebook-facial-recognition-lawsuit.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://abcnews.go.com/GMA/Living/video/hyper-realistic-face-masks-optical-illusions-needed-71835222&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://abcnews.go.com/GMA/Living/video/hyper-realistic-face-masks-optical-illusions-needed-71835222&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.newscientist.com/article/2114900-concerns-as-face-recognition-tech-used-to-identify-criminals/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.newscientist.com/article/2114900-concerns-as-face-recognition-tech-used-to-identify-criminals/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.yahoo.com/news/ukraine-using-facial-recognition-tech-153640828.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.yahoo.com/news/ukraine-using-facial-recognition-tech-153640828.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nytimes.com/2022/04/07/technology/facial-recognition-ukraine-clearview.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nytimes.com/2022/04/07/technology/facial-recognition-ukraine-clearview.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.washingtonpost.com/technology/2022/04/15/ukraine-facial-recognition-warfare/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.washingtonpost.com/technology/2022/04/15/ukraine-facial-recognition-warfare/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.biometricupdate.com/202204/biometrics-secure-unhcr-direct-cash-payments-to-ukrainian-refugees&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biometricupdate.com/202204/biometrics-secure-unhcr-direct-cash-payments-to-ukrainian-refugees&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.theverge.com/22672123/ai-voice-clone-synthesis-deepfake-applications-vergecast&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.theverge.com/22672123/ai-voice-clone-synthesis-deepfake-applications-vergecast&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.biometricupdate.com/202204/ny-state-audit-finds-bidding-for-school-facial-recognition-system-was-improper&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biometricupdate.com/202204/ny-state-audit-finds-bidding-for-school-facial-recognition-system-was-improper&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.biometricupdate.com/202204/suprema-face-biometrics-enable-uk-school-to-cut-back-plastic-waste-from-access-cards&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biometricupdate.com/202204/suprema-face-biometrics-enable-uk-school-to-cut-back-plastic-waste-from-access-cards&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://techcrunch.com/2022/04/18/web-scraping-legal-court/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://techcrunch.com/2022/04/18/web-scraping-legal-court/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Fast Local Spatial Verification for Feature-Agnostic Large-Scale Image Retrieval</title>
      <link>https://danielmoreira.github.io/publication/2021_tip/</link>
      <pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2021_tip/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sci-Int</title>
      <link>https://danielmoreira.github.io/project/sciint/</link>
      <pubDate>Fri, 04 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/project/sciint/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Ongoing, &lt;strong&gt;Funded by:&lt;/strong&gt; HHS&lt;br&gt;
&lt;strong&gt;Host:&lt;/strong&gt; &lt;a href=&#34;https://www.luc.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Loyola University Chicago&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Scientific Integrity (Sci-Int) project is an endeavor funded by the Department of Health and Human Services (HHS),
whose goal is to develop solutions to identify misconduct in scientific research through the detection of image tampering in scientific papers.&lt;/p&gt;
&lt;p&gt;Working together with the Universities of Purdue, Notre Dame, South California (USC), Campinas (Unicamp), Naples Federico II, and the Politécnico di Milano,
our team leads the development of Provenance Analysis to detect and explain how problematic images relate to each other, and how they share content across different papers.
Moreover, we also investigate the detection of synthetically generated scientific images, such as false gel blots.&lt;/p&gt;
&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Prof. Edward Delp (Lead PI)&lt;/li&gt;
&lt;li&gt;Prof. Daniel Moreira (PI)&lt;/li&gt;
&lt;li&gt;Prof. Walter Scheirer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Anderson Rocha (PI)&lt;/li&gt;
&lt;li&gt;João P. Cardenuto (PhD Student)&lt;/li&gt;
&lt;li&gt;Matt Hyatt (Undergraduate Student)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>SemaFor</title>
      <link>https://danielmoreira.github.io/project/semafor/</link>
      <pubDate>Thu, 03 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/project/semafor/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Ongoing, &lt;strong&gt;Funded by:&lt;/strong&gt; DARPA&lt;br&gt;
&lt;strong&gt;Host:&lt;/strong&gt; &lt;a href=&#34;https://www.nd.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;University of Notre Dame&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Semantic Forensics research project (&lt;a href=&#34;https://www.darpa.mil/program/semantic-forensics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SemaFor&lt;/a&gt;) is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA), whose goal is to leverage forensic tools to perform the &lt;strong&gt;detection&lt;/strong&gt; of the existence, &lt;strong&gt;atribution&lt;/strong&gt; of the authorship, and &lt;strong&gt;characterization&lt;/strong&gt; of the intention of manipulated digital media.&lt;/p&gt;
&lt;p&gt;Working together with the Universities of Purdue, Siena, Campinas (Unicamp), Naples Federico II, and the Politécnico di Milano, our team leads the development of solutions to the problem of digital document analysis (such as scientific papers, news articles, patents, grants, etc.).
By combining ideas from the topics of image retrieval, digital image forensics, natural language processing, and deep learning, we aim at proposing multimodal methods to spot semantic inconsistencies within the content of documents.&lt;/p&gt;
&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Prof. Walter Scheirer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Anderson Rocha (PI)&lt;/li&gt;
&lt;li&gt;Prof. Kevin Bowyer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Tim Weninger (PI)&lt;/li&gt;
&lt;li&gt;Prof. Daniel Moreira (PI)&lt;/li&gt;
&lt;li&gt;William Theisen (PhD Student)&lt;/li&gt;
&lt;li&gt;Trenton Ford (PhD Student)&lt;/li&gt;
&lt;li&gt;Rosaura VidalMata (PhD Student)&lt;/li&gt;
&lt;li&gt;Priscila Saboia (PhD Student)&lt;/li&gt;
&lt;li&gt;João P. Cardenuto (PhD Student)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Automatic Discovery of Political Meme Genres with Diverse Appearances</title>
      <link>https://danielmoreira.github.io/publication/2021_icwsm/</link>
      <pubDate>Sat, 22 May 2021 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2021_icwsm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Transformation-Aware Embeddings for Image Provenance</title>
      <link>https://danielmoreira.github.io/publication/2021_tifs/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2021_tifs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Biometrics, Spring 2020</title>
      <link>https://danielmoreira.github.io/teaching/biometrics-spr20/</link>
      <pubDate>Tue, 14 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/teaching/biometrics-spr20/</guid>
      <description>















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /teaching/biometrics-spr20/nd_hud2e645e058d5066bddd46eafc5baca2c_58116_24dd1c36b7a34ebfe9b9e2952867b278.webp 400w,
               /teaching/biometrics-spr20/nd_hud2e645e058d5066bddd46eafc5baca2c_58116_c7771669807438d62685d1c21c995ac4.webp 760w,
               /teaching/biometrics-spr20/nd_hud2e645e058d5066bddd46eafc5baca2c_58116_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/nd_hud2e645e058d5066bddd46eafc5baca2c_58116_24dd1c36b7a34ebfe9b9e2952867b278.webp&#34;
               width=&#34;250px&#34;
               height=&#34;197&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;hr&gt;
&lt;h2 id=&#34;details&#34;&gt;Details&lt;/h2&gt;
&lt;p&gt;Course: CSE 40537 / 60537 Biometrics&lt;br&gt;
Level: Undergraduate and Graduate&lt;br&gt;
Instructor: &lt;a href=&#34;https://danielmoreira.github.io/&#34;&gt;Daniel Moreira&lt;/a&gt; (&lt;a href=&#34;mailto:dhenriq1@nd.edu&#34;&gt;dhenriq1@nd.edu&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;del&gt;Lectures: TUE and THR, 5:05 to 6:20 PM, 125 DeBartolo Hall&lt;/del&gt;&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;br&gt;
&lt;del&gt;Office Hours: MON and WED, 2:00 to 4:00 PM, 150N Fitzpatrick Hall&lt;/del&gt;&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;br&gt;
Lectures: TUE and THR, 2:00 to 3:15 PM, at Zoom&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;br&gt;
Office Hours: TUE and THR, 5:05 to 6:20 PM, at Zoom&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;br&gt;
&lt;em&gt;Students are not obligated to attend classes at 2:00 pm, but are certainly welcome. All classes are being recorded with Panopto.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Slack: &lt;del&gt;&lt;a href=&#34;https://cse-biometrics-spr20.slack.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://cse-biometrics-spr20.slack.com&lt;/a&gt;&lt;/del&gt; &lt;em&gt;(now deactivated)&lt;/em&gt;&lt;br&gt;
Panopto: &lt;a href=&#34;https://bit.ly/33ZkU97&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bit.ly/33ZkU97&lt;/a&gt;&lt;br&gt;
Zoom: &lt;a href=&#34;https://notredame.zoom.us/my/dmoreira&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://notredame.zoom.us/my/dmoreira&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Course grades are now &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/grades.pdf&#34;&gt;available.&lt;/a&gt;&lt;/strong&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fake fingers made by students.&#34; srcset=&#34;
               /teaching/biometrics-spr20/fake-fingers_hu3624c59c52b8002a8b05756867852acc_28227_a04fb3525ef616e1dffb74ff1de692cd.webp 400w,
               /teaching/biometrics-spr20/fake-fingers_hu3624c59c52b8002a8b05756867852acc_28227_4fc760eb2705bed990f3196fb7ee1a47.webp 760w,
               /teaching/biometrics-spr20/fake-fingers_hu3624c59c52b8002a8b05756867852acc_28227_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/fake-fingers_hu3624c59c52b8002a8b05756867852acc_28227_a04fb3525ef616e1dffb74ff1de692cd.webp&#34;
               width=&#34;400&#34;
               height=&#34;400&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;progress&#34;&gt;Progress&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;01/14/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_00.pdf&#34;&gt;Syllabus,&lt;/a&gt; Course details.&lt;/li&gt;
&lt;li&gt;01/16/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_01.pdf&#34;&gt;Basics I,&lt;/a&gt; Biometrics, traits, and systems.&lt;/li&gt;
&lt;li&gt;01/21/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_02.pdf&#34;&gt;Basics II,&lt;/a&gt; Errors, metrics, and attacks.&lt;/li&gt;
&lt;li&gt;01/23/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_03.zip&#34;&gt;1st Coding Class,&lt;/a&gt; Implementation of metrics.&lt;/li&gt;
&lt;li&gt;01/28/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_04.pdf&#34;&gt;Fingerprint Recog. I,&lt;/a&gt; History and features.&lt;/li&gt;
&lt;li&gt;01/30/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_05.pdf&#34;&gt;Fingerprint Recog. II,&lt;/a&gt; Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;02/04/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_06.pdf&#34;&gt;Fingerprint Recog. III,&lt;/a&gt; Minutiae detection.&lt;/li&gt;
&lt;li&gt;02/06/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_07.zip&#34;&gt;Fingerprint Data Collection,&lt;/a&gt; password with instructor.&lt;/li&gt;
&lt;li&gt;02/11/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_08_09.zip&#34;&gt;2nd Coding Class,&lt;/a&gt; Minutiae-based recognition.&lt;/li&gt;
&lt;li&gt;02/13/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_08_09.zip&#34;&gt;2nd Coding Class,&lt;/a&gt; continuation.&lt;/li&gt;
&lt;li&gt;02/18/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_10.pdf&#34;&gt;Face Recog. I,&lt;/a&gt; Why faces and faces vs. fingerprints.&lt;/li&gt;
&lt;li&gt;02/20/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_11.pdf&#34;&gt;Face Recog. II,&lt;/a&gt; Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;02/25/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_12.pdf&#34;&gt;Face Recog. III,&lt;/a&gt; Description and matching.&lt;/li&gt;
&lt;li&gt;02/27/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_13.zip&#34;&gt;3rd Coding Class,&lt;/a&gt; Face recognition.&lt;/li&gt;
&lt;li&gt;03/03/2020 - Fingerprints assignment, &lt;em&gt;Developers&amp;rsquo; day&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;03/05/2020 - Fingerprints assignment, &lt;em&gt;Attackers&amp;rsquo; day&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;03/10/2020 - Spring Break.&lt;/li&gt;
&lt;li&gt;03/12/2020 - Spring Break.&lt;/li&gt;
&lt;li&gt;03/17/2020 - Extended Spring Break&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;li&gt;03/18/2020 - Extended Spring Break&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;li&gt;03/24/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_16.pdf&#34;&gt;New Course Directions&lt;sup&gt;1&lt;/sup&gt;.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;03/26/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_17.pdf&#34;&gt;Iris Recog. I,&lt;/a&gt; Why irises and irises vs. other traits.&lt;/li&gt;
&lt;li&gt;03/31/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_18.pdf&#34;&gt;Iris Recog. II,&lt;/a&gt; Acquisition and enhancement.&lt;/li&gt;
&lt;li&gt;04/02/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_19.pdf&#34;&gt;Iris Recog. III,&lt;/a&gt; Description and matching.&lt;/li&gt;
&lt;li&gt;04/07/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_20.zip&#34;&gt;4th Coding Class,&lt;/a&gt; Iris recognition.&lt;/li&gt;
&lt;li&gt;04/09/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/lecture_21.pdf&#34;&gt;Multibiometrics,&lt;/a&gt; Other traits, data fusion.&lt;/li&gt;
&lt;li&gt;04/14/2020 - &lt;a href=&#34;#kuehlkamp&#34;&gt;1st Invited Talk,&lt;/a&gt; Dr. Andrey Kuehlkamp.&lt;/li&gt;
&lt;li&gt;04/16/2020 - &lt;a href=&#34;#czajka&#34;&gt;2nd Invited Talk,&lt;/a&gt; Dr. Adam Czajka.&lt;/li&gt;
&lt;li&gt;04/21/2020 - Faces assignment, &lt;em&gt;Developers&amp;rsquo; day&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;04/23/2020 - Irises assignment, &lt;em&gt;Developers&amp;rsquo; day&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;04/28/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/assignment-grades.pdf&#34;&gt;Assignment Report&lt;/a&gt; due date.&lt;/li&gt;
&lt;li&gt;05/04/2020 - &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/exam.pdf&#34;&gt;Final exam,&lt;/a&gt; see &lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/exam-grades.pdf&#34;&gt;grades.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;important-dates&#34;&gt;Important Dates&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;03/03/2020 - Fingerprints assignment, &lt;em&gt;Developers&amp;rsquo; day&lt;/em&gt;.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;03/05/2020 - Fingerprints assignment, &lt;em&gt;Attackers&amp;rsquo; day&lt;/em&gt;.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;&lt;del&gt;03/31/2020 - Faces assignment, &lt;em&gt;Developers&amp;rsquo; day&lt;/em&gt;.&lt;/del&gt;&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;&lt;del&gt;04/02/2020 - Faces assignment, &lt;em&gt;Attackers&amp;rsquo; day&lt;/em&gt;.&lt;/del&gt;&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;&lt;del&gt;04/14/2020 - Irises assignment, &lt;em&gt;Developers&amp;rsquo; day&lt;/em&gt;.&lt;/del&gt;&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;&lt;del&gt;04/16/2020 - Irises assignment, &lt;em&gt;Attackers&amp;rsquo; day&lt;/em&gt;.&lt;/del&gt;&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span style=&#34;color:red&#34;&gt;&lt;del&gt;04/28/2020 - Last assignment, &lt;em&gt;Collaboration day&lt;/em&gt;.&lt;/del&gt;&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/14/2020 (5:05 PM at Zoom) - Dr. Andrey Kuehlkamp&amp;rsquo;s talk.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/16/2020 (5:05 PM at Zoom) - Dr. Adam Czajka&amp;rsquo;s talk.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/21/2020 - Faces assignment, &lt;em&gt;Developers&amp;rsquo; day&lt;/em&gt;&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/23/2020 - Irises assignment, &lt;em&gt;Developers&amp;rsquo; day&lt;/em&gt;&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;04/28/2020 - Final Report due date&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;.&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;05/04/2020 - Final exam.&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a name=&#34;kuehlkamp&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;invited-talks&#34;&gt;Invited Talks&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Dr. Andrey Kuehlkamp&#34; srcset=&#34;
               /teaching/biometrics-spr20/kuehlkamp_hu0bcbd370411708a3ffbc5bfa3e480ebe_5020_f9e9a1d1fcbaf26c7bd2613a33337b27.webp 400w,
               /teaching/biometrics-spr20/kuehlkamp_hu0bcbd370411708a3ffbc5bfa3e480ebe_5020_e1180eff5c20c3de1d54f643fc937f98.webp 760w,
               /teaching/biometrics-spr20/kuehlkamp_hu0bcbd370411708a3ffbc5bfa3e480ebe_5020_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/kuehlkamp_hu0bcbd370411708a3ffbc5bfa3e480ebe_5020_f9e9a1d1fcbaf26c7bd2613a33337b27.webp&#34;
               width=&#34;100&#34;
               height=&#34;125&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://crc.nd.edu/about/people/andrey-kuehlkamp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Andrey Kuehlkamp&lt;/a&gt;&lt;/br&gt; Postdoctoral Research Associate at the Center for Research Computing, University of Notre Dame&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Diverse Aspects in Advancing Iris Recognition Systems&lt;/b&gt;&lt;/br&gt;&lt;/br&gt; Are we ready for widespread, mass-scale adoption of iris recognition systems? Following the miniaturization of fingerprint scanners, these have dominated recognition systems and have even become almost commonplace for unlocking cell phones, but what if in the not-so-far-off future they were replaced with iris scanners, would you be comfortable with it? Since its initial introduction in 1993, automated iris recognition has dramatically grown in popularity and soon could become the dominant method for automated recognition. Take for example the largest recognition system in the world &amp;mdash; India’s Aadhaar program &amp;mdash; which has collected more than 1.1 billion irises from their citizens to be used as the primary identification for banking, pensions, and welfare programs. Even more recently &amp;mdash; November 2017 &amp;mdash; Somaliland became the first country in the world to use iris recognition as the means for identification in a public election, which had more than 800,000 registered voters. Although a mature technology in many regards, the drastic increase in iris recognition adoption has revealed many opportunities for improvement. In this talk I present an overview of my research, which focuses on improving iris recognition in three ways: speed, accuracy, and robustness. &lt;a name=&#34;czajka&#34;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Dr. Adam Czajka&#34; srcset=&#34;
               /teaching/biometrics-spr20/czajka_hub437e1922ab0268a7a76fb3927aa70c1_3815_ec37dd8a330dcf600f679ae8e0eb8abe.webp 400w,
               /teaching/biometrics-spr20/czajka_hub437e1922ab0268a7a76fb3927aa70c1_3815_8416ae5272b4c7de4f053a93f5cffbbc.webp 760w,
               /teaching/biometrics-spr20/czajka_hub437e1922ab0268a7a76fb3927aa70c1_3815_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/czajka_hub437e1922ab0268a7a76fb3927aa70c1_3815_ec37dd8a330dcf600f679ae8e0eb8abe.webp&#34;
               width=&#34;100&#34;
               height=&#34;125&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://engineering.nd.edu/profiles/aczajka&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Adam Czajka&lt;/a&gt;&lt;/br&gt; Assistant Professor at the Department of Computer Science and Engineering, University of Notre Dame&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Is this eye alive or artificial?&lt;/b&gt;&lt;/br&gt; &lt;i&gt;Oh wait, maybe it’s dead? Detection of unknown presentation attacks in biometrics.&lt;/i&gt;&lt;/br&gt;&lt;/br&gt; Presentation attacks are those physical presentations to a biometric system that aim at driving it into an incorrect decision. Rediscovered recently in general computer vision community (and raising a significant interest; look &amp;mdash; for instance &amp;mdash; for famous stop sign attacks on deep learning-based object detection models), these attacks are known in biometrics for several decades. In this talk, I will use iris recognition as an example and will present the huge creativity of attackers in using various artifacts (printouts, patterned contact lenses, plastic eyes, GAN-generated fakes and&amp;hellip; dead eyes) to spoof a system. Although training a model to recognize each of these presentation attack instruments is relatively easy and works well, a big challenge now is how to build models that generalize onto unknown attack types, going beyond our understanding of attackers’ creativity when training our models. I will present a few methods we are exploring in our research to provide presentation attack detection methods that perform promisingly in open-set classification scenario.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://danielmoreira.github.io/teaching/biometrics-spr20/panopto.pdf&#34;&gt;Classroom recording notification.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://vision.ucsd.edu/content/yale-face-database&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yale face dataset, &lt;/a&gt; used to replace face acquisition&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://biometrics.idealtest.org/dbDetailForUser.do?id=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CASIA-IrisV1, &lt;/a&gt; used to replace iris acquisition&lt;sup&gt;&lt;a href=&#34;#covid19&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;biometrics-on-the-news&#34;&gt;Biometrics on the News&lt;/h2&gt;
&lt;p&gt;Posted by the students the instructor on Slack:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://vancouversun.com/news/local-news/biometric-opioid-vending-machine-unveiled-in-vancouver&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://vancouversun.com/news/local-news/biometric-opioid-vending-machine-unveiled-in-vancouver&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.landmobile.co.uk/news/metropolitan-police-service-nec-live-facial-recognition/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.landmobile.co.uk/news/metropolitan-police-service-nec-live-facial-recognition/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nytimes.com/2020/01/20/opinion/facial-recognition-ban-privacy.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nytimes.com/2020/01/20/opinion/facial-recognition-ban-privacy.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.biometricupdate.com/202001/securiport-partners-with-university-of-notre-dame-in-biometrics-and-data-analytics-research-for-border-security&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biometricupdate.com/202001/securiport-partners-with-university-of-notre-dame-in-biometrics-and-data-analytics-research-for-border-security&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nytimes.com/2020/02/06/business/facial-recognition-schools.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nytimes.com/2020/02/06/business/facial-recognition-schools.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.abacusnews.com/tech/why-your-palm-could-be-safer-fingerprints-or-facial-recognition/article/3046162&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.abacusnews.com/tech/why-your-palm-could-be-safer-fingerprints-or-facial-recognition/article/3046162&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cnn.com/2020/02/26/tech/clearview-ai-hack/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.cnn.com/2020/02/26/tech/clearview-ai-hack/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://nakedsecurity.sophos.com/2020/04/08/as-if-the-world-couldnt-get-any-weirder-this-ai-toilet-scans-your-anus-to-identify-you/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://nakedsecurity.sophos.com/2020/04/08/as-if-the-world-couldnt-get-any-weirder-this-ai-toilet-scans-your-anus-to-identify-you/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arstechnica.com/information-technology/2020/04/attackers-can-bypass-fingerprint-authentication-with-an-80-success-rate/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arstechnica.com/information-technology/2020/04/attackers-can-bypass-fingerprint-authentication-with-an-80-success-rate/&lt;/a&gt;
&lt;a name=&#34;covid19&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;covid-19&#34;&gt;COVID-19&lt;/h2&gt;
&lt;p&gt;1: Modified/canceled due to &lt;a href=&#34;https://coronavirus.nd.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;COVID-19.&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;This course is heavily based on &lt;a href=&#34;https://engineering.nd.edu/profiles/aczajka&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Adam Czajka&amp;rsquo;s&lt;/a&gt; and &lt;a href=&#34;https://www.wjscheirer.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Walter Scheirer&amp;rsquo;s&lt;/a&gt; previous Biometrics courses. I sincerely thank them for kindly allowing me to rely upon their materials.&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>A Better Society</title>
      <link>https://danielmoreira.github.io/post/bettersoc/</link>
      <pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/post/bettersoc/</guid>
      <description>&lt;p&gt;One of the things I worry about while doing my research is how to drive it towards building a better society.
Although the concept of a &lt;em&gt;better society&lt;/em&gt; may differ from one culture to the other, I believe any society gets better whenever &lt;strong&gt;all&lt;/strong&gt; of its members experience more &lt;strong&gt;freedom&lt;/strong&gt; to enjoy their &lt;strong&gt;rights&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Among the untold manners technology can be used to breach people&amp;rsquo;s rights, five flaws in the way we are doing informatics get my attention.
Devices and programs usually suffer from (1) lack of &lt;strong&gt;safety&lt;/strong&gt;, (2) lack of &lt;strong&gt;trustworthiness&lt;/strong&gt;, (3) lack of &lt;strong&gt;privacy&lt;/strong&gt;, (4) ignorance of &lt;strong&gt;diversity&lt;/strong&gt;, and (5) lack of &lt;strong&gt;accountability&lt;/strong&gt;.
Not unintentionally, the &lt;a href=&#34;https://danielmoreira.github.io/#projects&#34;&gt;projects&lt;/a&gt; I&amp;rsquo;ve been contributing to in the past few years tackle one or more of these issues.&lt;/p&gt;
&lt;h2 id=&#34;safety&#34;&gt;Safety&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;a href=&#34;https://commons.wikimedia.org/wiki/File:Interest.jpg&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/bettersoc/safety_hu5c2b1449ce7cfaa94c29be8156bee6a5_11232_fbae809a6170f9b729999975a1475396.webp 400w,
               /post/bettersoc/safety_hu5c2b1449ce7cfaa94c29be8156bee6a5_11232_308a5d4494688f90a42c65dd4a5a983e.webp 760w,
               /post/bettersoc/safety_hu5c2b1449ce7cfaa94c29be8156bee6a5_11232_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/post/bettersoc/safety_hu5c2b1449ce7cfaa94c29be8156bee6a5_11232_fbae809a6170f9b729999975a1475396.webp&#34;
               width=&#34;300px&#34;
               height=&#34;224&#34;
               loading=&#34;lazy&#34; /&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;From the many ways safety can be harmed by technology, the improper dissemination of sensitive content (such as pornography or violence), to inadequate audiences (such as kids or unwary spectators), gained my attention while I was developing my PhD, under the supervision of prof. &lt;a href=&#34;https://www.ic.unicamp.br/~rocha/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anderson Rocha&lt;/a&gt; (who generously proposed the topic).&lt;/p&gt;
&lt;p&gt;With the popularity and pervasiveness of online video streams, sensitive scenes depicting &lt;a href=&#34;https://www.washingtonpost.com/news/the-intersect/wp/2017/01/15/a-12-year-old-girl-live-streamed-her-suicide-it-took-two-weeks-for-facebook-to-take-the-video-down/?utm_term=.ea8124e4a0e9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;suicide&lt;/a&gt;, &lt;a href=&#34;https://www.cnn.com/videos/us/2016/06/17/man-shot-killed-while-live-streaming-orig-vstan-dlewis.cnn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;murder&lt;/a&gt;, and even &lt;a href=&#34;https://www.nytimes.com/2016/04/19/us/periscope-rape-case-columbus-ohio-video-livestreaming.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rape&lt;/a&gt; have been broadcasted on the Internet, raising questions about the safety of these services.
Aware of this situation, &lt;a href=&#34;https://www.samsung.com/br/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Samsung&lt;/a&gt; has funded us to focus on the development of solutions to detect sensitive video.
Rather than aiming at denouncing or morally condemning the lawful consumers of certain types of sensitive content, our intent has always been to support the implementation of filtering and warning features that would make player systems safer (especially in the case of child spectators).&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve had the chance to tackle the lack of safety in video streaming systems through the &lt;a href=&#34;https://danielmoreira.github.io/project/sma/&#34;&gt;SMA&lt;/a&gt; project.&lt;/p&gt;
&lt;h2 id=&#34;trustworthiness&#34;&gt;Trustworthiness&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/bettersoc/trust_huc712311a1d7a57cd829d8a884be503f8_25148_c6c997cbfa676e89c3517303e2af96ef.webp 400w,
               /post/bettersoc/trust_huc712311a1d7a57cd829d8a884be503f8_25148_1a73b19b20e8e30e57956efe92ee6044.webp 760w,
               /post/bettersoc/trust_huc712311a1d7a57cd829d8a884be503f8_25148_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/post/bettersoc/trust_huc712311a1d7a57cd829d8a884be503f8_25148_c6c997cbfa676e89c3517303e2af96ef.webp&#34;
               width=&#34;300px&#34;
               height=&#34;333&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;In the era of misinformation and &lt;em&gt;fake news&lt;/em&gt;, there is a symptomatic undermining of trust not only in textual but also in visual information.
People are conscious of the existence of image editing software (e.g., &lt;em&gt;Photoshop&lt;/em&gt;), with which even unskilled users can easily fabricate and manipulate pictures.
Although many of these manipulations have benign purposes (no, there is nothing wrong with &lt;em&gt;your memes&lt;/em&gt;), some contents are generated with malicious intents, such as general public deception and propaganda.&lt;/p&gt;
&lt;p&gt;The lack of available solutions to assess the integrity of images and videos allows adversarial manipulated data to have a negative impact on the way people relate to each other on the Internet.
They don&amp;rsquo;t know what to believe or whom to trust anymore.
In addition, fraudulent images represent a challenge even for the &lt;a href=&#34;https://www.nature.com/articles/s41419-018-0430-3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scientific community&lt;/a&gt;.
Aware of this scenario, &lt;a href=&#34;https://www.darpa.mil/program/media-forensics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DARPA&lt;/a&gt; has been funding us, at &lt;a href=&#34;https://cvrl.nd.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CVRL&lt;/a&gt;, to conduct research on the development of tools to verify the integrity of digital images.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m having the chance to tackle the lack of trustworthiness in visual media systems through the &lt;a href=&#34;https://danielmoreira.github.io/project/medifor/&#34;&gt;MediFor&lt;/a&gt; and &lt;a href=&#34;https://danielmoreira.github.io/project/sciint/&#34;&gt;Sci-Int&lt;/a&gt; projects.&lt;/p&gt;
&lt;h2 id=&#34;privacy-and-diversity&#34;&gt;Privacy and Diversity&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://danielmoreira.github.io/post/bettersoc/privacy.gif&#34;
           loading=&#34;lazy&#34; data-zoomable width=&#34;300px&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;With the advent of deep learning and the necessity for large datasets, &lt;em&gt;visual data collection&lt;/em&gt; has become an important step of Computer Vision and Machine Learning research.
Due to the popularity of image and video capture devices (such as digital cameras, smartphones, dash cams, etc.), large datasets can now be quickly generated.
Nevertheless, a major question that stands out in such a process is how to protect the privacy of people who are eventually being recorded.
Imagine, for example, a dash cam that is collecting road data for a self-driving car project.
In a major city, plenty of people will certainly be captured in the footages, and it is very unlikely that one will be able to obtain image rights for each individual.&lt;/p&gt;
&lt;p&gt;Interested in such issue, we, at &lt;a href=&#34;https://cvrl.nd.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CVRL&lt;/a&gt;, investigate the generation of realistic synthetic faces, whose identities do not belong to a real existing person, hence avoiding privacy breaches.
The idea is to de-identify the recorded individuals, by replacing their faces with synthetic assets.&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;a href=&#34;https://www.youtube.com/watch?v=t4DT3tQqgRM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img alt=&#34;&#34;
           src=&#34;https://danielmoreira.github.io/post/bettersoc/diversity.gif&#34;
           loading=&#34;lazy&#34; width=&#34;300px&#34; /&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;In addition, collected data may be biased, due to a lack of diversity in the captured individuals.
Consider, for instance, training video footages collected in China.
It is very &lt;a href=&#34;https://www.nationalgeographic.com/travel/destinations/asia/china/black-tourist-china/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;unlikely&lt;/a&gt; that black people will be represented in such a dataset.&lt;/p&gt;
&lt;p&gt;Limitations of this nature comprise what I call &lt;em&gt;ignorance of diversity&lt;/em&gt; and are the potential cause of many &lt;a href=&#34;http://www.cnn.com/2009/TECH/12/22/hp.webcams/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;technological failures&lt;/a&gt; in the presence of underrepresented groups.
Unfortunately, glitches like these may go &lt;a href=&#34;https://www.forbes.com/sites/mzhang/2015/07/01/google-photos-tags-two-african-americans-as-gorillas-through-facial-recognition-software/#41ebc8e8713d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;beyond the technological aspects&lt;/a&gt; and prejudice the rights of equality in face of diversity.
To cope with this problem, similar to the privacy protection strategy, synthetic identities can be used to diversify the recorded individuals by performing face replacement, providing controlled variation of not only ethnicity but also of age and of gender.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m having the chance to tackle the lack of privacy and ignorance of diversity in image and video datasets through the &lt;a href=&#34;https://danielmoreira.github.io/project/srefv/&#34;&gt;SREFV&lt;/a&gt; project.&lt;/p&gt;
&lt;h2 id=&#34;accountability&#34;&gt;Accountability&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34;
           src=&#34;https://danielmoreira.github.io/post/bettersoc/acc.gif&#34;
           loading=&#34;lazy&#34; data-zoomable width=&#34;300px&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;People have the right to understand in details the decisions made about them by algorithms belonging to either government or industry.
This is fundamental to give them the possibility of questioning determinations and defending against resolutions that might be the outcome of incorrect, rigged, or even &lt;a href=&#34;https://www.youtube.com/watch?v=rga2-d1oi30&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bogus&lt;/a&gt; computations.
In this context, &lt;em&gt;accountability&lt;/em&gt; becomes a relevant concept, since it comprises the property of an automated decision system to be fair, transparent, and explainable to human beings.
As a consequence, the more accountable a system is, the more audit power it gives to people.&lt;/p&gt;
&lt;p&gt;Within the field of Biometrics, traditional iris recognition solutions are well known for constituting very reliable methods of identity verification.
Nevertheless, since they are not human-friendly enough to convince people who do not possess image processing expertise, their usage before a jury in courts of law is usually avoided.
Aware of this limitation, Prof. &lt;a href=&#34;https://engineering.nd.edu/profiles/aczajka&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adam Czajka&lt;/a&gt; has started at &lt;a href=&#34;https://cvrl.nd.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CVRL&lt;/a&gt; the investigation of human-intelligible iris matching strategies.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m having the chance to tackle the lack of accountability in iris recognition algorithms through the &lt;a href=&#34;https://danielmoreira.github.io/project/tshepii/&#34;&gt;TSHEPII&lt;/a&gt; project.&lt;/p&gt;
&lt;h2 id=&#34;keep-pushing&#34;&gt;Keep pushing&lt;/h2&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;a href=&#34;http://matt.might.net/articles/phd-school-in-pictures/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/bettersoc/conclusion_hu616153b9ba853b08cfcb0b17a764e62a_15659_e23e16d19519778674ab513c11e045a2.webp 400w,
               /post/bettersoc/conclusion_hu616153b9ba853b08cfcb0b17a764e62a_15659_854e5ff6e773e415988e6dcb79881f6d.webp 760w,
               /post/bettersoc/conclusion_hu616153b9ba853b08cfcb0b17a764e62a_15659_1200x1200_fit_q90_h2_lanczos.webp 1200w&#34;
               src=&#34;https://danielmoreira.github.io/post/bettersoc/conclusion_hu616153b9ba853b08cfcb0b17a764e62a_15659_e23e16d19519778674ab513c11e045a2.webp&#34;
               width=&#34;600px&#34;
               height=&#34;251&#34;
               loading=&#34;lazy&#34; /&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;Although the aforementioned efforts may seem minuscule in face of the size of the challenge of building a better society, I try to calm myself down by making a parallel to the &lt;a href=&#34;http://matt.might.net/articles/phd-school-in-pictures/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;explanation&lt;/a&gt; of Prof. Matt Might on how the human knowledge increases with the progress of scientific research.
As he advises, &lt;em&gt;I keep pushing&lt;/em&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MediFor</title>
      <link>https://danielmoreira.github.io/project/medifor/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/project/medifor/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Concluded, &lt;strong&gt;Funded by:&lt;/strong&gt; DARPA&lt;br&gt;
&lt;strong&gt;Advisor:&lt;/strong&gt; Prof. &lt;a href=&#34;https://www.wjscheirer.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Walter Scheirer&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Host:&lt;/strong&gt; &lt;a href=&#34;https://www.nd.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;University of Notre Dame&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Media Forensics research project (&lt;a href=&#34;https://www.darpa.mil/program/media-forensics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MediFor&lt;/a&gt;) is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA) and the Air Force Research Laboratory (AFRL), whose goal is to develop solutions for the automated assessment of the integrity of digital images.&lt;/p&gt;
&lt;p&gt;Working together with the Universities of Purdue, South California (USC), New York (NYU), Siena, Campinas (Unicamp), and the Politécnico di Milano, our team leads the development of solutions to the problem of Provenance Analysis. Given a questioned image, namely a probe, and a large corpus of images (such as the Internet), Provenance Analysis aims at two major tasks:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Finding the images that directly and transitively share content with the probe (a task we call Provenance Filtering).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Building the directed acyclic graph whose nodes individually represent the probe and related images, and whose edges express the edition and content-donation history (e.g., cropping, blurring, removal, splicing, etc.) between pairs of images, linking seminal to generated elements (a task we call Provenance Graph Construction).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Na43QFKW9PE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;/p&gt;
&lt;p&gt;By combining ideas from the areas of image retrieval, digital image forensics, and graph theory, Provenance Analysis constitutes an interesting interdisciplinary topic that spans the fields of image processing and computer vision.&lt;/p&gt;
&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Prof. Walter Scheirer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Anderson Rocha (PI)&lt;/li&gt;
&lt;li&gt;Prof. Kevin Bowyer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Patrick Flynn (PI)&lt;/li&gt;
&lt;li&gt;Daniel Moreira (Postdoc)&lt;/li&gt;
&lt;li&gt;Aparna Bharati (PhD Student)&lt;/li&gt;
&lt;li&gt;Joel Brogan (PhD Student)&lt;/li&gt;
&lt;li&gt;Allan Pinto (PhD Student)&lt;/li&gt;
&lt;li&gt;Michael Parowski (Undergrad Student)&lt;/li&gt;
&lt;li&gt;Patricia Hale (Undergrad Student)&lt;/li&gt;
&lt;li&gt;William Badart (Undergrad Student)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>SREFV</title>
      <link>https://danielmoreira.github.io/project/srefv/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/project/srefv/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Concluded&lt;br&gt;
&lt;strong&gt;Advisor:&lt;/strong&gt; Prof. &lt;a href=&#34;http://sites.nd.edu/patrick-flynn/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Patrick Flynn&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Host:&lt;/strong&gt; &lt;a href=&#34;https://www.nd.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;University of Notre Dame&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The SREFV project aims at extending &lt;a href=&#34;https://cvrl.nd.edu/projects/?project_name=Synthesis%20of%20Realistic%20Example%20Face%20Images%20%28SREFI%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;prior research&lt;/a&gt; on synthesis of realistic faces, to support the generation of videos containing animated faces with synthetic identities, depicted either frontally or in varying poses.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;SREFV preliminary results.&#34;
           src=&#34;https://danielmoreira.github.io/project/srefv/sample.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Besides the obvious artistic and entertainment purposes, the outcome of this project will constitute an interesting tool to de-identify and diversify the faces depicted in video training datasets, helping to protect the identity of volunteers, and to mitigate eventual age, gender, and ethnic dataset collection biases.&lt;/p&gt;
&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Prof. Patrick Flynn (PI)&lt;/li&gt;
&lt;li&gt;Prof. Kevin Bowyer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Adam Czajka (PI)&lt;/li&gt;
&lt;li&gt;Prof. Walter Scheirer (PI)&lt;/li&gt;
&lt;li&gt;Daniel Moreira (Postdoc)&lt;/li&gt;
&lt;li&gt;Sandipan Banerjee (PhD Student)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>TSHEPII</title>
      <link>https://danielmoreira.github.io/project/tshepii/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/project/tshepii/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Concluded&lt;br&gt;
&lt;strong&gt;Advisor:&lt;/strong&gt; Prof. &lt;a href=&#34;https://engineering.nd.edu/profiles/aczajka&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adam Czajka&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Host:&lt;/strong&gt; &lt;a href=&#34;https://www.nd.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;University of Notre Dame&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The TSHEPII project aims at developing a software tool to support the human examination of post-mortem iris images.
The tool puts together diverse computer vision techniques to automatically process, extract, annotate, and match iris regions from two different eye captures.
The idea is to give to the user enough iris texture matching and non-matching information, so they can decided if the two given images depict the same eye or not.&lt;/p&gt;
&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/FLlXDv8EdeU&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;/p&gt;
&lt;p&gt;The video above depicts a demo of the TSHEPII tool, with all the computer vision techniques added to the software.
As the project name suggests (Tool Supporting the Human Examination of &lt;strong&gt;Post-Mortem&lt;/strong&gt; Iris Images), the tool is particularly tuned to the case of comparing post-mortem irises, which, contrary to the common sense, might still be useful for performing iris recognition.&lt;/p&gt;
&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Prof. Adam Czajka (PI)&lt;/li&gt;
&lt;li&gt;Prof. Patrick Flynn (PI)&lt;/li&gt;
&lt;li&gt;Prof. Kevin Bowyer (PI)&lt;/li&gt;
&lt;li&gt;Daniel Moreira (Postdoc)&lt;/li&gt;
&lt;li&gt;Mateusz Trokielewicz (PhD Student)&lt;/li&gt;
&lt;li&gt;M.D. Piotr Maciejewicz (Collaborator)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>TRoF</title>
      <link>https://danielmoreira.github.io/project/trof/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/project/trof/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/oIeYz6Kj9Q4&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Concluded, &lt;strong&gt;Funded by:&lt;/strong&gt; Samsung Eletrônica da Amazônia Ltda.&lt;br&gt;
&lt;strong&gt;Advisor:&lt;/strong&gt; Prof. &lt;a href=&#34;https://www.ic.unicamp.br/~rocha/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anderson Rocha&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Host:&lt;/strong&gt; &lt;a href=&#34;https://www.unicamp.br/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;University of Campinas&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;about&#34;&gt;About&lt;/h2&gt;
&lt;p&gt;Temporal Robust Features (TRoF) comprise a spatiotemporal video content detector and a descriptor developed to present low-memory footprint and small runtime.
It was shown to be effective for the tasks of &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0379073816304169&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pornography&lt;/a&gt; and &lt;a href=&#34;https://ieeexplore.ieee.org/document/7926633&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;violence&lt;/a&gt; detection.
Please refer to both articles for further technical details.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;usage&#34;&gt;Usage&lt;/h2&gt;
&lt;p&gt;TRoF executable is available through a &lt;a href=&#34;https://www.docker.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docker&lt;/a&gt; image, available &lt;a href=&#34;https://hub.docker.com/r/dmoreira/trof/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.
Prior to running it, you have to &lt;a href=&#34;https://docs.docker.com/install/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;install docker&lt;/a&gt; (available for various OS platforms).
Once docker is running, you have to execute the following scripts, in command line:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;your-computer$ docker run -ti dmoreira/trof bash
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;go&#34;&gt;docker-instance# cd TRoF
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;docker-instance# ./fast_trof_descriptor
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Follow the printed usage instructions for running TRoF.
The software reads a video input file and outputs float feature vectors, one per line, in the following format:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;x y t v1 v2 v3 ... vn
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Pleaser refer to either &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/cp/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; or &lt;a href=&#34;https://docs.docker.com/storage/volumes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, if you want to add videos to a running TRoF docker instance.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you are using TRoF, please cite:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;@article{moreira2016fsi,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;  title = {Pornography classification: the hidden clues in video space-time},
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;  author={Daniel Moreira and Sandra Avila and Mauricio Perez and Daniel Moraes and
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;     Vanessa Testoni and Eduardo Valle and Siome Goldenstein and Anderson Rocha},
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;  journal = {Elsevier Forensic Science International},
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;  year    = {2016},
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;  volume  = {268},
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;  number  = {1},
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;  pages   = {46--61}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;go&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;disclaimer&#34;&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;This software is provided by the authors as is, with no warranties and no support, &lt;strong&gt;for academic purposes only&lt;/strong&gt;.
The authors assume no responsibility or liability for the use of the software.
They do not convey any license or title under any patent or copyright, and they reserve the right to make changes in the software without notification.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;This software was developed through the project &amp;ldquo;Sensitive Media Analysis&amp;rdquo;, hosted at the University of Campinas, and sponsored by Samsung Eletronica da Amazonia Ltda., in the framework of the Brazilian law N. 815 8,248/91.
We thank the financial support of the Brazilian Council for Scientific and Technological Development - CNPq (Grants #477662/2013-7, #304472/2015-8), the Sao Paulo Research Foundation - Fapesp (DejaVu Grant #2015/19222-9), and the Coordination for the Improvement of Higher Level Education Personnel - CAPES (DeepEyes project).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SMA</title>
      <link>https://danielmoreira.github.io/project/sma/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/project/sma/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Concluded, &lt;strong&gt;Funded by:&lt;/strong&gt; Samsung Eletrônica da Amazônia Ltda.&lt;br&gt;
&lt;strong&gt;Advisor:&lt;/strong&gt; Prof. &lt;a href=&#34;https://www.ic.unicamp.br/~rocha/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Anderson Rocha&lt;/a&gt;&lt;br&gt;
&lt;strong&gt;Host:&lt;/strong&gt; &lt;a href=&#34;https://www.unicamp.br/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;University of Campinas&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The Sensitive Media Analysis (SMA) project aims at researching solutions to combine different and complementary data representations and pattern classifiers for detecting sensitive content in digital images and videos.&lt;/p&gt;
&lt;p&gt;Sensitive media can be defined as the digital content whose depiction to particular audiences (e.g., children or unwary spectators), at particular places (e.g., at work, at school, in the church) may inflict harm (e.g., trauma, shock, or fear) due to its inappropriateness.
Typical representatives include – but are not limited to – scenes depicting pornography and violence, animal cruelty and child abuse, hate speech, etc.&lt;/p&gt;
&lt;p&gt;The innovation aspects of the project reside on the development of solutions that are amenable to deployment on mobile devices (e.g., smartphones and tablets), observing their constraints of memory footprint, processing power, and runtime responsiveness.&lt;/p&gt;
&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Prof. Anderson Rocha (PI)&lt;/li&gt;
&lt;li&gt;Prof. Siome Goldenstein (PI)&lt;/li&gt;
&lt;li&gt;Prof. Eduardo Valle (PI)&lt;/li&gt;
&lt;li&gt;Dr. Vanessa Testoni (Samsung Collaborator)&lt;/li&gt;
&lt;li&gt;Dr. Sandra Avila (Postdoc)&lt;/li&gt;
&lt;li&gt;Daniel Moreira (PhD Student)&lt;/li&gt;
&lt;li&gt;Mauricio Perez (MSc Student)&lt;/li&gt;
&lt;li&gt;Daniel Moraes (Developer)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Multimodal and real-time method for filtering sensitive media</title>
      <link>https://danielmoreira.github.io/publication/2019_patent/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2019_patent/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Beyond Pixels: Image Provenance Analysis Leveraging Metadata</title>
      <link>https://danielmoreira.github.io/publication/2019_wacv_metada/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2019_wacv_metada/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Domain-Specific Human-Inspired Binarized Statistical Image Features for Iris Recognition</title>
      <link>https://danielmoreira.github.io/publication/2019_wacv_bsif/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2019_wacv_bsif/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Performance of Humans in Iris Recognition: The Impact of Iris Condition and Annotation-Driven Verification</title>
      <link>https://danielmoreira.github.io/publication/2019_wacv_human/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2019_wacv_human/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multimodal data fusion for sensitive scene localization</title>
      <link>https://danielmoreira.github.io/publication/2019_if/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2019_if/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image Provenance Analysis at Scale</title>
      <link>https://danielmoreira.github.io/publication/2018_tip/</link>
      <pubDate>Thu, 16 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2018_tip/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Getting the subtext without the text: Scalable multimodal sentiment classification from visual and acoustic modalities</title>
      <link>https://danielmoreira.github.io/publication/2018_acl/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2018_acl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Método multimodal e em tempo real para filtragem de conteúdo sensível</title>
      <link>https://danielmoreira.github.io/publication/2017_patent/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2017_patent/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Provenance filtering for multimedia phylogeny</title>
      <link>https://danielmoreira.github.io/publication/2017_icip_filtering/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2017_icip_filtering/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spotting the difference: Context retrieval and analysis for improved forgery detection and localization</title>
      <link>https://danielmoreira.github.io/publication/2017_icip_spotting/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2017_icip_spotting/</guid>
      <description></description>
    </item>
    
    <item>
      <title>U-Phylogeny: Undirected provenance graph construction in the wild</title>
      <link>https://danielmoreira.github.io/publication/2017_icip_uphylogeny/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2017_icip_uphylogeny/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Temporal Robust Features for Violence Detection</title>
      <link>https://danielmoreira.github.io/publication/2017_wacv/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2017_wacv/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/yoV4b1CQ1aY&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Video pornography detection through deep learning techniques and motion information</title>
      <link>https://danielmoreira.github.io/publication/2017_neurocomputing/</link>
      <pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2017_neurocomputing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pornography classification: The hidden clues in video space–time</title>
      <link>https://danielmoreira.github.io/publication/2016_fsi/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2016_fsi/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sensitive-Video Analysis</title>
      <link>https://danielmoreira.github.io/publication/2016_dissertation/</link>
      <pubDate>Tue, 19 Jul 2016 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2016_dissertation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RECOD at MediaEval 2015: Affective Impact of Movies Task</title>
      <link>https://danielmoreira.github.io/publication/2015_mediaeval/</link>
      <pubDate>Fri, 16 Oct 2015 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2015_mediaeval/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RECOD at MediaEval 2014: Violent Scenes Detection Task</title>
      <link>https://danielmoreira.github.io/publication/2014_mediaeval/</link>
      <pubDate>Thu, 16 Oct 2014 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2014_mediaeval/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SimPatrol: um simulador de sistemas multiagentes para o patrulhamento</title>
      <link>https://danielmoreira.github.io/publication/2008_thesis/</link>
      <pubDate>Thu, 04 Sep 2008 00:00:00 +0000</pubDate>
      <guid>https://danielmoreira.github.io/publication/2008_thesis/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
