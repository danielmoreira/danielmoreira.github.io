<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Daniel Moreira</title>
    <link>https://danielmoreira.github.io/</link>
    <description>Recent content on Daniel Moreira</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Daniel Moreira, {year}</copyright>
    <lastBuildDate>Thu, 13 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://danielmoreira.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A Better Society</title>
      <link>https://danielmoreira.github.io/post/bettersoc/</link>
      <pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/post/bettersoc/</guid>
      <description>

&lt;p&gt;One of the major challenges I face while doing my research is how to drive it towards building a better society.
Although I understand the concept of a &lt;em&gt;better society&lt;/em&gt; may be different from one culture to the other, I try to make things simpler by believing that any society gets better whenever &lt;strong&gt;all&lt;/strong&gt; of its members experience more &lt;strong&gt;freedom&lt;/strong&gt; to enjoy their &lt;strong&gt;rights&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Among the untold manners technology can be used to breach people&amp;rsquo;s rights, five setbacks in the way we are doing informatics get my attention.
Devices and programs usually suffer from (1) lack of &lt;strong&gt;safety&lt;/strong&gt;, (2) nonobservance of &lt;strong&gt;data integrity&lt;/strong&gt;, (3) lack of &lt;strong&gt;privacy&lt;/strong&gt;, (4) nonobservance of &lt;strong&gt;diversity&lt;/strong&gt;, and (5) lack of &lt;strong&gt;accountability&lt;/strong&gt;.
Not unintentionally, the &lt;a href=&#34;https://danielmoreira.github.io/#projects&#34;&gt;projects&lt;/a&gt; I&amp;rsquo;ve been contributing to in the past few years tackle one or more of these issues.&lt;/p&gt;

&lt;h2 id=&#34;safety&#34;&gt;Safety&lt;/h2&gt;




&lt;figure&gt;
&lt;a href=&#34;https://commons.wikimedia.org/wiki/File:Interest.jpg&#34;&gt;
&lt;img src=&#34;safety.jpg&#34; width=&#34;300px&#34; /&gt;
&lt;/a&gt;

&lt;/figure&gt;

&lt;p&gt;From the many ways safety can be harmed by technology, the improper dissemination of sensitive content (such as pornography or violence), to inadequate audiences (such as kids or unwary spectators), gained my attention while I was developing my PhD, under the supervision of prof. &lt;a href=&#34;https://www.ic.unicamp.br/~rocha/index.html&#34; target=&#34;_blank&#34;&gt;Anderson Rocha&lt;/a&gt; (who generously proposed the topic).&lt;/p&gt;

&lt;p&gt;With the popularity and pervasiveness of online video streams, sensitive scenes depicting &lt;a href=&#34;https://www.washingtonpost.com/news/the-intersect/wp/2017/01/15/a-12-year-old-girl-live-streamed-her-suicide-it-took-two-weeks-for-facebook-to-take-the-video-down/?utm_term=.ea8124e4a0e9&#34; target=&#34;_blank&#34;&gt;suicide&lt;/a&gt;, &lt;a href=&#34;https://www.cnn.com/videos/us/2016/06/17/man-shot-killed-while-live-streaming-orig-vstan-dlewis.cnn&#34; target=&#34;_blank&#34;&gt;murder&lt;/a&gt;, and even &lt;a href=&#34;https://www.nytimes.com/2016/04/19/us/periscope-rape-case-columbus-ohio-video-livestreaming.html&#34; target=&#34;_blank&#34;&gt;rape&lt;/a&gt; have been broadcasted on the Internet, raising questions about the safety of these services.
Aware of this situation, &lt;a href=&#34;https://www.samsung.com/br/&#34; target=&#34;_blank&#34;&gt;Samsung&lt;/a&gt; has funded us to focus on the development of solutions to detect sensitive video.
Rather than aiming at denouncing or morally condemning the lawful consumers of certain types of sensitive content, our intent has always been to support the implementation of filtering and warning features that would make player systems safer (especially in the case of child spectators).&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve had the chance to tackle the lack of safety in video streaming systems through the &lt;a href=&#34;https://danielmoreira.github.io/project/sma&#34;&gt;SMA&lt;/a&gt; project.&lt;/p&gt;

&lt;h2 id=&#34;data-integrity&#34;&gt;Data Integrity&lt;/h2&gt;




&lt;figure&gt;

&lt;img src=&#34;trust.jpg&#34; width=&#34;300px&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;In the era of misinformation and &lt;em&gt;fake news&lt;/em&gt;, there is a symptomatic undermining of trust not only in textual but also in visual information.
People are conscious of the existence of image editing software (e.g., &lt;em&gt;Photoshop&lt;/em&gt;), with which even unskilled users can easily fabricate and manipulate pictures.
Although many of these manipulations have benign purposes (no, there is nothing wrong with &lt;em&gt;your memes&lt;/em&gt;), some contents are generated with malicious intents, such as general public deception and propaganda.&lt;/p&gt;

&lt;p&gt;The lack of available solutions to assess the integrity of images and videos allows adversarial manipulated data to have a negative impact on the way people relate to each other on the Internet.
They don&amp;rsquo;t know what to trust anymore.
In addition, fraudulent images represent a challenge even for the &lt;a href=&#34;https://www.nature.com/articles/s41419-018-0430-3&#34; target=&#34;_blank&#34;&gt;scientific community&lt;/a&gt;.
Aware of this scenario, &lt;a href=&#34;https://www.darpa.mil/program/media-forensics&#34; target=&#34;_blank&#34;&gt;DARPA&lt;/a&gt; has been funding us, at &lt;a href=&#34;https://cvrl.nd.edu/&#34; target=&#34;_blank&#34;&gt;CVRL&lt;/a&gt;, to conduct research on the development of tools to verify the integrity of digital images.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m having the chance to tackle the nonobservance of data integrity in visual media systems through the &lt;a href=&#34;https://danielmoreira.github.io/project/medifor&#34;&gt;MediFor&lt;/a&gt; and &lt;a href=&#34;https://danielmoreira.github.io/project/sciint&#34;&gt;Sci-Int&lt;/a&gt; projects.&lt;/p&gt;

&lt;h2 id=&#34;privacy-and-diversity&#34;&gt;Privacy and Diversity&lt;/h2&gt;




&lt;figure&gt;

&lt;img src=&#34;privacy.gif&#34; width=&#34;300px&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;With the advent of deep learning and the necessity for large datasets, &lt;em&gt;visual data collection&lt;/em&gt; has become an important step of Computer Vision and Machine Learning research.
Due to the popularity of image and video capture devices (such as digital cameras, smartphones, dash cams, etc.), large datasets can now be quickly generated.
Nevertheless, a major question that stands out in such a process is how to protect the privacy of people who are eventually being recorded.
Imagine, for example, a dash cam that is collecting road data for a self-driving car project.
In a major city, plenty of people will certainly be captured in the footages, and it is very unlikely that one will be able to obtain image rights for each individual.&lt;/p&gt;

&lt;p&gt;Interested in such issue, we, at &lt;a href=&#34;https://cvrl.nd.edu/&#34; target=&#34;_blank&#34;&gt;CVRL&lt;/a&gt;, investigate the generation of realistic synthetic faces, whose identities do not belong to a real existing person, hence avoiding privacy breaches.
The idea is to de-identify the recorded individuals, by replacing their faces with synthetic assets.&lt;/p&gt;




&lt;figure&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=t4DT3tQqgRM&#34;&gt;
&lt;img src=&#34;diversity.gif&#34; width=&#34;300px&#34; /&gt;
&lt;/a&gt;

&lt;/figure&gt;

&lt;p&gt;In addition, collected data may be biased, due to a lack of diversity in the captured individuals.
Consider, for instance, training video footages collected in China.
It is very &lt;a href=&#34;https://www.nationalgeographic.com/travel/destinations/asia/china/black-tourist-china/&#34; target=&#34;_blank&#34;&gt;unlikely&lt;/a&gt; that black people will be represented in such a dataset.&lt;/p&gt;

&lt;p&gt;Limitations of this nature comprise what I call &lt;em&gt;nonobservance of diversity&lt;/em&gt; and are the potential cause of many &lt;a href=&#34;http://www.cnn.com/2009/TECH/12/22/hp.webcams/index.html&#34; target=&#34;_blank&#34;&gt;technological failures&lt;/a&gt; in the presence of underrepresented groups.
Unfortunately, glitches like these may go &lt;a href=&#34;https://www.forbes.com/sites/mzhang/2015/07/01/google-photos-tags-two-african-americans-as-gorillas-through-facial-recognition-software/#41ebc8e8713d&#34; target=&#34;_blank&#34;&gt;beyond the technological aspects&lt;/a&gt; and prejudice the rights of equality in face of diversity.
To cope with this problem, similar to the privacy protection strategy, synthetic identities can be used to diversify the recorded individuals by performing face replacement, providing controlled variation of not only ethnicity but also of age and of gender.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m having the chance to tackle the lack of privacy and nonobservance of diversity in image and video datasets through the &lt;a href=&#34;https://danielmoreira.github.io/project/srefv&#34;&gt;SREFV&lt;/a&gt; project.&lt;/p&gt;

&lt;h2 id=&#34;accountability&#34;&gt;Accountability&lt;/h2&gt;




&lt;figure&gt;

&lt;img src=&#34;acc.gif&#34; width=&#34;300px&#34; /&gt;


&lt;/figure&gt;

&lt;p&gt;People have the right to understand in details the decisions made about them by algorithms belonging to either government or industry.
This is fundamental to give them the possibility of questioning determinations and defending against resolutions that might be the outcome of incorrect, rigged, or even &lt;a href=&#34;https://www.youtube.com/watch?v=rga2-d1oi30&#34; target=&#34;_blank&#34;&gt;bogus&lt;/a&gt; computations.
In this context, &lt;em&gt;accountability&lt;/em&gt; becomes a relevant concept, since it comprises the property of an automated decision system to be fair, transparent, and explainable to human beings.
As a consequence, the more accountable a system is, the more audit power it gives to people.&lt;/p&gt;

&lt;p&gt;Within the field of Biometrics, traditional iris recognition solutions are well known for constituting very reliable methods of identity verification.
Nevertheless, since they are not human-friendly enough to convince people who do not possess image processing expertise, their usage before a jury in courts of law is still avoided.
Aware of this limitation, Prof. &lt;a href=&#34;https://engineering.nd.edu/profiles/aczajka&#34; target=&#34;_blank&#34;&gt;Adam Czajka&lt;/a&gt; has started at &lt;a href=&#34;https://cvrl.nd.edu/&#34; target=&#34;_blank&#34;&gt;CVRL&lt;/a&gt; the investigation of more human-intelligible iris matching strategies.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m having the chance to tackle the lack of accountability in iris recognition algorithms through the &lt;a href=&#34;https://danielmoreira.github.io/project/tshepii&#34;&gt;TSHEPII&lt;/a&gt; project.&lt;/p&gt;

&lt;h2 id=&#34;keep-pushing&#34;&gt;Keep pushing&lt;/h2&gt;




&lt;figure&gt;
&lt;a href=&#34;http://matt.might.net/articles/phd-school-in-pictures/&#34;&gt;
&lt;img src=&#34;conclusion.jpg&#34; width=&#34;600px&#34; /&gt;
&lt;/a&gt;

&lt;/figure&gt;

&lt;p&gt;Although the aforementioned efforts may seem minuscule in face of the size of the challenge of building a better society, I try to calm myself down by making a parallel to the &lt;a href=&#34;http://matt.might.net/articles/phd-school-in-pictures/&#34; target=&#34;_blank&#34;&gt;explanation&lt;/a&gt; of Prof. Matt Might on how the human knowledge increases with the progress of scientific research.
As he advises, &lt;em&gt;I keep pushing&lt;/em&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MediFor</title>
      <link>https://danielmoreira.github.io/project/medifor/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/project/medifor/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Ongoing, &lt;strong&gt;Funded by:&lt;/strong&gt; DARPA&lt;br /&gt;
&lt;strong&gt;Advisor:&lt;/strong&gt; Prof. &lt;a href=&#34;https://www.wjscheirer.com/&#34; target=&#34;_blank&#34;&gt;Walter Scheirer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The Media Forensics research project (&lt;a href=&#34;https://www.darpa.mil/program/media-forensics&#34; target=&#34;_blank&#34;&gt;MediFor&lt;/a&gt;) is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA) and the Air Force Research Laboratory (AFRL), whose goal is to develop solutions for the automated assessment of the integrity of digital images.&lt;/p&gt;

&lt;p&gt;Working together with the Universities of Purdue, South California (USC), New York (NYU), Siena, Campinas (Unicamp), and the Politécnico di Milano, our team leads the development of solutions to the problem of Provenance Analysis. Given a questioned image, namely a probe, and a large corpus of images (such as the Internet), Provenance Analysis aims at two major tasks:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Finding the images that directly and transitively share content with the probe (a task we call Provenance Filtering).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Building the directed acyclic graph whose nodes individually represent the probe and related images, and whose edges express the edition and content-donation history (e.g., cropping, blurring, removal, splicing, etc.) between pairs of images, linking seminal to generated elements (a task we call Provenance Graph Construction).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;By combining ideas from the areas of image retrieval, digital image forensics, and graph theory, Provenance Analysis constitutes an interesting interdisciplinary topic that spans the fields of image processing and computer vision.&lt;/p&gt;

&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Prof. Walter Scheirer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Anderson Rocha (PI)&lt;/li&gt;
&lt;li&gt;Prof. Kevin Bowyer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Patrick Flynn (PI)&lt;/li&gt;
&lt;li&gt;Daniel Moreira (Postdoc)&lt;/li&gt;
&lt;li&gt;Aparna Bharati (PhD Student)&lt;/li&gt;
&lt;li&gt;Joel Brogan (PhD Student)&lt;/li&gt;
&lt;li&gt;Allan Pinto (PhD Student)&lt;/li&gt;
&lt;li&gt;Michael Parowski (Undergrad Student)&lt;/li&gt;
&lt;li&gt;Patricia Hale (Undergrad Student)&lt;/li&gt;
&lt;li&gt;William Badart (Undergrad Student)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>SREFV</title>
      <link>https://danielmoreira.github.io/project/srefv/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/project/srefv/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Wrapping up&lt;br /&gt;
&lt;strong&gt;Advisor:&lt;/strong&gt; Prof. &lt;a href=&#34;http://sites.nd.edu/patrick-flynn/&#34; target=&#34;_blank&#34;&gt;Patrick Flynn&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The SREFV project aims at extending &lt;a href=&#34;https://cvrl.nd.edu/projects/?project_name=Synthesis%20of%20Realistic%20Example%20Face%20Images%20(SREFI)&#34; target=&#34;_blank&#34;&gt;prior research&lt;/a&gt; on synthesis of realistic faces, to support the generation of videos containing animated faces with synthetic identities, depicted either frontally or in varying poses.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;sample.gif&#34; alt=&#34;SREFV preliminary results.&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Besides the obvious artistic and entertainment purposes, the outcome of this project will constitute an interesting tool to de-identify and diversify the faces depicted in video training datasets, helping to protect the identity of volunteers, and to mitigate eventual age, gender, and ethnic dataset collection biases.&lt;/p&gt;

&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Prof. Patrick Flynn (PI)&lt;/li&gt;
&lt;li&gt;Prof. Kevin Bowyer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Adam Czajka (PI)&lt;/li&gt;
&lt;li&gt;Prof. Walter Scheirer (PI)&lt;/li&gt;
&lt;li&gt;Daniel Moreira (Postdoc)&lt;/li&gt;
&lt;li&gt;Sandipan Banerjee (PhD Student)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Sci-Int</title>
      <link>https://danielmoreira.github.io/project/sciint/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/project/sciint/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Ongoing, &lt;strong&gt;Funded by:&lt;/strong&gt; DARPA&lt;br /&gt;
&lt;strong&gt;Advisor:&lt;/strong&gt; Prof. &lt;a href=&#34;https://www.wjscheirer.com/&#34; target=&#34;_blank&#34;&gt;Walter Scheirer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The Scientific Integrity (Sci-Int) project is an endeavor funded by the Defense Advanced Research Projects Agency (DARPA), whose goal is to develop solutions to identify misconduct in scientific research through the detection of image tampering in scientific papers.&lt;/p&gt;

&lt;p&gt;Working together with the Universities of Purdue, South California (USC), Campinas (Unicamp), and the Politécnico di Milano, our team leads the development of techniques to (1) rule out false positive cases of misidentified misconduct, and to (2) better report and document misconduct practices in retraction notices.&lt;/p&gt;

&lt;p&gt;To accomplish item (1), we plan to perform semantic analyses of the suspect paper cases, in order to identify situations in which duplications or manipulations of content were made with fair scientific purpose (e.g., to visually highlight or to better explain previous results). To do that, we plan to use natural language processing to perform basic automated paper text and image caption interpretation.&lt;/p&gt;

&lt;p&gt;To accomplish item (2), we plan to rely on techniques of Provenance Graph Construction to present better explanations of how problematic images relate to each other, and how they share content across different papers.&lt;/p&gt;

&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Prof. Walter Scheirer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Anderson Rocha (PI)&lt;/li&gt;
&lt;li&gt;Prof. Kevin Bowyer (PI)&lt;/li&gt;
&lt;li&gt;Prof. Patrick Flynn (PI)&lt;/li&gt;
&lt;li&gt;Daniel Moreira (Postdoc)&lt;/li&gt;
&lt;li&gt;Aparna Bharati (PhD Student)&lt;/li&gt;
&lt;li&gt;Joel Brogan (PhD Student)&lt;/li&gt;
&lt;li&gt;Abigail Graese (PhD Student)&lt;/li&gt;
&lt;li&gt;João P. Cardenuto (MSc Student)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>TSHEPII</title>
      <link>https://danielmoreira.github.io/project/tshepii/</link>
      <pubDate>Wed, 29 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/project/tshepii/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Wrapping up&lt;br /&gt;
&lt;strong&gt;Advisor:&lt;/strong&gt; Prof. &lt;a href=&#34;https://engineering.nd.edu/profiles/aczajka&#34; target=&#34;_blank&#34;&gt;Adam Czajka&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The TSHEPII project aims at developing a software tool to support the human examination of post-mortem iris images.
The tool puts together diverse computer vision techniques to automatically process, extract, annotate, and match iris regions from two different eye captures.
The idea is to give to the user enough iris texture matching and non-matching information, so they can decided if the two given images depict the same eye or not.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/FLlXDv8EdeU&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;The video above depicts a demo of the TSHEPII tool, with all the computer vision techniques added to the software.
As the project name suggests (Tool Supporting the Human Examination of &lt;strong&gt;Post-Mortem&lt;/strong&gt; Iris Images), the tool is particularly tuned to the case of comparing post-mortem irises, which, contrary to the common sense, might still be useful for performing iris recognition.&lt;/p&gt;

&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Prof. Adam Czajka (PI)&lt;/li&gt;
&lt;li&gt;Prof. Patrick Flynn (PI)&lt;/li&gt;
&lt;li&gt;Prof. Kevin Bowyer (PI)&lt;/li&gt;
&lt;li&gt;Daniel Moreira (Postdoc)&lt;/li&gt;
&lt;li&gt;Mateusz Trokielewicz (PhD Student)&lt;/li&gt;
&lt;li&gt;M.D. Piotr Maciejewicz (Collaborator)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>TRoF</title>
      <link>https://danielmoreira.github.io/project/trof/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/project/trof/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SMA</title>
      <link>https://danielmoreira.github.io/project/sma/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/project/sma/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Status:&lt;/strong&gt; Concluded, &lt;strong&gt;Funded by:&lt;/strong&gt; Samsung Eletrônica da Amazônia Ltda.&lt;br /&gt;
&lt;strong&gt;Advisor:&lt;/strong&gt; Prof. &lt;a href=&#34;https://www.ic.unicamp.br/~rocha/index.html&#34; target=&#34;_blank&#34;&gt;Anderson Rocha&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The Sensitive Media Analysis (SMA) project aims at researching solutions to combine different and complementary data representations and pattern classifiers for detecting sensitive content in digital images and videos.&lt;/p&gt;

&lt;p&gt;Sensitive media can be defined as the digital content whose depiction to particular audiences (e.g., children or unwary spectators), at particular places (e.g., at work, at school, in the church) may inflict harm (e.g., trauma, shock, or fear) due to its inappropriateness.
Typical representatives include – but are not limited to – scenes depicting pornography and violence, animal cruelty and child abuse, hate speech, etc.&lt;/p&gt;

&lt;p&gt;The innovation aspects of the project reside on the development of solutions that are amenable to deployment on mobile devices (e.g., smartphones and tablets), observing their constraints of memory footprint, processing power, and runtime responsiveness.&lt;/p&gt;

&lt;h2 id=&#34;research-team&#34;&gt;Research Team&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Prof. Anderson Rocha (PI)&lt;/li&gt;
&lt;li&gt;Prof. Siome Goldenstein (PI)&lt;/li&gt;
&lt;li&gt;Prof. Eduardo Valle (PI)&lt;/li&gt;
&lt;li&gt;Dr. Vanessa Testoni (Samsung Collaborator)&lt;/li&gt;
&lt;li&gt;Dr. Sandra Avila (Postdoc)&lt;/li&gt;
&lt;li&gt;Daniel Moreira (PhD Student)&lt;/li&gt;
&lt;li&gt;Mauricio Perez (MSc Student)&lt;/li&gt;
&lt;li&gt;Daniel Moraes (Programmer)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Needle in a Haystack: A Framework for Seeking Small Objects in Big Datasets</title>
      <link>https://danielmoreira.github.io/publication/2019_preprint_needle/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2019_preprint_needle/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multimodal and real-time method for filtering sensitive media</title>
      <link>https://danielmoreira.github.io/publication/2019_patent/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2019_patent/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Beyond Pixels: Image Provenance Analysis Leveraging Metadata</title>
      <link>https://danielmoreira.github.io/publication/2019_wacv_metada/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2019_wacv_metada/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Domain-Specific Human-Inspired Binarized Statistical Image Features for Iris Recognition</title>
      <link>https://danielmoreira.github.io/publication/2019_wacv_bsif/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2019_wacv_bsif/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Performance of Humans in Iris Recognition: The Impact of Iris Condition and Annotation-Driven Verification</title>
      <link>https://danielmoreira.github.io/publication/2019_wacv_human/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2019_wacv_human/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multimodal data fusion for sensitive scene localization</title>
      <link>https://danielmoreira.github.io/publication/2019_if/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2019_if/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image Provenance Analysis at Scale</title>
      <link>https://danielmoreira.github.io/publication/2018_tip/</link>
      <pubDate>Thu, 16 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2018_tip/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Getting the subtext without the text: Scalable multimodal sentiment classification from visual and acoustic modalities</title>
      <link>https://danielmoreira.github.io/publication/2018_acl/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2018_acl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Método multimodal e em tempo real para filtragem de conteúdo sensível</title>
      <link>https://danielmoreira.github.io/publication/2017_patent/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2017_patent/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Provenance filtering for multimedia phylogeny</title>
      <link>https://danielmoreira.github.io/publication/2017_icip_filtering/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2017_icip_filtering/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spotting the difference: Context retrieval and analysis for improved forgery detection and localization</title>
      <link>https://danielmoreira.github.io/publication/2017_icip_spotting/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2017_icip_spotting/</guid>
      <description></description>
    </item>
    
    <item>
      <title>U-Phylogeny: Undirected provenance graph construction in the wild</title>
      <link>https://danielmoreira.github.io/publication/2017_icip_uphylogeny/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2017_icip_uphylogeny/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Temporal Robust Features for Violence Detection</title>
      <link>https://danielmoreira.github.io/publication/2017_wacv/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2017_wacv/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/yoV4b1CQ1aY&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Video pornography detection through deep learning techniques and motion information</title>
      <link>https://danielmoreira.github.io/publication/2017_neurocomputing/</link>
      <pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2017_neurocomputing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pornography classification: The hidden clues in video space–time</title>
      <link>https://danielmoreira.github.io/publication/2016_fsi/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2016_fsi/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/ZfaW5kvXjMo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>RECOD at MediaEval 2015: Affective Impact of Movies Task</title>
      <link>https://danielmoreira.github.io/publication/2015_mediaeval/</link>
      <pubDate>Fri, 16 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2015_mediaeval/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RECOD at MediaEval 2014: Violent Scenes Detection Task</title>
      <link>https://danielmoreira.github.io/publication/2014_mediaeval/</link>
      <pubDate>Thu, 16 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://danielmoreira.github.io/publication/2014_mediaeval/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
